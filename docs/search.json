[
  {
    "objectID": "tutorials/s3-multivar-lakes.html",
    "href": "tutorials/s3-multivar-lakes.html",
    "title": "Multivariate Lake Data Example",
    "section": "",
    "text": "The following example demonstrates basic multivariate principles by means of a teaching example. A detailed description of theory and applications is found in excellent books of Legendre & Legendre (1998) and Borcard et al. (2018). Practical help is found in the tutorials of the vegan package (Oksanen et al., 2020)."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#data-set-and-terms-of-use",
    "href": "tutorials/s3-multivar-lakes.html#data-set-and-terms-of-use",
    "title": "Multivariate Lake Data Example",
    "section": "2 Data set and terms of use",
    "text": "2 Data set and terms of use\nThe lake data set originates from the public data repository of the German Umweltbundesamt (Umweltbundesamt, 2021). The data set provided can be used freely according to the terms and conditions published at the UBA web site, that refer to § 12a EGovG with respect of the data, and to the Creative Commons CC-BY ND International License 4.0 with respect to other objects directly created by UBA.\nThe document and codes provided here can be shared according to CC BY 4.0."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#load-the-data",
    "href": "tutorials/s3-multivar-lakes.html#load-the-data",
    "title": "Multivariate Lake Data Example",
    "section": "3 Load the data",
    "text": "3 Load the data\nHere we load the data set and add English column names and abbreviated lake identifiers as row names to the table, that are useful for the multivariate plotting functions.\n\nlibrary(\"readxl\") # read Excel files directly\nlibrary(\"vegan\")  # multivariate statistics in ecology\nlakes <- as.data.frame(\n  read_excel(\"../data/uba/3_tab_kenndaten-ausgew-seen-d_2021-04-08.xlsx\", sheet=\"Tabelle1\", skip=3)\n)\nnames(lakes) <- c(\"name\", \"state\", \"drainage\", \"population\", \"altitude\", \n                  \"z_mean\", \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                  \"shore_devel\", \"drain_ratio\", \"wfd_type\")\nrownames(lakes) <- paste0(1:nrow(lakes), substr(lakes$name, 1, 4))\n\nText columns, e.g Federal State names and lake type are removed and rows with missing data excluded. If population is not used, the analysis can be repeated with more lakes.\n\nvalid_columns <- c(\"drainage\", \"population\", \"altitude\", \"z_mean\",\n                   \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                   \"shore_devel\", \"drain_ratio\")\n\n#valid_columns <- c(\"drainage\", \"altitude\", \"z_mean\",\n#                   \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n#                   \"shore_devel\",\"drain_ratio\")\ndat <- lakes[valid_columns]\ndat <- na.omit(dat)"
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#data-inspection",
    "href": "tutorials/s3-multivar-lakes.html#data-inspection",
    "title": "Multivariate Lake Data Example",
    "section": "4 Data inspection",
    "text": "4 Data inspection\nIt is alwas a good idea to plot the data first, as time series or boxplots for example, dependingon the type of data. Here we use boxplots, that we scale (z-transform) to a mean zero and standard deviation one to have comparable values.\nAs we can see a number of high extreme values, we apply also a square root transformation, that is less extreme than log transform and not sensitive against zero values, but because altitude contains a negative value (below sea level) we replace this with zero. As it is a small value, it does not influence our analysis, but we should always be very careful to document such workarounds.\n\npar(mfrow = c(1, 1))\npar(mar = c(7, 4, 2, 1) + .1)\nboxplot(scale(dat), las = 2)\n\n\n\ndat$altitude <- ifelse(dat$altitude < 0, 0, dat$altitude)\nboxplot(scale(sqrt(dat)), las=2)"
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#multivariate-analysis",
    "href": "tutorials/s3-multivar-lakes.html#multivariate-analysis",
    "title": "Multivariate Lake Data Example",
    "section": "5 Multivariate Analysis",
    "text": "5 Multivariate Analysis\n\n5.1 Principal Components: PCA\n\npc <- prcomp(scale(dat))\nsummary(pc)\n\nImportance of components:\n                         PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     2.305 1.4737 1.1459 1.0686 0.84953 0.50024 0.24164\nProportion of Variance 0.483 0.1974 0.1194 0.1038 0.06561 0.02275 0.00531\nCumulative Proportion  0.483 0.6805 0.7998 0.9036 0.96925 0.99200 0.99731\n                           PC8     PC9    PC10    PC11\nStandard deviation     0.12590 0.08400 0.07563 0.03077\nProportion of Variance 0.00144 0.00064 0.00052 0.00009\nCumulative Proportion  0.99875 0.99939 0.99991 1.00000\n\nplot(pc)\n\n\n\nbiplot(pc)\n\n\n\n\nAs the PCA with the untransformed data looks somewhat asymmetric, we repeat it with square transformed data. In addition, also the 3rd PC is plotted.\n\ndat2 <- sqrt(dat)\npc2 <- prcomp(scale(dat2))\nsummary(pc2)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     2.1886 1.5906 1.2499 1.0634 0.79782 0.44854 0.28572\nProportion of Variance 0.4354 0.2300 0.1420 0.1028 0.05786 0.01829 0.00742\nCumulative Proportion  0.4354 0.6654 0.8075 0.9103 0.96812 0.98641 0.99383\n                           PC8     PC9    PC10    PC11\nStandard deviation     0.17665 0.13833 0.12041 0.05528\nProportion of Variance 0.00284 0.00174 0.00132 0.00028\nCumulative Proportion  0.99666 0.99840 0.99972 1.00000\n\npar(mfrow=c(1,2))\npar(mar=c(5, 4, 4, 2) + 0.1)\nbiplot(pc2, cex=0.6)\nbiplot(pc2, cex=0.6, choices=c(3, 2))\n\n\n\n\nA PCA is also possible with the rda function of the vegan package. The syntax of the plot functions is somewhat different. Instead of biplot as above, we can directly use plot. Details are found in the vegan documentation.\n\npar(mfrow=c(1,1))\npc3 <- rda(dat2, scale = TRUE)\npc3\n\nCall: rda(X = dat2, scale = TRUE)\n\n              Inertia Rank\nTotal              11     \nUnconstrained      11   11\nInertia is correlations \n\nEigenvalues for unconstrained axes:\n  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10  PC11 \n4.790 2.530 1.562 1.131 0.637 0.201 0.082 0.031 0.019 0.014 0.003 \n\n#summary(pc3)\nplot(pc3)\n\n\n\n\n\n\n5.2 Nonmetric Multidimensional Scaling: NMDS\nLt’s now perform an NMDS for the data set. Function metaMDS runs a series of NMDS fits with different start values to avoid local minima. It has also some automatic transformations built in and works usually with the Bray-Curtis dissimilarity, that is used for plants and animal species abundance data. As we work with physical data here, we set the distance measure to “euclidean”.\n\nmd <- metaMDS(dat2, scale = TRUE, distance = \"euclid\")\n\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.1181117 \nRun 1 stress 0.1207022 \nRun 2 stress 0.1188526 \nRun 3 stress 0.1188534 \nRun 4 stress 0.1230331 \nRun 5 stress 0.1188257 \nRun 6 stress 0.1208973 \nRun 7 stress 0.1207018 \nRun 8 stress 0.1181117 \n... New best solution\n... Procrustes: rmse 1.728789e-05  max resid 5.144074e-05 \n... Similar to previous best\nRun 9 stress 0.1181116 \n... New best solution\n... Procrustes: rmse 4.843601e-05  max resid 0.0001439558 \n... Similar to previous best\nRun 10 stress 0.1188267 \nRun 11 stress 0.1181116 \n... Procrustes: rmse 9.483475e-05  max resid 0.0002783637 \n... Similar to previous best\nRun 12 stress 0.1188538 \nRun 13 stress 0.1181116 \n... Procrustes: rmse 0.000104247  max resid 0.0003014734 \n... Similar to previous best\nRun 14 stress 0.1181117 \n... Procrustes: rmse 8.306504e-05  max resid 0.0002417354 \n... Similar to previous best\nRun 15 stress 0.1181117 \n... Procrustes: rmse 4.608876e-05  max resid 0.0001336367 \n... Similar to previous best\nRun 16 stress 0.1188572 \nRun 17 stress 0.1188527 \nRun 18 stress 0.2076954 \nRun 19 stress 0.1181117 \n... Procrustes: rmse 6.38454e-05  max resid 0.0001867477 \n... Similar to previous best\nRun 20 stress 0.1208971 \n*** Best solution repeated 6 times\n\nplot(md, type=\"text\")\nabline(h=0, col=\"grey\", lty=\"dotted\")\nabline(v=0, col=\"grey\", lty=\"dotted\")\n\n\n\n\n\n\n5.3 Cluster analysis\nHere we apply a hierarchical cluster analysis with square root transformed data and two different agglomeration schemes, “complete linkage” and “Ward’s method”.\n\npar(mfrow=c(2,1))\nhc <- hclust(dist(scale(dat2)), method=\"complete\") # the default\nplot(hc)\n\nhc2 <- hclust(dist(scale(dat2)), method=\"ward.D2\")\nplot(hc2)\n\n\n\n\nWe can also use the clusters to indicate groups in the NMDS plot. Function rect.hclust indicates a given number of clusters in the dendrogram, then we cut the tree with cutree and use the groups grp as color codes. R has 8 standard colors. If we need more, we can define an own palette.\n\nplot(hc, hang = -1)\nrect.hclust(hc, 5)\n\n\n\ngrp <- cutree(hc, 5)\n# grp                  # can be used to show the groups\nplot(md, type = \"n\")\ntext(md$points, row.names(dat2), col = grp)\n\n\n\n\nInstead of hierarchical clustering, we can also use a non-hierarchical method, e.g. k-means clustering. This is an iterative method, and avoids the problem that cluster assignment depends on the order of clustering and the agglomeration method.\nDepending on the question, it may be a disadvantage, that the number of clusters needs to be specified beforehand (e.g. from hierarchical clustering) and that we do not get a tree diagramm."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#task",
    "href": "tutorials/s3-multivar-lakes.html#task",
    "title": "Multivariate Lake Data Example",
    "section": "6 Task",
    "text": "6 Task\n\nTry to understand the analysis,\ndiscuss the results,\nask questions.\nThe idea is to work on this report together and to make it more complete."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html",
    "href": "tutorials/s1-introductory-r-session.html",
    "title": "An Introductory R Session",
    "section": "",
    "text": "This tutorial is available in HTML format for screen reading and PDF for printing."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#program-start-and-help-system",
    "href": "tutorials/s1-introductory-r-session.html#program-start-and-help-system",
    "title": "An Introductory R Session",
    "section": "2.1 Program start and help system",
    "text": "2.1 Program start and help system\nThe easiest way to learn R is the creative understanding and modification of given examples, the usage of R for solving practical problems and the diagnosis of the frequently occurring problems and error messages. Don’t worry: error messages are a normal phenomenon in scientific computing and not an indication of a dysfunction of the computer or the human brain. The opposite is true, a certain amount of stress hormones helps to acquire permanent learning effects. Then, after a certain level of experience reading the official R-Documentation “An Introduction to R” (Venables et al., 2021). or any good R-book is strongly recommended.\nThe first sections of this “crash course” are intended to give an overview over some of the most important elements of R and an insight into a typical work flow, that may be useful for the first statistical analyses and as a starting point for self-education.\nWe begin our first session by starting RStudio, a platform independent interface that makes working with R easier. RStudio divides the screen into 3 (resp. 4) windows (called panes), where some of them have additional tabs to switch between different views.\n\nFigure 1: R Studio with 4 panes. Use File – New R Script to open the the source code pane (shown top left). Then enter some code and don’t forget to explore the help files.\nIn a fresh RStudio session, one “Pane” should be the main help page of R. It is a good idea to browse a little bit around to get an impression about the amount and the typical style of the available help topics. The most important sections are “An Introduction to R”, “Search Engine & Keywords”, “Packages”, the “Frequently Asked Questions” and possibly “R Data Import/Export”.\nWe start now to explore the R-System itself."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-as-a-pocket-calculator",
    "href": "tutorials/s1-introductory-r-session.html#r-as-a-pocket-calculator",
    "title": "An Introductory R Session",
    "section": "2.2 R as a pocket calculator",
    "text": "2.2 R as a pocket calculator\nEntering an arithmetic expression like this:\n\n2 + 4\n\nshows that R can be used as a pocket calculator, that immediately outputs the result:\n\n\n[1] 6\n\n\nInstead of printing the result to the screen, it is also possible to save the result into a named variable using the assignment operator “<-”.\n\na <- 2 + 4\n\nIt seems that nothing happens, but the result is now saved in the variable a that can be recalled at any time by entering the variable name alone:\n\na\n\nVariable names in R start always with a character (or for special purposes a dot), followed by further characters, numerals, dots or underscores, where a distinction is made between small and capital letters, i.e. the variables value, Value and VALUE can contain different data. A few character combinations are reserved words and cannot be used as variables:\nbreak, for, function, if, in, next, repeat, while and “...” (three dots).\nOther identifiers like plot can be re-defined, but this should be done with care to avoid unwanted confusion and side effects."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#vectors",
    "href": "tutorials/s1-introductory-r-session.html#vectors",
    "title": "An Introductory R Session",
    "section": "2.3 Vectors",
    "text": "2.3 Vectors\nYou may have noticed, that the output of the example above had a leading [1], which means that the line begins with the first element of a. This brings us to a very important feature of R that variables can contain more than single values: vectors, matrices, lists, data frames (tables) and so on.\nThe most basic data type is the vector, that can be filled with data using the c (combine) function:\n\nvalues <- c(2, 3, 5, 7, 8.3, 10)\nvalues\n\n[1]  2.0  3.0  5.0  7.0  8.3 10.0\n\n\nTo create a sequence of values, one can use the : (colon):\n\nx <- 1:10\nx\n\nor, even more flexibly the seq function:\n\nx <- seq(2, 4, 0.25)\nx\n\nSequences of repeated equal values can be obtained with rep:\n\nx <- rep(2, 4)\nx"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercise",
    "href": "tutorials/s1-introductory-r-session.html#exercise",
    "title": "An Introductory R Session",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\nThere are many ways to use these functions, try for example:\n\nseq(0, 10)\nseq(0, 10, by = 2)\nseq(0, pi, length = 12)\nrep(c(0, 1, 2, 4, 9), times = 5)\nrep(c(0, 1, 2, 4, 9), each = 2)\nrep(c(0, 1, 2, 4, 9), each = 2, times = 5)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#access-to-vector-elements",
    "href": "tutorials/s1-introductory-r-session.html#access-to-vector-elements",
    "title": "An Introductory R Session",
    "section": "2.5 Access to vector elements",
    "text": "2.5 Access to vector elements\nInstead of accessing vectors as a whole, it is also possible to extract single elements, where the index of the requested data is itself a vector:\n\nvalues[5]\nvalues[2:4]\nvalues[c(1, 3, 5)]\n\nSometimes, elements of a vector may have individual names, which makes it easy to access them:\n\nnamed <- c(a = 1, b = 2.3, c = 4.5)\nnamed\nnamed[\"a\"]\n\nIn R (and in contrast to other languages like C/C++) vector indices start with 1. Negative indices are also possible, but they have the special purpose to delete one or several elements:\n\nvalues[-3]\n\nIt is also possible to extend a given vector by preceding or appending values with the combine function (c):\n\nc(1, 1, values, 0, 0)\n\nThe length of a vector can be determined with:\n\nlength(values)\n\nand it is also possible to have empty vectors, i.e. vectors that exist, but do not contain any values. Here the keyword NULL means “nothing” in contrast to “0” (zero) that has length 1:\n\nvalues <- NULL\nvalues\nlength(values)\n\nSuch empty vectors are sometimes used as “containers” for appending data step by step:\n\nvalues <- NULL\nvalues\nlength(values)\nvalues <- c(values, 1)\nvalues\nvalues <- c(values, 1.34)\nvalues\n\nIf a data element should be removed completely, this can be done using the remove function:\nrm(values)\nvalues\nError: Object \"values\" not found\nThe complete workspace can be deleted from the menu of R or RStudio (Session – Clear workspace) or from the command line with rm (remove):\n\nrm(list = ls(all = TRUE))\n\nThe R session can be closed by using the menu as usual or by entering:\n\nq()\n\nSometimes and depending of the configuration, R asks whether the “R workspace” should be saved to the disk. This may be useful for continuing work at a later time, but has the risk to clutter the workspace and to get irreproducible results at a later session, so it is recommended to say “No” for now, except if you exactly know why.\nLater we will learn how to save only the data (and commands) that are needed."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-as-function-plotter",
    "href": "tutorials/s1-introductory-r-session.html#r-as-function-plotter",
    "title": "An Introductory R Session",
    "section": "3.1 R as function plotter",
    "text": "3.1 R as function plotter\nNow, we will see how to use R as a function plotter by drawing sine or cosine functions within an interval between 0 to 10. First, we create two vectors with x and y. To obtain a smooth curve, it is reasonable to choose a small step size. As a rule of thumb I always recommend to use about 100…400 small steps as a good compromise between smoothness and memory requirements, so let’s set the step size to 0.1:\n\nx <- seq(0, 10, 0.1)\ny <- sin(x)\nplot(x, y)\n\n\n\n\nInstead of plotting points, we can also draw continuous lines. This is indicated by supplying an optional argument type = \"l\".\nNote: the symbol used here for type is the small letter “L” for “line” and not the – in printing very similar – numeral “1” (one)!\nWe see also, that optional arguments like type can be given as “keyword = value” pair. This has the advantage that the order of arguments does not matter, because arguments are referenced by their name:\n\nplot(x, y, type = \"l\")\n\nNow we want to add a cosine function with another color. This can be done with one of the function lines or points, for adding lines or points to an existing figure:\n\ny1 <- cos(x)\nlines(x, y1, col = \"red\")\n\nWith the help of text it is also possible to add arbitrary text, by specifying first the x and y coordinates and then the text:\n\nx1 <- 1:10\ntext(x1, sin(x1), x1, col = \"green\")\n\nMany options exist to modify the behavior of most graphics functions so the following specifies user-defined coordinate limits (xlim, ylim), axis labels and a heading (xlab, ylab, main).\n\nplot(x, y, xlim = c(-10, 10), ylim = c(-2, 2),\n    xlab = \"x-Values\", ylab = \"y-Values\", main = \"Example Graphics\")\n\nCode formatting and line breaks\nThe above example shows a rather long command that may not fit on a single line. In such cases, R displays a + (plus sign) to indicate that a command must be continued, e.g. because a closing parenthesis or a closing quote is still missing. Such a + at the beginning of a line is an automatic “prompt” similar to the ordinary > prompt and must never be typed in manually. If, however, the + continuation prompt occurs by accident, press “ESC” to cancel this mode.\nIn contrast to the long line continuation prompt, it is also possible to write several commands on one line, separated by a semi-colon “;”. This is unseful in some cases, but as a general rule it is much better to use the script editor and then to:\n\nwrite each command to a separate line\navoid long lines with more than about 80 characters\nuse proper indentation, e.g. 2 characters per indentation level\nuse spacing to improve readability of the code, e.g. before and after the assignment operator <-.\n\nFinally, a number symbol (or hash) # means that a complete line or the part of the line that follows # is a comment and should be ignored by R."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#additional-plotting-options",
    "href": "tutorials/s1-introductory-r-session.html#additional-plotting-options",
    "title": "An Introductory R Session",
    "section": "3.2 Additional plotting options",
    "text": "3.2 Additional plotting options\nIn order to explore the wealth of graphical functions, you may now have a more extensive look into the online help, especially regarding ?plot or ?plot.default, and you should experiment a little bit with different plotting parameters, like lty, pch, lwd, type, log etc. R contains uncountable possibilities to get full control over the style and content of your graphics, e.g. with user-specified axes (axis), legends (legend) or user-defined lines and areas (abline, rect, polygon). The general style of figures like (font size, margins, line width) can be influenced with the par function."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#high-level-plotting-functions",
    "href": "tutorials/s1-introductory-r-session.html#high-level-plotting-functions",
    "title": "An Introductory R Session",
    "section": "3.3 High level plotting functions",
    "text": "3.3 High level plotting functions\nIn addition, R and its packages contain numerous “high level”-graphics functions for specific purposes. To demonstrate a few, we first generate a data set with normally distributed random numbers (mean = 0, standard deviation sd = 1), then we plot them and create a histogram. Here, the function par(mfrow = c(2, 2)) divides the plotting area into 2 rows and 2 columns to show 4 separate figures:\n\npar(mfrow = c(2, 2))\nx <- rnorm(100)\nplot(x)\nhist(x)\n\nNow, we add a so-called normal probability plot and a second histogram with relative frequencies together with the bell-shaped density curve of the standard normal distribution. The optional argument probability = TRUE makes sure that the histogram has the same scaling as the density function, so that both can be overlayed:\n\nqqnorm(x)\nqqline(x, col = \"red\")\nhist(x, probability = TRUE)\nxx <- seq(-3, 3, 0.1)\nlines(xx, dnorm(xx, 0, 1), col = \"red\")\n\n\n\n\n\n\n\nHere it may also be a good chance to do a little bit summary statistics like: z.B. mean(x), var(x), sd(x), range(x), summary(x), min(x), max(x), …\nOr we may consider to test if the generated random numbers x are approximately normal distributed using the Shapiro-Wilks-W-Test:\n\nx <- rnorm(100)\nshapiro.test(x)\n\nA p-value bigger than 0.05 tells us that the test has no objections against normal distribution of the data. The concrete results may differ, because x contains random numbers, so it makes sense to repeat this several times. It can be also useful compare these normally distributed random numbers generated with rnorm with uniformly distributed random numbers generated with runif:\n\npar(mfrow=c(2,2))\ny <- runif(100)\nplot(y)\nhist(y)\nqqnorm(y)\nqqline(y, col=\"red\")\nmean(y)\nvar(y)\nmin(y)\nmax(y)\nhist(y, probability=TRUE)\nyy <- seq(min(y), max(y), length = 50)\nlines(yy, dnorm(yy, mean(y), sd(y)), col = \"red\")\nshapiro.test(y)\n\nAt the end, we compare the pattern of both data sets with box-and-whisker plots:\n\npar(mfrow=c(1, 1))\nboxplot(x, y)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercises",
    "href": "tutorials/s1-introductory-r-session.html#exercises",
    "title": "An Introductory R Session",
    "section": "3.4 Exercises",
    "text": "3.4 Exercises\nRepeat this example with new random numbers and vary sample size (n), mean value (mean) and standard deviation (sd) for random numbers created with rnorm, and use different min and max for runif. Consult the help pages for an explanation of the functions and its arguments, and create boxplots with different data sets."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#numeric-and-character-vectors",
    "href": "tutorials/s1-introductory-r-session.html#numeric-and-character-vectors",
    "title": "An Introductory R Session",
    "section": "4.1 Numeric and character vectors",
    "text": "4.1 Numeric and character vectors\nAll data objects have the two built-in attributes mode (data type) and length (number of data in the object).\nModes can be “numeric” for calculations or “character” for text elements.\n\nx <- c(1, 3, 4, 5)       # numeric\na <- c(\"hello\", \"world\") # character\n\nThe following is also a character variable, because the numbers are given in quotes. It is then not possible to do calculations:\n\nx <- c(\"1\", \"3\", \"4\", \"5\")  # character\nsum(x)\n\nError in sum(x) : invalid 'type' (character) of argument\n\nHere it is necessary to convert the character to numeric first:\n\ny <- as.numeric(x)\nsum(y)\n\n[1] 9.040591"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#factors",
    "href": "tutorials/s1-introductory-r-session.html#factors",
    "title": "An Introductory R Session",
    "section": "4.2 Factors",
    "text": "4.2 Factors\nA special kind of mode is factor. This is, statistically speaking, a nominal variable that appears like characters, e.g. “control”, “treatment A”, “treatment B” …, but its levels are internally encoded as integer.\nHere a typical example with three factor levels. In a first step,let’s create a character variable:\n\ntext <- rep(c(\"control\", \"treatment A\", \"treatment B\"), each=5)\ntext\n\n [1] \"control\"     \"control\"     \"control\"     \"control\"     \"control\"    \n [6] \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\"\n[11] \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\"\n\n\nand then convert it to a factor:\n\nf <- factor(text)\nf\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: control treatment A treatment B\n\n\nWe se that the character variable is printed with quotes and the factor without quotes, but with an additional information about the Levels. The reason for this is, that the factor is internally encoded as integer values with assigned levels as a translation table:\n\nlevels(f)\n\n[1] \"control\"     \"treatment A\" \"treatment B\"\n\n\nTo show encoding, we can convert the factor into an integer\n\nas.integer(f)\n\n [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3\n\n\nThe encoding is done in alphabetical order by default. It can be changed by using an additional levels argument:\n\nf2 <- factor(text, levels=c(\"treatment A\", \"treatment B\", \"control\"))\nf2\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: treatment A treatment B control\n\nas.numeric(f2)\n\n [1] 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2\n\n\nFactors are useful for statistical analyses like ANOVA and statistical tests, and also as categories for plotting:\n\nx <- c(7.44, 6.45, 6.04, 5.58, 4.5, 8.13, 5.54, 7.34, 8.91, 5.16, 8.7, 7.74, 6.8, 6.49, 6.2)\nplot(x ~ f)\n\n\n\n\nWe see that a boxplot is created and no x-y-plot, because the explanation variable is a factor.\nNumeric variables (especially ordinal) can also be converted to factors. This is useful, if we want to make clear, that numbers are to be treated as name without order.\nHowever, conversion of such factors back into numeric variables types should be done with care, because a character “123” may be encoded with another value (e.g. 1) and not 123, see the following demonstration of a correct and wrong factor conversions:\n\nx <- c(2, 4, 6, 5, 8)\nf <- as.factor(x)\nas.numeric(f)               # wrong !!!\nas.numeric(as.character(f)) # correct\nas.numeric(levels(f))[f]    # even better\n\nSuch a factor coding is not specific to R and appears also in other statistics packages. Then they are sometimes called “dummy variables”."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#matrices-and-arrays",
    "href": "tutorials/s1-introductory-r-session.html#matrices-and-arrays",
    "title": "An Introductory R Session",
    "section": "4.3 Matrices and arrays",
    "text": "4.3 Matrices and arrays\nA matrix is a two-dimensional data structure that can be used for matrix algebra. To create a matrix, we can first create a one-dimensional vector and then reformat it as two-dimensional matrix with nrow rows and ncolcolumns:\n\nx <- 1:20\nx\n\ny <- matrix(x, nrow = 5, ncol = 4)\ny\n\nWe see that the matrix is filled rowwise. We can also convert it back to a vector:\n\nas.vector(y) # flattens the matrix to a vector\n\nAn array extends the matrix concept to more than two dimensions:\n\nx <- array(1:24, dim=c(3, 4, 2))\n\nVectors, matrices and arrays have an important limitation: they can only contain one data type (mode), either numeric or character. So, if a single element is of type character, the whole matrix will be of mode character and appears in quotes:\n\nx <- c(1, 2, 5, 2, \"a\")\nmode(x)\nx"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#lists",
    "href": "tutorials/s1-introductory-r-session.html#lists",
    "title": "An Introductory R Session",
    "section": "4.4 Lists",
    "text": "4.4 Lists\nThe most flexible data type of R is the list. It can contain arbitrary data of different modes. Lists can be nested to form a tree-like structure:\n\nl <- list(x = 1:3, y = c(1,2,3,4), a = \"hello\", L = list(x = 1, y = 2))\n\nLists are extremely powerful and flexible and may be discussed later. The impatient may have a look at the tutorial of w3schools.com."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#data-frames",
    "href": "tutorials/s1-introductory-r-session.html#data-frames",
    "title": "An Introductory R Session",
    "section": "4.5 Data frames",
    "text": "4.5 Data frames\nThe typical data structure for data analysis in R is the so-called data.frame. It can contain both, columns with numeric data and columns of mode character. Some packages use ando extended versions of data frames, a so called tibbles.\nA data frame can be constructed from scratch directly in the R code or read from a file or the internet. As an example, students were asked in different years for their favorite number from one to 9. The results can be put in a data frame like follows:\n\nfavnum <- data.frame(\n  favorite = 1:9,\n  obs2019  = c(1, 1, 6, 2, 2,  5,  8, 6, 3),\n  obs2020  = c(1, 2, 8, 1, 2,  2, 20, 2, 4),\n  obs2021  = c(2, 6, 8, 1, 6,  4, 13, 2, 4),\n  obs2022  = c(2, 3, 7, 8, 2, 10, 12, 6, 1)\n)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#direct-input",
    "href": "tutorials/s1-introductory-r-session.html#direct-input",
    "title": "An Introductory R Session",
    "section": "5.1 Direct input",
    "text": "5.1 Direct input\nWe used this method already when creating vectors with the c (combine)-Function:\n\nx <- c(1, 2, 5, 7, 3, 4, 5, 8)\nx\n\nIn the same way it is possible to create other data types like data frames:\n\ndat <- data.frame(f = c(\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"),\n                  x = c(1,   4,   3,   3,   5,   7)\n       )\ndat\n\nor matrices:\n\nA <- matrix(c(1:9), nrow=3)\nA\n\nWe see that a matrix is not much different from a vector, formatted into rows and columns."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#read-data-from-a-text-file",
    "href": "tutorials/s1-introductory-r-session.html#read-data-from-a-text-file",
    "title": "An Introductory R Session",
    "section": "5.2 Read data from a text file",
    "text": "5.2 Read data from a text file\nR has very flexible functions to read data from text files. Let’s for example use a table that contains some data from a lake area in north-eastern Germany (Table 1).\nTable 1: Morphometrical and chemical properties of selected lakes (S=Stechlinsee, NN=Nehmitzsee Nord, NS=Nehmitzsee Süd, BL=Breiter Luzin, SL = Schmaler Luzin, DA = Dagowsee, HS = Feldberger Haussee; z=mean depth (m), t=theoretical retention time (a), P=phosphorus concentration (\\(\\mathrm{\\mu g L^{-1}}\\)), N=nitrogen concentration (\\(\\mathrm{mg L{^-1}}\\)), Chl=chlorophyll concentration (\\(\\mathrm{\\mu g L^{-1}}\\)), PP=annual primary production (\\(\\mathrm{g C m^{-2} a^{-1}}\\)), SD = secchi depth (m)). The data are an adapted and simplified “toy version” taken from Casper (1985) and Koschel & Scheffler (1985).\n\n\n\n\n\nLake\nz\nt\nP\nN\nChl\nPP\nSD\n\n\n\n\nS\n23.7\n40\n2.5\n0.20\n0.7\n95\n8.4\n\n\nNN\n5.9\n10\n2.0\n0.20\n1.1\n140\n7.4\n\n\nNS\n7.1\n10\n2.5\n0.10\n0.9\n145\n6.5\n\n\nBL\n25.2\n17\n50.0\n0.10\n6.1\n210\n3.8\n\n\nSL\n7.8\n2\n30.0\n0.10\n4.7\n200\n3.7\n\n\nDA\n5.0\n4\n100.0\n0.50\n14.9\n250\n1.9\n\n\nHS\n6.3\n4\n1150.0\n0.75\n17.5\n420\n1.6\n\n\n\n\n\nThe data can be downloaded from https://github.com/tpetzoldt/datasets/tree/main/data\n\n5.2.1 Set working directory\nR needs to know where to find the data on your computer. One way is to provide the full path to the data set, e.g. if it is c:/users/<username>/documents, then\n\nlakes <- read.csv(\"c:/users/julia/documents/lakes.csv\")\n\nThis can be cumbersome and error-prone, so the preferred method is to set the working directory of R to the data directory. This can be done in RStudio like follows:\n\nLocate the folder with the data in the “Files” pane\nSelect “More”\nSelect “Set As Working Directory”\n\n Figure2: Setting the working directory in RStudio\nAfter this, data can be retrieved directly from the working directory :\n\nlakes <- read.csv(\"lakes.csv\", header=TRUE)\n\nWe may also consider to create a sub-folder data of the working direktory and put the data in. Then we could use for example:\n\nlakes <- read.csv(\"../data/lakes.csv\", header=TRUE)\n\nNote also that we use always the ordinary slash “/” and not the backslash “\\”, even on Windows.\nIn some countries that have the comma and not the dot as a decimal separator and then for example a semicolon as column separator, additional arguments dec = \",\", sep=\";\" may be required. The details are found on the read.table help page."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#read-data-from-the-internet",
    "href": "tutorials/s1-introductory-r-session.html#read-data-from-the-internet",
    "title": "An Introductory R Session",
    "section": "5.3 Read data from the internet",
    "text": "5.3 Read data from the internet\nIf the data are available on an internet server, it can be read directly from there:\n\nlakes <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/lakes.csv\")\n\nNow, as the data are saved in the data frame lakes it is possible to access them as usual:\n\nlakes\nsummary(lakes)\nboxplot(lakes[-1])\n\nHere summary shows a quick overview and boxplot creates a boxplot for all columns except the first, that contains no numbers.\nNow, we are ready to inspect the content of this new variable lakes. If we use RStudio a View can be invoked by clicking to lakes in the environment window."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#import-dataset-in-rstudio",
    "href": "tutorials/s1-introductory-r-session.html#import-dataset-in-rstudio",
    "title": "An Introductory R Session",
    "section": "5.4 “Import Dataset” in RStudio",
    "text": "5.4 “Import Dataset” in RStudio\nRStudio contains a handy feature that makes importing of data more convenient. Essentially, this “Import Dataset” wizard helps us to construct the correct read.table, read.csv or read_delim function interactively. It is possible to try different options until a satisfying result is obtained. Current versions of RStudio contain several different ways to import data. Here we demonstrate the “Import Dataset From Text (readr)” assistant:\n\nFrom the menu select: File – Import DataSet – From CSV.\nSelect the requested file and select suitable options like the name of the variable the data are to be assigned to, the delimiter character (comma or Tab) and whether the first row of the file contains variable names.\n\n\nImport Dataset From Text (readr) assistant of RStudio.\nHint: In the exmple above, the name of the data frame is identical to the file name, i.e. “lakes”. If we want to name it differently (e.g.: dat), we must not forget to change this setting.\nNote also that the Code Preview contains the commands that the wizard created. If we copy these commands to the script pane, you can re-read the data several times without going back to the menu system:\n\nlibrary(readr)\nlakes <- read_csv(\"D:/DATA/lakes.csv\")\nView(lakes)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#display-the-content-of-the-data-frame",
    "href": "tutorials/s1-introductory-r-session.html#display-the-content-of-the-data-frame",
    "title": "An Introductory R Session",
    "section": "6.1 Display the content of the data frame",
    "text": "6.1 Display the content of the data frame\nThe easiest way is to just enter the name of the data frame to the R console, e.g.:\n\nlakes\n\nor to click to the name of the data frame in the “Environment” explorer of RStudio. This executes then View(lakes), so that the data are shown.\nFor large tables it is often not very useful to display the full content with View, so it may be better to use the function str (structure) that gives a compact overview over type, size and content of a variable:\n\nstr(mydata)\n\nThe str function is universal and also suitable for complicated object types like lists. Of course, there are many more possibilities for inspecting the content of a variable:\n\nnames(lakes)\nmode(lakes)\nlength(lakes)\n\nand sometimes even:\n\nplot(lakes)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#access-single-columns-with",
    "href": "tutorials/s1-introductory-r-session.html#access-single-columns-with",
    "title": "An Introductory R Session",
    "section": "6.2 Access single columns with $",
    "text": "6.2 Access single columns with $\nSingle columns of a data frame can be accessed by using indices (with []) similar to a vector or a matrix or by using the column name and the $) operator:\n\nmean(lakes[,2])\nmean(lakes$z)\nmean(lakes[,\"z\"])\nmean(lakes[[\"z\"]])\nplot(lakes$z, lakes$t)\n\nwhere z is the mean depth of the lakes and t the so-called mean residence time.\nWe should also nitice the subtle difference of the output of the [] and the [[]]- version. The difference is as follows: single brackets return a data frame with one column, but double square brackets return the content of the column as a vector without the caption.\nWarning: In some older books, the $-style is sometimes abbreviated using the attach and detach-functions. This “prehistoric relict” is strongly discouraged, as it can lead to data inconsistency and strange errors. If you find it somewhere where it is still used, then it is a good idea to use detach repeatedly until an error message confirms us that there is nothing else that can be detached. Finally: never use attach/detach in a package.\nInstead, it is much better to use another function width, that opens the data frame only temporarily:\n\nwith(lakes, plot(z, t))"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#subsets-and-logical-indices",
    "href": "tutorials/s1-introductory-r-session.html#subsets-and-logical-indices",
    "title": "An Introductory R Session",
    "section": "6.3 Subsets and logical indices",
    "text": "6.3 Subsets and logical indices\nIn the following, we use another data set that we read directly from the internet:\n\nfruits <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/clementines.csv\")\n\nIt contains weight, width and height measurements of two brands of Clementine fruits. After loading the data, we look at it with View(fruits) or the Environment explorer of Rstudio\nA very powerful feature of R is the use of logical vectors as “indices”, with similar results like data base queries. As an example, we can show the weight of all fruits of brand “A” with\n\nfruits[fruits$brand == \"A\", c(\"brand\", \"weight\")]\n\n   brand weight\n6      A     81\n7      A    113\n8      A     94\n9      A     86\n10     A    108\n11     A     91\n12     A     94\n13     A     86\n14     A     91\n15     A     88\n\n\nHere the first indext in the square brackets indicates the subset of rows that we want and the second argument the columns. If we want to see all columns, we leave the argument after the comma empty:\n\nfruits[fruits$brand == \"A\", ]\n\n   id no brand weight width height\n6   6  7     A     81    53     54\n7   7  8     A    113    61     60\n8   8  9     A     94    62     49\n9   9  3     A     86    58     53\n10 10  6     A    108    64     50\n11 11  1     A     91    59     51\n12 12 10     A     94    59     51\n13 13  4     A     86    55     55\n14 14  2     A     91    61     51\n15 15  5     A     88    54     55\n\n\nA logical comparison requires always a double “==”. Logical operations like & (and) and | (or) are also possible. Note that “and” has always precedence before “or”, except this is changed with parenthesis.\nA subset of a data frame can also be extracted with the subset function:\n\nbrand_B <- subset(fruits, brand == \"B\")\nbrand_B\n\nLike in the example before, the condition argument allows also logical expressions with & (and) and | (or).\nWe can also access single elements in matrix-like manner.\nThe element from the 2nd row and the 4th column can be selected with:\n\nfruits[2, 4]\n\nthe complete 5th row with:\n\nfruits[5, ]\n\nand rows 5:10 of the 4th column (weight) with:\n\nfruits[5:10, 4]\n\nAdditional methods for working with matrices, data frames and lists can be found in R textbooks or in the official R documentation."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#pipelines-and-summaries",
    "href": "tutorials/s1-introductory-r-session.html#pipelines-and-summaries",
    "title": "An Introductory R Session",
    "section": "7.1 Pipelines and summaries",
    "text": "7.1 Pipelines and summaries\nThe last examples are intended to demonstrate how powerful a single line can be in R. How to analyse data sets evolved over the history of R, so there is for example a function aggregate to compute statistics (e.g. mean values) depending on given criteria.\nThis works well and is still used, but the modern methods are more compact and easier to understand. Here let’s introduce a modern concept first, that is called “pipelining”. The idea is, that the result of a function is directly pipelined to another function, so instead of writing:\n\nbrand_B <- subset(fruits, brand == \"B\")\ncolumns_B <- brand_B[c(\"weight\", \"width\", \"height\")]\nmeans_B <- colMeans(columns_B)\nmeans_B\n\nwe can directly write:\n\nlibrary(\"dplyr\")\nfruits |> filter(brand == \"B\") |> select(weight, width, height) |> colMeans()\n\nHere we load an add-on package dplyr first, that contains a lot of helpful functions for data management, for example filter that selects rows and select that selects columns. The pipeline operator |> pipes then the data set fruitsto the filter- function and subsequently to the next. The “native pipeline operator” |> was introduced with R 4.1. As an alternative we can also use the %>% pipeline operator, that is loaded by the dplyr package. Its function would be identical in this case.\nTwo other extremely useful dplyr functions are group_by and summary, that allow to calculate arbitrary summary statistics in dependence of grouping variables. If we use the brand for grouping, we can summarize all groups simultaneously:\n\nfruits |> \n  group_by(brand) |>\n  summarise(mean(weight), mean(width), mean(height))\n\nThe summarize line above can still be made better, and there plenty of other stunning possibilities, so we will come back to this later."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#output-of-results",
    "href": "tutorials/s1-introductory-r-session.html#output-of-results",
    "title": "An Introductory R Session",
    "section": "7.2 Output of Results",
    "text": "7.2 Output of Results\nThe most simple method to save outputs from R is to copy it directly from the R console to any other program (e.g. LibreOffice, Microsoft Word or Powerpoint) via the Clipboard. This is convenient, but cannot be automated. Therefore, it is better to use a programmatic approach.\nLet’s use the example before and store the results in a new data frame results:\n\nresults <-\n  fruits |> \n  group_by(brand) |>\n  summarise(mean(weight), mean(width), mean(height))\n\nData frames can be saved as text files with write.table, write.csv or write_csv. Here we use write_csv (with underscore, not dot) from package readr:\n\nlibrary(\"readr\")\nwrite_csv(results, file=\"output-data.csv\")\n\nIn addition to these basic functions R has a wealth of possibilities to save output and data for later use in reports and presentations. All of them are of course documented in the online help, e.g. print, print.table, cat for text files, and pdf, png for figures. The add-on packages xtable contains functions for creating LaTeX or HTML-tables while full HTML output is supported by the R2HTML or knitr packages."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#plots-with-ggplot2",
    "href": "tutorials/s1-introductory-r-session.html#plots-with-ggplot2",
    "title": "An Introductory R Session",
    "section": "7.3 Plots with ggplot2",
    "text": "7.3 Plots with ggplot2\nIn addition to the plot functions we used so far, other plot packages exist, for example lattice or ggplot2. Here a few small examples with the very popular **ggplot2* package:\n\nlibrary(\"ggplot2\")\nfruits |>\n  ggplot(aes(brand, weight)) + geom_boxplot()\n\n\n\n\nOr a scatterplot to compare weight and width of the fruits\n\nfruits |> ggplot(aes(weight, width)) + geom_point(aes(color=brand))\n\n\n\n\nwhere the brand is indicated as color. Another option could be:\n\nfruits |> ggplot(aes(weight, width)) + \n  geom_point() + \n  geom_smooth(method=\"lm\") + \n  facet_grid(~brand)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercises-1",
    "href": "tutorials/s1-introductory-r-session.html#exercises-1",
    "title": "An Introductory R Session",
    "section": "7.4 Exercises",
    "text": "7.4 Exercises\nR contains lots of data sets for exploring its graphical and statistical functions and that can be activated by using the data function, e.g. data(iris) or data(cars). A description of the data set can be found as usual in the help files, e.g. ?iris, ?cars.\nUse one of these data sets and try\n\nways to access columns, to select rows and to create subsets\nways for summary statistics and visualization with R’s base plot functions and optionally with ggplot."
  },
  {
    "objectID": "slides/10-multivariate-1.html#data-sets-and-terms-of-use",
    "href": "slides/10-multivariate-1.html#data-sets-and-terms-of-use",
    "title": "10-Multivariate methods I",
    "section": "Data sets and terms of use",
    "text": "Data sets and terms of use\n\n\nThe “UBA-lakes” data set originates from the public data repository of the German Umweltbundesamt (Umweltbundesamt, 2021). The data set provided can be used freely according to the terms and conditions published at the UBA web site, that refer to § 12a EGovG with respect of the data, and to the Creative Commons CC-BY ND International License 4.0 with respect to other objects directly created by UBA.\nThe “gauernitz” data set contains simplified teaching versions from research data, of the study from Winkelmann et al. (2011)\nThe document itself, the codes and the ebedded images are own work and can be shared according to CC BY 4.0."
  },
  {
    "objectID": "slides/10-multivariate-1.html#an-introductory-example",
    "href": "slides/10-multivariate-1.html#an-introductory-example",
    "title": "10-Multivariate methods I",
    "section": "An introductory example",
    "text": "An introductory example"
  },
  {
    "objectID": "slides/10-multivariate-1.html#correlation-between-all-variables",
    "href": "slides/10-multivariate-1.html#correlation-between-all-variables",
    "title": "10-Multivariate methods I",
    "section": "Correlation between all variables?",
    "text": "Correlation between all variables?\n\nlibrary(\"readxl\") # read Excel files directly\nlakes <- as.data.frame(\n  read_excel(\"../data/uba/3_tab_kenndaten-ausgew-seen-d_2021-04-08.xlsx\", sheet=\"Tabelle1\", skip=3)\n)\nnames(lakes) <- c(\"name\", \"state\", \"drainage\", \"population\", \"altitude\", \n                  \"z_mean\", \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                  \"shore_devel\", \"drain_ratio\", \"wfd_type\")\nstr(lakes)\n\n'data.frame':   56 obs. of  14 variables:\n $ name        : chr  \"Ammersee\" \"Arendsee\" \"Bleilochtalsperre\" \"Bodensee\" ...\n $ state       : chr  \"BY\" \"ST\" \"TH\" \"BW\" ...\n $ drainage    : num  993 29.8 1239.9 11477 28.2 ...\n $ population  : num  114900 3200 180000 1400000 28 ...\n $ altitude    : num  532.9 22.8 404 395.4 13.1 ...\n $ z_mean      : num  37.6 28.6 23.3 85 2.4 ...\n $ z_max       : num  81.1 48.7 55 254 4.8 58.3 32.5 73.4 1.7 18.8 ...\n $ t_ret       : num  2.7 50 0.526 4.2 1.9 16.3 NA 1.26 0.1 2.3 ...\n $ volume      : num  1.75 0.147 0.215 48.522 0.009 ...\n $ area        : num  46.6 5.14 9.2 571.5 3.9 ...\n $ shore_length: num  43 9 NA 273 10.4 13.7 17.5 64 7.5 10.1 ...\n $ shore_devel : num  1.78 1.12 NA 2.26 1.48 2.09 1.64 2.02 2.22 1.6 ...\n $ drain_ratio : num  20.3 5.8 NA 21.9 7.2 ...\n $ wfd_type    : chr  \"Typ 4\" \"Typ 13\" \"Typ 5\" \"Typ 4\" ...\n\n\n\nnames(lakes) replaces the original German column names by abbreviated English abbreviations"
  },
  {
    "objectID": "slides/10-multivariate-1.html#create-pairwise-scatter-plots-for-all-variables",
    "href": "slides/10-multivariate-1.html#create-pairwise-scatter-plots-for-all-variables",
    "title": "10-Multivariate methods I",
    "section": "Create pairwise scatter plots for all variables?",
    "text": "Create pairwise scatter plots for all variables?\n\nplot(lakes)"
  },
  {
    "objectID": "slides/10-multivariate-1.html#create-pairwise-scatter-plots-for-all-variables-1",
    "href": "slides/10-multivariate-1.html#create-pairwise-scatter-plots-for-all-variables-1",
    "title": "10-Multivariate methods I",
    "section": "Create pairwise scatter plots for all variables?",
    "text": "Create pairwise scatter plots for all variables?\n\n\nnot a good idea, 14 variables would produce 182 (or 91) plots\ncan lead to “statistical fishing”\nwe need methods to extract the main information with a small number of plots"
  },
  {
    "objectID": "slides/10-multivariate-1.html#the-multivariate-approach",
    "href": "slides/10-multivariate-1.html#the-multivariate-approach",
    "title": "10-Multivariate methods I",
    "section": "The multivariate approach",
    "text": "The multivariate approach\n\nWork with the complete original variables directly\n\n\\(\\rightarrow\\) Multivariate statistics\n\ndependent variables + explanation variables optional\nanalyze distance and location in multidimensional space\nfind way to vizualize relationship in lower dimensions\n\n\nFor comparison\n\nunivariate: 1 variable\nbivariate: 1 dependent, 1 independent variable\nmultiple: 1 dependent, >1 independent variables"
  },
  {
    "objectID": "slides/10-multivariate-1.html#two-approches-of-multivariate-statistics",
    "href": "slides/10-multivariate-1.html#two-approches-of-multivariate-statistics",
    "title": "10-Multivariate methods I",
    "section": "Two approches of multivariate statistics",
    "text": "Two approches of multivariate statistics\n\n\n\n\nOrdination\n\n\n\n\n\n\ndimension reduction\nrelate observations and variables\n\n\n\nCluster analysis\n\n\n\n\n\n\ndistance and similarity\nidentification of groups"
  },
  {
    "objectID": "slides/10-multivariate-1.html#basic-concepts",
    "href": "slides/10-multivariate-1.html#basic-concepts",
    "title": "10-Multivariate methods I",
    "section": "Basic concepts",
    "text": "Basic concepts\n\nSimilarity and correlation\n\ndistance and similarity: \\(\\rightarrow\\) How different or similar are the observations?\ncorrelation and covariance: \\(\\rightarrow\\) Are variables interdependent?\ndimension reduction: \\(\\rightarrow\\) Try to show essential parts of information on a lower number of dimensions.\ncluster analysis: \\(\\rightarrow\\) Show which observations are closely together.\nordination: \\(\\rightarrow\\) Plot data at lower dimensions, similar observations closely together."
  },
  {
    "objectID": "slides/10-multivariate-1.html#a-data-set-from-german-lakes",
    "href": "slides/10-multivariate-1.html#a-data-set-from-german-lakes",
    "title": "10-Multivariate methods I",
    "section": "A data set from German lakes",
    "text": "A data set from German lakes"
  },
  {
    "objectID": "slides/10-multivariate-1.html#example-a-simplified-subset-from-the-uba-lake-data",
    "href": "slides/10-multivariate-1.html#example-a-simplified-subset-from-the-uba-lake-data",
    "title": "10-Multivariate methods I",
    "section": "Example: A simplified subset from the UBA lake data",
    "text": "Example: A simplified subset from the UBA lake data\n\n\n\n\n\n\n\n\n \n  \n      \n    name \n    shortname \n    z_mean \n    z_max \n    t_ret \n    volume \n    area \n    p_tot \n    n_no3 \n    chl \n    wfd_type \n  \n \n\n  \n    Ammer \n    Ammersee \n    Ammer \n    37.60 \n    81.1 \n    2.70 \n    1.75000 \n    46.600 \n    7.3 \n    1.09 \n    2.80 \n    Typ 4 \n  \n  \n    Arend \n    Arendsee \n    Arend \n    28.60 \n    48.7 \n    50.00 \n    0.14700 \n    5.140 \n    375.0 \n    0.05 \n    22.30 \n    Typ 13 \n  \n  \n    Boden \n    Bodensee \n    Boden \n    85.00 \n    254.0 \n    4.20 \n    48.52150 \n    571.500 \n    6.9 \n    0.84 \n    2.10 \n    Typ 4 \n  \n  \n    Chiem \n    Chiemsee \n    Chiem \n    25.60 \n    73.4 \n    1.26 \n    2.04800 \n    79.900 \n    9.2 \n    0.55 \n    3.80 \n    Typ 4 \n  \n  \n    Dober \n    Dobersdorfer See \n    Dober \n    5.40 \n    18.8 \n    2.30 \n    0.01690 \n    3.120 \n    63.9 \n    0.64 \n    27.30 \n    Typ 14 \n  \n  \n    Muegg \n    Großer Müggelsee \n    Muegg \n    4.85 \n    7.5 \n    0.20 \n    0.03500 \n    7.200 \n    189.9 \n    0.17 \n    32.90 \n    Typ 11 \n  \n  \n    Ploen \n    Großer Plöner See \n    Ploen \n    12.40 \n    58.0 \n    3.10 \n    0.37200 \n    29.970 \n    62.3 \n    0.22 \n    8.80 \n    Typ 13 \n  \n  \n    Kumme \n    Kummerower See \n    Kumme \n    8.10 \n    23.3 \n    1.50 \n    0.26300 \n    32.500 \n    65.3 \n    0.78 \n    16.60 \n    Typ 11 \n  \n  \n    Mueritz \n    Müritz (Außenmüritz) \n    Mueritz \n    6.50 \n    28.1 \n    6.00 \n    0.68000 \n    105.300 \n    19.7 \n    0.11 \n    6.30 \n    Typ 14 \n  \n  \n    MuerB \n    Müritz (Binnenmüritz) \n    MuerB \n    9.80 \n    30.3 \n    6.00 \n    0.03800 \n    3.910 \n    34.2 \n    0.11 \n    6.70 \n    Typ 10 \n  \n  \n    Plaue \n    Plauer See \n    Plaue \n    6.80 \n    25.5 \n    3.00 \n    0.30000 \n    38.400 \n    26.0 \n    0.09 \n    6.80 \n    Typ 10 \n  \n  \n    Sacro \n    Sacrower See \n    Sacro \n    18.01 \n    36.0 \n    15.00 \n    0.01930 \n    1.072 \n    79.8 \n    0.04 \n    8.60 \n    Typ 10 \n  \n  \n    Schar \n    Scharmützelsee \n    Schar \n    9.00 \n    29.5 \n    16.00 \n    0.10823 \n    12.090 \n    35.3 \n    0.12 \n    10.40 \n    Typ 13 \n  \n  \n    SchwA \n    Schweriner See (Außensee) \n    SchwA \n    9.40 \n    52.4 \n    10.00 \n    0.33100 \n    35.200 \n    100.0 \n    0.23 \n    11.70 \n    Typ 13 \n  \n  \n    SchwI \n    Schweriner See (Innensee) \n    SchwI \n    13.50 \n    44.6 \n    5.30 \n    0.35600 \n    26.400 \n    246.5 \n    0.19 \n    5.86 \n    Typ 13 \n  \n  \n    Starn \n    Starnberger See \n    Starn \n    53.20 \n    127.8 \n    21.00 \n    2.99900 \n    56.400 \n    5.9 \n    0.32 \n    1.84 \n    Typ 3 \n  \n  \n    Stech \n    Stechlinsee \n    Stech \n    22.80 \n    68.0 \n    32.00 \n    0.09700 \n    4.250 \n    15.8 \n    0.04 \n    2.60 \n    Typ 13 \n  \n  \n    Stein \n    Steinhuder Meer \n    Stein \n    1.35 \n    2.9 \n    2.30 \n    0.04200 \n    29.100 \n    53.3 \n    0.12 \n    29.00 \n    Typ 11 \n  \n\n\n\n\n\nmean and maximum depth (m): z_mean, z_max; retention time (years): t_ret; volume (10^9 m^3); area (km^2), total phosphorus P (µg/L): p_tot; nitrogen-N (mg/L): n_no3, chlorophyll (µg/L): chl, water framework directive lake type: wfd_type \n\n\nData set from UBA = Umweltbundesamt = German Federal Environmental Agency"
  },
  {
    "objectID": "slides/10-multivariate-1.html#code-to-read-the-data",
    "href": "slides/10-multivariate-1.html#code-to-read-the-data",
    "title": "10-Multivariate methods I",
    "section": "Code to read the data",
    "text": "Code to read the data\n\nlakes <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/elements/main/data/uba/lakes-combined-data.csv\")\nvalid_columns <- c(\"name\", \"shortname\", \"z_mean\", \"z_max\",  \"t_ret\", \"volume\", \n  \"area\", \"p_tot\", \"n_no3\", \"chl\", \"wfd_type\")\nlakes <- lakes[valid_columns] |> na.omit()\nrow.names(lakes) <- lakes$shortname\n\nlake_ids <- lakes[c(\"name\", \"shortname\")]\nlakedata <- lakes[, -c(1, 2)]\n\n## remove wfd_type for now\nlakedata$wfd_type <- NULL\n\n\nData files downloadable from https://github.com/tpetzoldt/elements/tree/main/data/uba\nSource of original data: Uwweltbundesamt https://www.uba.de\nTerms of use, see: Copyright and description of derived data"
  },
  {
    "objectID": "slides/10-multivariate-1.html#data-transformation-and-normalization",
    "href": "slides/10-multivariate-1.html#data-transformation-and-normalization",
    "title": "10-Multivariate methods I",
    "section": "Data transformation and normalization",
    "text": "Data transformation and normalization\n\npar(mfrow = c(1, 4), mar = c(6, 4, 3, 1), las = 2)\nboxplot(lakedata, main = \"raw data\")\nboxplot(scale(lakedata), main = \"normalized\")\nboxplot(scale(sqrt(lakedata)), main = \"sqrt + normalized\")\nboxplot(scale(log(lakedata)), main = \"log + normalized\")\n\n\n\nscale() performs normalisation (z-transformation)\naim: make different scales better comparable"
  },
  {
    "objectID": "slides/10-multivariate-1.html#principal-component-analysis-pca",
    "href": "slides/10-multivariate-1.html#principal-component-analysis-pca",
    "title": "10-Multivariate methods I",
    "section": "Principal Component Analysis: PCA",
    "text": "Principal Component Analysis: PCA\n\n\nidentify cvovariance or correlation structure\nrotate coordinate system, so that it points in the diretions of maximum variance\n\\(k\\) dimensions in original space are transformed into \\(k\\) orthogonal (rectangular) coordinates in principal components space.\nworks with any number of dimensions\nvisualisation by a 3D example"
  },
  {
    "objectID": "slides/10-multivariate-1.html#correlation-structure-of-the-lakes-data-set",
    "href": "slides/10-multivariate-1.html#correlation-structure-of-the-lakes-data-set",
    "title": "10-Multivariate methods I",
    "section": "Correlation structure of the lakes data set",
    "text": "Correlation structure of the lakes data set\n\n\n\nround(cor(lakedata), 2)\n\n       z_mean z_max t_ret volume  area p_tot n_no3   chl\nz_mean   1.00  0.97  0.20   0.81  0.78 -0.17  0.48 -0.49\nz_max    0.97  1.00  0.07   0.88  0.87 -0.26  0.47 -0.54\nt_ret    0.20  0.07  1.00  -0.12 -0.18  0.48 -0.41 -0.04\nvolume   0.81  0.88 -0.12   1.00  0.98 -0.20  0.44 -0.27\narea     0.78  0.87 -0.18   0.98  1.00 -0.26  0.45 -0.32\np_tot   -0.17 -0.26  0.48  -0.20 -0.26  1.00 -0.32  0.47\nn_no3    0.48  0.47 -0.41   0.44  0.45 -0.32  1.00 -0.15\nchl     -0.49 -0.54 -0.04  -0.27 -0.32  0.47 -0.15  1.00\n\n\n\n\n\nLet’s pick 3 variables for a 3D visualization: z_mix, z_max and volume.\nUse log-transformation to make them symetrically distributed."
  },
  {
    "objectID": "slides/10-multivariate-1.html#z_mix-z_max-and-volume-are-highly-corelated",
    "href": "slides/10-multivariate-1.html#z_mix-z_max-and-volume-are-highly-corelated",
    "title": "10-Multivariate methods I",
    "section": "z_mix, z_max and volume are highly corelated",
    "text": "z_mix, z_max and volume are highly corelated\n\n\n\n\n\\(\\rightarrow\\) We see that the three variables carry redundant information."
  },
  {
    "objectID": "slides/10-multivariate-1.html#how-rotation-of-axes-works",
    "href": "slides/10-multivariate-1.html#how-rotation-of-axes-works",
    "title": "10-Multivariate methods I",
    "section": "How rotation of axes works",
    "text": "How rotation of axes works\n\nOriginal coordinates\n\n\n\n\n\n\n\n\n\nPCA rotated coordinates\n\n\n\n\n\n\n\n\n\n\nThis slide contains interactive 3D graphics, that can be rotated with the mouse.\nRotate the left image, so that the points on both size show similar patterns.\nRotate the right image to show PC 3\n\n\\(\\rightarrow\\) Most of the 3D information of the data can be vizualized in 2D.\nNote: log-transformed variables were used in this example."
  },
  {
    "objectID": "slides/10-multivariate-1.html#pca-is-an-orthogonal-model-ii-regression",
    "href": "slides/10-multivariate-1.html#pca-is-an-orthogonal-model-ii-regression",
    "title": "10-Multivariate methods I",
    "section": "PCA is an orthogonal (model II) regression",
    "text": "PCA is an orthogonal (model II) regression\n\n\n\nPC1, PC2, PC3 are the principal components\nOLS is ordinary least squares regression (linear model lm)"
  },
  {
    "objectID": "slides/10-multivariate-1.html#now-analyse-all-numeric-variables",
    "href": "slides/10-multivariate-1.html#now-analyse-all-numeric-variables",
    "title": "10-Multivariate methods I",
    "section": "Now analyse all numeric variables",
    "text": "Now analyse all numeric variables\n\n\n\n\n\n \n  \n      \n    name \n    shortname \n    z_mean \n    z_max \n    t_ret \n    volume \n    area \n    p_tot \n    n_no3 \n    chl \n  \n \n\n  \n    Ammer \n    Ammersee \n    Ammer \n    37.60 \n    81.1 \n    2.70 \n    1.75000 \n    46.600 \n    7.3 \n    1.09 \n    2.80 \n  \n  \n    Arend \n    Arendsee \n    Arend \n    28.60 \n    48.7 \n    50.00 \n    0.14700 \n    5.140 \n    375.0 \n    0.05 \n    22.30 \n  \n  \n    Boden \n    Bodensee \n    Boden \n    85.00 \n    254.0 \n    4.20 \n    48.52150 \n    571.500 \n    6.9 \n    0.84 \n    2.10 \n  \n  \n    Chiem \n    Chiemsee \n    Chiem \n    25.60 \n    73.4 \n    1.26 \n    2.04800 \n    79.900 \n    9.2 \n    0.55 \n    3.80 \n  \n  \n    Dober \n    Dobersdorfer See \n    Dober \n    5.40 \n    18.8 \n    2.30 \n    0.01690 \n    3.120 \n    63.9 \n    0.64 \n    27.30 \n  \n  \n    Muegg \n    Großer Müggelsee \n    Muegg \n    4.85 \n    7.5 \n    0.20 \n    0.03500 \n    7.200 \n    189.9 \n    0.17 \n    32.90 \n  \n  \n    Ploen \n    Großer Plöner See \n    Ploen \n    12.40 \n    58.0 \n    3.10 \n    0.37200 \n    29.970 \n    62.3 \n    0.22 \n    8.80 \n  \n  \n    Kumme \n    Kummerower See \n    Kumme \n    8.10 \n    23.3 \n    1.50 \n    0.26300 \n    32.500 \n    65.3 \n    0.78 \n    16.60 \n  \n  \n    Mueritz \n    Müritz (Außenmüritz) \n    Mueritz \n    6.50 \n    28.1 \n    6.00 \n    0.68000 \n    105.300 \n    19.7 \n    0.11 \n    6.30 \n  \n  \n    MuerB \n    Müritz (Binnenmüritz) \n    MuerB \n    9.80 \n    30.3 \n    6.00 \n    0.03800 \n    3.910 \n    34.2 \n    0.11 \n    6.70 \n  \n  \n    Plaue \n    Plauer See \n    Plaue \n    6.80 \n    25.5 \n    3.00 \n    0.30000 \n    38.400 \n    26.0 \n    0.09 \n    6.80 \n  \n  \n    Sacro \n    Sacrower See \n    Sacro \n    18.01 \n    36.0 \n    15.00 \n    0.01930 \n    1.072 \n    79.8 \n    0.04 \n    8.60 \n  \n  \n    Schar \n    Scharmützelsee \n    Schar \n    9.00 \n    29.5 \n    16.00 \n    0.10823 \n    12.090 \n    35.3 \n    0.12 \n    10.40 \n  \n  \n    SchwA \n    Schweriner See (Außensee) \n    SchwA \n    9.40 \n    52.4 \n    10.00 \n    0.33100 \n    35.200 \n    100.0 \n    0.23 \n    11.70 \n  \n  \n    SchwI \n    Schweriner See (Innensee) \n    SchwI \n    13.50 \n    44.6 \n    5.30 \n    0.35600 \n    26.400 \n    246.5 \n    0.19 \n    5.86 \n  \n  \n    Starn \n    Starnberger See \n    Starn \n    53.20 \n    127.8 \n    21.00 \n    2.99900 \n    56.400 \n    5.9 \n    0.32 \n    1.84 \n  \n  \n    Stech \n    Stechlinsee \n    Stech \n    22.80 \n    68.0 \n    32.00 \n    0.09700 \n    4.250 \n    15.8 \n    0.04 \n    2.60 \n  \n  \n    Stein \n    Steinhuder Meer \n    Stein \n    1.35 \n    2.9 \n    2.30 \n    0.04200 \n    29.100 \n    53.3 \n    0.12 \n    29.00 \n  \n\n\n\n\n\n\n\ncolumns: called variables or species\nrows: observations or objects"
  },
  {
    "objectID": "slides/10-multivariate-1.html#pca-with-the-uba-lake-data",
    "href": "slides/10-multivariate-1.html#pca-with-the-uba-lake-data",
    "title": "10-Multivariate methods I",
    "section": "PCA with the UBA lake data",
    "text": "PCA with the UBA lake data\n\n\n\n\npc <- prcomp(scale(lakedata))\n\nEigenvalues (proportion of variance) indicate importance of components.\n\nsummary(pc)\n\nImportance of components:\n                          PC1    PC2   PC3     PC4    PC5     PC6     PC7     PC8\nStandard deviation     2.0692 1.2735 1.047 0.76067 0.5499 0.30497 0.12230 0.10618\nProportion of Variance 0.5352 0.2027 0.137 0.07233 0.0378 0.01163 0.00187 0.00141\nCumulative Proportion  0.5352 0.7379 0.875 0.94729 0.9851 0.99672 0.99859 1.00000"
  },
  {
    "objectID": "slides/10-multivariate-1.html#pca-biplot",
    "href": "slides/10-multivariate-1.html#pca-biplot",
    "title": "10-Multivariate methods I",
    "section": "PCA Biplot",
    "text": "PCA Biplot\n\nbiplot(pc)"
  },
  {
    "objectID": "slides/10-multivariate-1.html#pca-with-sqrt-transformed-data",
    "href": "slides/10-multivariate-1.html#pca-with-sqrt-transformed-data",
    "title": "10-Multivariate methods I",
    "section": "PCA with sqrt transformed data",
    "text": "PCA with sqrt transformed data\n\n\nlakedata2 <- sqrt(lakedata)\npc <- prcomp(scale(lakedata2))\nsummary(pc)\n\nImportance of components:\n                         PC1    PC2    PC3     PC4     PC5     PC6     PC7    PC8\nStandard deviation     2.111 1.3059 0.9748 0.70830 0.50321 0.29742 0.17060 0.1266\nProportion of Variance 0.557 0.2132 0.1188 0.06271 0.03165 0.01106 0.00364 0.0020\nCumulative Proportion  0.557 0.7702 0.8889 0.95165 0.98330 0.99436 0.99800 1.0000\n\n\n\n\nThe PCA with the untransformed data looked very asymmetric, we repeat it with square root transformed data.\nhelps to get a better “resolution”\nmust be taken into account when interpreting the results\nlog transformation is also possible"
  },
  {
    "objectID": "slides/10-multivariate-1.html#biplot-of-sqrt-transformed-data-1.-3.-pc",
    "href": "slides/10-multivariate-1.html#biplot-of-sqrt-transformed-data-1.-3.-pc",
    "title": "10-Multivariate methods I",
    "section": "Biplot of sqrt transformed data (1.-3. PC)",
    "text": "Biplot of sqrt transformed data (1.-3. PC)\n\npar(mfrow=c(1, 2), mar=c(5, 4, 4, 2.4), las=1)\nbiplot(pc)\nbiplot(pc, choices=c(3, 2))"
  },
  {
    "objectID": "slides/10-multivariate-1.html#pca-with-the-vegan-package",
    "href": "slides/10-multivariate-1.html#pca-with-the-vegan-package",
    "title": "10-Multivariate methods I",
    "section": "PCA with the vegan package",
    "text": "PCA with the vegan package\n\npc <- rda(lakedata2, scale = TRUE)\nsummary(pc)\n\n\nCall:\nrda(X = lakedata2, scale = TRUE) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal               8          1\nUnconstrained       8          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                        PC1    PC2    PC3     PC4     PC5     PC6      PC7      PC8\nEigenvalue            4.456 1.7053 0.9503 0.50170 0.25322 0.08846 0.029105 0.016020\nProportion Explained  0.557 0.2132 0.1188 0.06271 0.03165 0.01106 0.003638 0.002003\nCumulative Proportion 0.557 0.7702 0.8889 0.95165 0.98330 0.99436 0.997997 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  3.414953 \n\n\nSpecies scores\n\n           PC1     PC2      PC3      PC4       PC5      PC6\nz_mean -1.0598  0.4289 -0.21113  0.23873 -0.008753  0.18441\nz_max  -1.1318  0.3420 -0.12121  0.10258  0.072128  0.04149\nt_ret   0.0321  1.1531 -0.07499  0.10386 -0.291203 -0.15956\nvolume -1.0984 -0.1075 -0.36435 -0.28489 -0.088096  0.07254\narea   -1.0368 -0.2858 -0.25303 -0.44554 -0.025908 -0.17654\np_tot   0.7169  0.2934 -0.85503  0.06207  0.345841 -0.05495\nn_no3  -0.7044 -0.7316 -0.18149  0.60719 -0.072833 -0.13748\nchl     0.8938 -0.3753 -0.59964 -0.02895 -0.381711  0.09702\n\n\nSite scores (weighted sums of species scores)\n\n             PC1     PC2      PC3      PC4      PC5      PC6\nAmmer   -0.83902 -0.6075  0.51716  1.81616  0.22343 -0.15112\nArend    0.61718  1.8219 -1.92971  0.44353 -0.51334 -0.46420\nBoden   -2.56671 -0.3066 -1.32007 -1.14721 -0.41861  0.35821\nChiem   -0.64712 -0.5918  0.55561  0.35138  0.48915  0.23752\nDober    0.57998 -1.0029 -0.35592  1.09957 -1.11137  0.09904\nMuegg    0.98336 -0.8687 -1.03143 -0.33065  0.31544  1.71907\nPloen    0.05148 -0.1788  0.12415 -0.07719  0.74087  0.42564\nKumme    0.20231 -1.0792 -0.29790  0.92094 -0.25802 -1.13785\nMueritz  0.01805 -0.1716  0.69453 -1.37602 -0.04136 -1.55657\nMuerB    0.32308  0.1145  0.83401 -0.12085  0.39231  0.75409\nPlaue    0.21775 -0.2308  0.80820 -0.98103  0.44885  0.06816\nSacro    0.40494  0.8219  0.29088 -0.04609  0.23456  1.24642\nSchar    0.34038  0.3961  0.50515 -0.19722 -0.82282 -0.52792\nSchwA    0.19197  0.1243 -0.30591 -0.03972  0.15528 -1.05932\nSchwI    0.24471  0.2379 -0.69605  0.04506  2.41490 -0.72493\nStarn   -0.95511  0.9136  0.55372  0.66291 -0.52409  0.55554\nStech   -0.05030  1.4337  1.12433  0.06976 -0.49103  0.09703\nStein    0.88307 -0.8259 -0.07074 -1.09331 -1.23415  0.06121\n\n\n\nThe two first PCs explain PC 1 = 77% of variance of the square root transformed observations."
  },
  {
    "objectID": "slides/10-multivariate-1.html#variance-importance-and-biplot",
    "href": "slides/10-multivariate-1.html#variance-importance-and-biplot",
    "title": "10-Multivariate methods I",
    "section": "Variance importance and biplot",
    "text": "Variance importance and biplot\n\nImportance of components\n\nPC 1 = 56%\nPC 2 = 21%\nPC 3 = 12%\n\n\\(\\Rightarrow\\) The two first PCs explain PC 1 = 77% of variance of the square root transformed observations.\n\n\n\nbiplot(pc)"
  },
  {
    "objectID": "slides/10-multivariate-1.html#interpretation",
    "href": "slides/10-multivariate-1.html#interpretation",
    "title": "10-Multivariate methods I",
    "section": "Interpretation",
    "text": "Interpretation\n\nVariables\n\nonly long arrows can be interpreted\nsame direction: positive correlation\nopposite direction: negative correlation\nrectangular: no correlation\n\nObservations\n\nidentification of groups and extreme cases\n\nCombined View\n\nrelative size of variable for observations\narrow direction: high values\nopposite direction: low values\naround middle: average\n\n\\(\\Rightarrow\\) Important: always read perpendicular to PCs and arrows!"
  },
  {
    "objectID": "slides/10-multivariate-1.html#biplot-in-3d",
    "href": "slides/10-multivariate-1.html#biplot-in-3d",
    "title": "10-Multivariate methods I",
    "section": "Biplot in 3D",
    "text": "Biplot in 3D\n\n\nVariance\n\nPC 1 = 56%\nPC 2 = 21%\nPC 3 = 12%\nsum of PC 4 … 8 = 11%\n\n\n\\(\\rightarrow\\) Use the mouse to rotate and zoom."
  },
  {
    "objectID": "slides/10-multivariate-1.html#nonmetric-multidimensional-scaling-nmds",
    "href": "slides/10-multivariate-1.html#nonmetric-multidimensional-scaling-nmds",
    "title": "10-Multivariate methods I",
    "section": "Nonmetric Multidimensional Scaling: NMDS",
    "text": "Nonmetric Multidimensional Scaling: NMDS\n\nmd <- metaMDS(lakedata2, scale = TRUE, distance = \"euclid\", trace=FALSE)\nplot(md, type=\"text\")\nabline(h=0, col=\"grey\", lty=\"dotted\")\nabline(v=0, col=\"grey\", lty=\"dotted\")\n\n\nThe NMDS tries to map the higher dimensions even better to 2D or 3D. However, it accepts some distortion. More about this in the next chapter."
  },
  {
    "objectID": "slides/10-multivariate-1.html#the-code",
    "href": "slides/10-multivariate-1.html#the-code",
    "title": "10-Multivariate methods I",
    "section": "The code",
    "text": "The code\n\nlakes <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/elements/main/data/uba/lakes-combined-data.csv\")\nvalid_columns <- c(\"name\", \"shortname\", \"z_mean\", \"z_max\",  \"t_ret\", \"volume\", \n  \"area\", \"p_tot\", \"n_no3\", \"chl\", \"wfd_type\")\n\n# set row names and limit data set to complete records without missing data\nrow.names(lakes) <- lakes$shortname\nlakes <- na.omit(lakes[valid_columns])\n\n# only the numerical variables\nlakedata <- lakes[c(\"z_mean\", \"z_max\",  \"t_ret\", \"volume\", \n                     \"area\", \"p_tot\", \"n_no3\", \"chl\")] \n\n## PCA with the vegan package\nlibrary(\"vegan\")\nlakedata2 <- sqrt(lakedata)\npc <- rda(lakedata2, scale = TRUE)\nsummary(pc)\nbiplot(pc)\nbiplot(pc, choices=c(3, 2))\n\n## 3D Plot\nlibrary(\"vegan3d\")\nordirgl(pc, col = \"yellow\")\norgltext(pc, display = \"species\", col=\"red\")\norgltext(pc, display = \"sites\", col=\"blue\", pos=4)\nview3d(theta = 5, phi = 15, fov=30, zoom=1)\n\n## NMDS\nmd <- metaMDS(lakedata2, scale = TRUE, distance = \"euclid\", trace=FALSE)\nplot(md, type=\"text\")\nabline(h=0, col=\"grey\", lty=\"dotted\")\nabline(v=0, col=\"grey\", lty=\"dotted\")\n\n\nData and full source code is available from https://github.com/tpetzoldt/elements/"
  },
  {
    "objectID": "slides/10-multivariate-1.html#summary",
    "href": "slides/10-multivariate-1.html#summary",
    "title": "10-Multivariate methods I",
    "section": "Summary",
    "text": "Summary\n\n\nMultivariate methods can be used to analyze data sets, where multiple variables depend on each other.\nPCA is a dimension reduction technique that tries to map high-dimensional data to a lower number of dimensions.\nIt can be used as an explorative technique to find relationships between data.\nCompared to creating multiple plots between all variables, it helps to see the overall picture, saves time and avoids statistical fishing.\nThe next chapter will introduce more methods.\n\n\nFurther reading\n\nOksanen (2010)\nBorcard et al. (2018)"
  },
  {
    "objectID": "slides/10-multivariate-1.html#references",
    "href": "slides/10-multivariate-1.html#references",
    "title": "10-Multivariate methods I",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\nBorcard, D., Gillet, F., & Legendre, P. (2018). Numerical ecology with R. Springer International Publishing. https://doi.org/10.1007/978-3-319-71404-2\n\n\nOksanen, J. (2010). Multivariate analysis of ecological communities in R: Vegan tutorial.\n\n\nUmweltbundesamt. (2021). Kenndaten ausgewählter Seen Deutschlands. https://www.umweltbundesamt.de/daten/wasser/zustand-der-seen#okologischer-zustand-der-seen\n\n\nWinkelmann, C., Hellmann, C., Worischka, S., Petzoldt, T., & Benndorf, J. (2011). Fish predation affects the structure of a benthic community. Freshwater Biology, 56(6), 1030–1046. https://doi.org/10.1111/j.1365-2427.2010.02543.x"
  }
]