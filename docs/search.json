[
  {
    "objectID": "tutorials/s3-multivar-lakes.html",
    "href": "tutorials/s3-multivar-lakes.html",
    "title": "Multivariate Lake Data Example",
    "section": "",
    "text": "The following example demonstrates basic multivariate principles by means of a teaching example. A detailed description of theory and applications is found in excellent books of Legendre & Legendre (1998) and Borcard et al. (2018). Practical help is found in the tutorials of the vegan package (Oksanen et al., 2020)."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#data-set-and-terms-of-use",
    "href": "tutorials/s3-multivar-lakes.html#data-set-and-terms-of-use",
    "title": "Multivariate Lake Data Example",
    "section": "2 Data set and terms of use",
    "text": "2 Data set and terms of use\nThe lake data set originates from the public data repository of the German Umweltbundesamt (Umweltbundesamt, 2021). The data set provided can be used freely according to the terms and conditions published at the UBA web site, that refer to § 12a EGovG with respect of the data, and to the Creative Commons CC-BY ND International License 4.0 with respect to other objects directly created by UBA.\nThe document and codes provided here can be shared according to CC BY 4.0."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#load-the-data",
    "href": "tutorials/s3-multivar-lakes.html#load-the-data",
    "title": "Multivariate Lake Data Example",
    "section": "3 Load the data",
    "text": "3 Load the data\nHere we load the data set and add English column names and abbreviated lake identifiers as row names to the table, that are useful for the multivariate plotting functions.\n\nlibrary(\"readxl\") # read Excel files directly\nlibrary(\"vegan\")  # multivariate statistics in ecology\nlakes <- as.data.frame(\n  read_excel(\"../data/uba/3_tab_kenndaten-ausgew-seen-d_2021-04-08.xlsx\", sheet=\"Tabelle1\", skip=3)\n)\nnames(lakes) <- c(\"name\", \"state\", \"drainage\", \"population\", \"altitude\", \n                  \"z_mean\", \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                  \"shore_devel\", \"drain_ratio\", \"wfd_type\")\nrownames(lakes) <- paste0(1:nrow(lakes), substr(lakes$name, 1, 4))\n\nText columns, e.g Federal State names and lake type are removed and rows with missing data excluded. If population is not used, the analysis can be repeated with more lakes.\n\nvalid_columns <- c(\"drainage\", \"population\", \"altitude\", \"z_mean\",\n                   \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                   \"shore_devel\", \"drain_ratio\")\n\n#valid_columns <- c(\"drainage\", \"altitude\", \"z_mean\",\n#                   \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n#                   \"shore_devel\",\"drain_ratio\")\ndat <- lakes[valid_columns]\ndat <- na.omit(dat)"
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#data-inspection",
    "href": "tutorials/s3-multivar-lakes.html#data-inspection",
    "title": "Multivariate Lake Data Example",
    "section": "4 Data inspection",
    "text": "4 Data inspection\nIt is alwas a good idea to plot the data first, as time series or boxplots for example, dependingon the type of data. Here we use boxplots, that we scale (z-transform) to a mean zero and standard deviation one to have comparable values.\nAs we can see a number of high extreme values, we apply also a square root transformation, that is less extreme than log transform and not sensitive against zero values, but because altitude contains a negative value (below sea level) we replace this with zero. As it is a small value, it does not influence our analysis, but we should always be very careful to document such workarounds.\n\npar(mfrow = c(1, 1))\npar(mar = c(7, 4, 2, 1) + .1)\nboxplot(scale(dat), las = 2)\n\n\n\ndat$altitude <- ifelse(dat$altitude < 0, 0, dat$altitude)\nboxplot(scale(sqrt(dat)), las=2)"
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#multivariate-analysis",
    "href": "tutorials/s3-multivar-lakes.html#multivariate-analysis",
    "title": "Multivariate Lake Data Example",
    "section": "5 Multivariate Analysis",
    "text": "5 Multivariate Analysis\n\n5.1 Principal Components: PCA\n\npc <- prcomp(scale(dat))\nsummary(pc)\n\nImportance of components:\n                         PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     2.305 1.4737 1.1459 1.0686 0.84953 0.50024 0.24164\nProportion of Variance 0.483 0.1974 0.1194 0.1038 0.06561 0.02275 0.00531\nCumulative Proportion  0.483 0.6805 0.7998 0.9036 0.96925 0.99200 0.99731\n                           PC8     PC9    PC10    PC11\nStandard deviation     0.12590 0.08400 0.07563 0.03077\nProportion of Variance 0.00144 0.00064 0.00052 0.00009\nCumulative Proportion  0.99875 0.99939 0.99991 1.00000\n\nplot(pc)\n\n\n\nbiplot(pc)\n\n\n\n\nAs the PCA with the untransformed data looks somewhat asymmetric, we repeat it with square transformed data. In addition, also the 3rd PC is plotted.\n\ndat2 <- sqrt(dat)\npc2 <- prcomp(scale(dat2))\nsummary(pc2)\n\nImportance of components:\n                          PC1    PC2    PC3    PC4     PC5     PC6     PC7\nStandard deviation     2.1886 1.5906 1.2499 1.0634 0.79782 0.44854 0.28572\nProportion of Variance 0.4354 0.2300 0.1420 0.1028 0.05786 0.01829 0.00742\nCumulative Proportion  0.4354 0.6654 0.8075 0.9103 0.96812 0.98641 0.99383\n                           PC8     PC9    PC10    PC11\nStandard deviation     0.17665 0.13833 0.12041 0.05528\nProportion of Variance 0.00284 0.00174 0.00132 0.00028\nCumulative Proportion  0.99666 0.99840 0.99972 1.00000\n\npar(mfrow=c(1,2))\npar(mar=c(5, 4, 4, 2) + 0.1)\nbiplot(pc2, cex=0.6)\nbiplot(pc2, cex=0.6, choices=c(3, 2))\n\n\n\n\nA PCA is also possible with the rda function of the vegan package. The syntax of the plot functions is somewhat different. Instead of biplot as above, we can directly use plot. Details are found in the vegan documentation.\n\npar(mfrow=c(1,1))\npc3 <- rda(dat2, scale = TRUE)\npc3\n\nCall: rda(X = dat2, scale = TRUE)\n\n              Inertia Rank\nTotal              11     \nUnconstrained      11   11\nInertia is correlations \n\nEigenvalues for unconstrained axes:\n  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10  PC11 \n4.790 2.530 1.562 1.131 0.637 0.201 0.082 0.031 0.019 0.014 0.003 \n\n#summary(pc3)\nplot(pc3)\n\n\n\n\n\n\n5.2 Nonmetric Multidimensional Scaling: NMDS\nLt’s now perform an NMDS for the data set. Function metaMDS runs a series of NMDS fits with different start values to avoid local minima. It has also some automatic transformations built in and works usually with the Bray-Curtis dissimilarity, that is used for plants and animal species abundance data. As we work with physical data here, we set the distance measure to “euclidean”.\n\nmd <- metaMDS(dat2, scale = TRUE, distance = \"euclid\")\n\nSquare root transformation\nWisconsin double standardization\nRun 0 stress 0.1181117 \nRun 1 stress 0.1207022 \nRun 2 stress 0.1188526 \nRun 3 stress 0.1188534 \nRun 4 stress 0.1230331 \nRun 5 stress 0.1188257 \nRun 6 stress 0.1208973 \nRun 7 stress 0.1207018 \nRun 8 stress 0.1181117 \n... New best solution\n... Procrustes: rmse 1.728789e-05  max resid 5.144074e-05 \n... Similar to previous best\nRun 9 stress 0.1181116 \n... New best solution\n... Procrustes: rmse 4.843601e-05  max resid 0.0001439558 \n... Similar to previous best\nRun 10 stress 0.1188267 \nRun 11 stress 0.1181116 \n... Procrustes: rmse 9.483475e-05  max resid 0.0002783637 \n... Similar to previous best\nRun 12 stress 0.1188538 \nRun 13 stress 0.1181116 \n... Procrustes: rmse 0.000104247  max resid 0.0003014734 \n... Similar to previous best\nRun 14 stress 0.1181117 \n... Procrustes: rmse 8.306504e-05  max resid 0.0002417354 \n... Similar to previous best\nRun 15 stress 0.1181117 \n... Procrustes: rmse 4.608876e-05  max resid 0.0001336367 \n... Similar to previous best\nRun 16 stress 0.1188572 \nRun 17 stress 0.1188527 \nRun 18 stress 0.2076954 \nRun 19 stress 0.1181117 \n... Procrustes: rmse 6.38454e-05  max resid 0.0001867477 \n... Similar to previous best\nRun 20 stress 0.1208971 \n*** Best solution repeated 6 times\n\nplot(md, type=\"text\")\nabline(h=0, col=\"grey\", lty=\"dotted\")\nabline(v=0, col=\"grey\", lty=\"dotted\")\n\n\n\n\n\n\n5.3 Cluster analysis\nHere we apply a hierarchical cluster analysis with square root transformed data and two different agglomeration schemes, “complete linkage” and “Ward’s method”.\n\npar(mfrow=c(2,1))\nhc <- hclust(dist(scale(dat2)), method=\"complete\") # the default\nplot(hc)\n\nhc2 <- hclust(dist(scale(dat2)), method=\"ward.D2\")\nplot(hc2)\n\n\n\n\nWe can also use the clusters to indicate groups in the NMDS plot. Function rect.hclust indicates a given number of clusters in the dendrogram, then we cut the tree with cutree and use the groups grp as color codes. R has 8 standard colors. If we need more, we can define an own palette.\n\nplot(hc, hang = -1)\nrect.hclust(hc, 5)\n\n\n\ngrp <- cutree(hc, 5)\n# grp                  # can be used to show the groups\nplot(md, type = \"n\")\ntext(md$points, row.names(dat2), col = grp)\n\n\n\n\nInstead of hierarchical clustering, we can also use a non-hierarchical method, e.g. k-means clustering. This is an iterative method, and avoids the problem that cluster assignment depends on the order of clustering and the agglomeration method.\nDepending on the question, it may be a disadvantage, that the number of clusters needs to be specified beforehand (e.g. from hierarchical clustering) and that we do not get a tree diagramm."
  },
  {
    "objectID": "tutorials/s3-multivar-lakes.html#task",
    "href": "tutorials/s3-multivar-lakes.html#task",
    "title": "Multivariate Lake Data Example",
    "section": "6 Task",
    "text": "6 Task\n\nTry to understand the analysis,\ndiscuss the results,\nask questions.\nThe idea is to work on this report together and to make it more complete."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html",
    "href": "tutorials/s1-introductory-r-session.html",
    "title": "An Introductory R Session",
    "section": "",
    "text": "This tutorial is available in HTML format for screen reading and PDF for printing."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#program-start-and-help-system",
    "href": "tutorials/s1-introductory-r-session.html#program-start-and-help-system",
    "title": "An Introductory R Session",
    "section": "2.1 Program start and help system",
    "text": "2.1 Program start and help system\nThe easiest way to learn R is the creative understanding and modification of given examples, the usage of R for solving practical problems and the diagnosis of the frequently occurring problems and error messages. Don’t worry: error messages are a normal phenomenon in scientific computing and not an indication of a dysfunction of the computer or the human brain. The opposite is true, a certain amount of stress hormones helps to acquire permanent learning effects. Then, after a certain level of experience reading the official R-Documentation “An Introduction to R” (Venables et al., 2021). or any good R-book is strongly recommended.\nThe first sections of this “crash course” are intended to give an overview over some of the most important elements of R and an insight into a typical work flow, that may be useful for the first statistical analyses and as a starting point for self-education.\nWe begin our first session by starting RStudio, a platform independent interface that makes working with R easier. RStudio divides the screen into 3 (resp. 4) windows (called panes), where some of them have additional tabs to switch between different views.\n\nFigure 1: R Studio with 4 panes. Use File – New R Script to open the the source code pane (shown top left). Then enter some code and don’t forget to explore the help files.\nIn a fresh RStudio session, one “Pane” should be the main help page of R. It is a good idea to browse a little bit around to get an impression about the amount and the typical style of the available help topics. The most important sections are “An Introduction to R”, “Search Engine & Keywords”, “Packages”, the “Frequently Asked Questions” and possibly “R Data Import/Export”.\nWe start now to explore the R-System itself."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-as-a-pocket-calculator",
    "href": "tutorials/s1-introductory-r-session.html#r-as-a-pocket-calculator",
    "title": "An Introductory R Session",
    "section": "2.2 R as a pocket calculator",
    "text": "2.2 R as a pocket calculator\nEntering an arithmetic expression like this:\n\n2 + 4\n\nshows that R can be used as a pocket calculator, that immediately outputs the result:\n\n\n[1] 6\n\n\nInstead of printing the result to the screen, it is also possible to save the result into a named variable using the assignment operator “<-”.\n\na <- 2 + 4\n\nIt seems that nothing happens, but the result is now saved in the variable a that can be recalled at any time by entering the variable name alone:\n\na\n\nVariable names in R start always with a character (or for special purposes a dot), followed by further characters, numerals, dots or underscores, where a distinction is made between small and capital letters, i.e. the variables value, Value and VALUE can contain different data. A few character combinations are reserved words and cannot be used as variables:\nbreak, for, function, if, in, next, repeat, while and “...” (three dots).\nOther identifiers like plot can be re-defined, but this should be done with care to avoid unwanted confusion and side effects."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#vectors",
    "href": "tutorials/s1-introductory-r-session.html#vectors",
    "title": "An Introductory R Session",
    "section": "2.3 Vectors",
    "text": "2.3 Vectors\nYou may have noticed, that the output of the example above had a leading [1], which means that the line begins with the first element of a. This brings us to a very important feature of R that variables can contain more than single values: vectors, matrices, lists, data frames (tables) and so on.\nThe most basic data type is the vector, that can be filled with data using the c (combine) function:\n\nvalues <- c(2, 3, 5, 7, 8.3, 10)\nvalues\n\n[1]  2.0  3.0  5.0  7.0  8.3 10.0\n\n\nTo create a sequence of values, one can use the : (colon):\n\nx <- 1:10\nx\n\nor, even more flexibly the seq function:\n\nx <- seq(2, 4, 0.25)\nx\n\nSequences of repeated equal values can be obtained with rep:\n\nx <- rep(2, 4)\nx"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercise",
    "href": "tutorials/s1-introductory-r-session.html#exercise",
    "title": "An Introductory R Session",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\nThere are many ways to use these functions, try for example:\n\nseq(0, 10)\nseq(0, 10, by = 2)\nseq(0, pi, length = 12)\nrep(c(0, 1, 2, 4, 9), times = 5)\nrep(c(0, 1, 2, 4, 9), each = 2)\nrep(c(0, 1, 2, 4, 9), each = 2, times = 5)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#access-to-vector-elements",
    "href": "tutorials/s1-introductory-r-session.html#access-to-vector-elements",
    "title": "An Introductory R Session",
    "section": "2.5 Access to vector elements",
    "text": "2.5 Access to vector elements\nInstead of accessing vectors as a whole, it is also possible to extract single elements, where the index of the requested data is itself a vector:\n\nvalues[5]\nvalues[2:4]\nvalues[c(1, 3, 5)]\n\nSometimes, elements of a vector may have individual names, which makes it easy to access them:\n\nnamed <- c(a = 1, b = 2.3, c = 4.5)\nnamed\nnamed[\"a\"]\n\nIn R (and in contrast to other languages like C/C++) vector indices start with 1. Negative indices are also possible, but they have the special purpose to delete one or several elements:\n\nvalues[-3]\n\nIt is also possible to extend a given vector by preceding or appending values with the combine function (c):\n\nc(1, 1, values, 0, 0)\n\nThe length of a vector can be determined with:\n\nlength(values)\n\nand it is also possible to have empty vectors, i.e. vectors that exist, but do not contain any values. Here the keyword NULL means “nothing” in contrast to “0” (zero) that has length 1:\n\nvalues <- NULL\nvalues\nlength(values)\n\nSuch empty vectors are sometimes used as “containers” for appending data step by step:\n\nvalues <- NULL\nvalues\nlength(values)\nvalues <- c(values, 1)\nvalues\nvalues <- c(values, 1.34)\nvalues\n\nIf a data element should be removed completely, this can be done using the remove function:\nrm(values)\nvalues\nError: Object \"values\" not found\nThe complete workspace can be deleted from the menu of R or RStudio (Session – Clear workspace) or from the command line with rm (remove):\n\nrm(list = ls(all = TRUE))\n\nThe R session can be closed by using the menu as usual or by entering:\n\nq()\n\nSometimes and depending of the configuration, R asks whether the “R workspace” should be saved to the disk. This may be useful for continuing work at a later time, but has the risk to clutter the workspace and to get irreproducible results at a later session, so it is recommended to say “No” for now, except if you exactly know why.\nLater we will learn how to save only the data (and commands) that are needed."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#r-as-function-plotter",
    "href": "tutorials/s1-introductory-r-session.html#r-as-function-plotter",
    "title": "An Introductory R Session",
    "section": "3.1 R as function plotter",
    "text": "3.1 R as function plotter\nNow, we will see how to use R as a function plotter by drawing sine or cosine functions within an interval between 0 to 10. First, we create two vectors with x and y. To obtain a smooth curve, it is reasonable to choose a small step size. As a rule of thumb I always recommend to use about 100…400 small steps as a good compromise between smoothness and memory requirements, so let’s set the step size to 0.1:\n\nx <- seq(0, 10, 0.1)\ny <- sin(x)\nplot(x, y)\n\n\n\n\nInstead of plotting points, we can also draw continuous lines. This is indicated by supplying an optional argument type = \"l\".\nNote: the symbol used here for type is the small letter “L” for “line” and not the – in printing very similar – numeral “1” (one)!\nWe see also, that optional arguments like type can be given as “keyword = value” pair. This has the advantage that the order of arguments does not matter, because arguments are referenced by their name:\n\nplot(x, y, type = \"l\")\n\nNow we want to add a cosine function with another color. This can be done with one of the function lines or points, for adding lines or points to an existing figure:\n\ny1 <- cos(x)\nlines(x, y1, col = \"red\")\n\nWith the help of text it is also possible to add arbitrary text, by specifying first the x and y coordinates and then the text:\n\nx1 <- 1:10\ntext(x1, sin(x1), x1, col = \"green\")\n\nMany options exist to modify the behavior of most graphics functions so the following specifies user-defined coordinate limits (xlim, ylim), axis labels and a heading (xlab, ylab, main).\n\nplot(x, y, xlim = c(-10, 10), ylim = c(-2, 2),\n    xlab = \"x-Values\", ylab = \"y-Values\", main = \"Example Graphics\")\n\nCode formatting and line breaks\nThe above example shows a rather long command that may not fit on a single line. In such cases, R displays a + (plus sign) to indicate that a command must be continued, e.g. because a closing parenthesis or a closing quote is still missing. Such a + at the beginning of a line is an automatic “prompt” similar to the ordinary > prompt and must never be typed in manually. If, however, the + continuation prompt occurs by accident, press “ESC” to cancel this mode.\nIn contrast to the long line continuation prompt, it is also possible to write several commands on one line, separated by a semi-colon “;”. This is unseful in some cases, but as a general rule it is much better to use the script editor and then to:\n\nwrite each command to a separate line\navoid long lines with more than about 80 characters\nuse proper indentation, e.g. 2 characters per indentation level\nuse spacing to improve readability of the code, e.g. before and after the assignment operator <-.\n\nFinally, a number symbol (or hash) # means that a complete line or the part of the line that follows # is a comment and should be ignored by R."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#additional-plotting-options",
    "href": "tutorials/s1-introductory-r-session.html#additional-plotting-options",
    "title": "An Introductory R Session",
    "section": "3.2 Additional plotting options",
    "text": "3.2 Additional plotting options\nIn order to explore the wealth of graphical functions, you may now have a more extensive look into the online help, especially regarding ?plot or ?plot.default, and you should experiment a little bit with different plotting parameters, like lty, pch, lwd, type, log etc. R contains uncountable possibilities to get full control over the style and content of your graphics, e.g. with user-specified axes (axis), legends (legend) or user-defined lines and areas (abline, rect, polygon). The general style of figures like (font size, margins, line width) can be influenced with the par function."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#high-level-plotting-functions",
    "href": "tutorials/s1-introductory-r-session.html#high-level-plotting-functions",
    "title": "An Introductory R Session",
    "section": "3.3 High level plotting functions",
    "text": "3.3 High level plotting functions\nIn addition, R and its packages contain numerous “high level”-graphics functions for specific purposes. To demonstrate a few, we first generate a data set with normally distributed random numbers (mean = 0, standard deviation sd = 1), then we plot them and create a histogram. Here, the function par(mfrow = c(2, 2)) divides the plotting area into 2 rows and 2 columns to show 4 separate figures:\n\npar(mfrow = c(2, 2))\nx <- rnorm(100)\nplot(x)\nhist(x)\n\nNow, we add a so-called normal probability plot and a second histogram with relative frequencies together with the bell-shaped density curve of the standard normal distribution. The optional argument probability = TRUE makes sure that the histogram has the same scaling as the density function, so that both can be overlayed:\n\nqqnorm(x)\nqqline(x, col = \"red\")\nhist(x, probability = TRUE)\nxx <- seq(-3, 3, 0.1)\nlines(xx, dnorm(xx, 0, 1), col = \"red\")\n\n\n\n\n\n\n\nHere it may also be a good chance to do a little bit summary statistics like: z.B. mean(x), var(x), sd(x), range(x), summary(x), min(x), max(x), …\nOr we may consider to test if the generated random numbers x are approximately normal distributed using the Shapiro-Wilks-W-Test:\n\nx <- rnorm(100)\nshapiro.test(x)\n\nA p-value bigger than 0.05 tells us that the test has no objections against normal distribution of the data. The concrete results may differ, because x contains random numbers, so it makes sense to repeat this several times. It can be also useful compare these normally distributed random numbers generated with rnorm with uniformly distributed random numbers generated with runif:\n\npar(mfrow=c(2,2))\ny <- runif(100)\nplot(y)\nhist(y)\nqqnorm(y)\nqqline(y, col=\"red\")\nmean(y)\nvar(y)\nmin(y)\nmax(y)\nhist(y, probability=TRUE)\nyy <- seq(min(y), max(y), length = 50)\nlines(yy, dnorm(yy, mean(y), sd(y)), col = \"red\")\nshapiro.test(y)\n\nAt the end, we compare the pattern of both data sets with box-and-whisker plots:\n\npar(mfrow=c(1, 1))\nboxplot(x, y)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercises",
    "href": "tutorials/s1-introductory-r-session.html#exercises",
    "title": "An Introductory R Session",
    "section": "3.4 Exercises",
    "text": "3.4 Exercises\nRepeat this example with new random numbers and vary sample size (n), mean value (mean) and standard deviation (sd) for random numbers created with rnorm, and use different min and max for runif. Consult the help pages for an explanation of the functions and its arguments, and create boxplots with different data sets."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#numeric-and-character-vectors",
    "href": "tutorials/s1-introductory-r-session.html#numeric-and-character-vectors",
    "title": "An Introductory R Session",
    "section": "4.1 Numeric and character vectors",
    "text": "4.1 Numeric and character vectors\nAll data objects have the two built-in attributes mode (data type) and length (number of data in the object).\nModes can be “numeric” for calculations or “character” for text elements.\n\nx <- c(1, 3, 4, 5)       # numeric\na <- c(\"hello\", \"world\") # character\n\nThe following is also a character variable, because the numbers are given in quotes. It is then not possible to do calculations:\n\nx <- c(\"1\", \"3\", \"4\", \"5\")  # character\nsum(x)\n\nError in sum(x) : invalid 'type' (character) of argument\n\nHere it is necessary to convert the character to numeric first:\n\ny <- as.numeric(x)\nsum(y)\n\n[1] 9.040591"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#factors",
    "href": "tutorials/s1-introductory-r-session.html#factors",
    "title": "An Introductory R Session",
    "section": "4.2 Factors",
    "text": "4.2 Factors\nA special kind of mode is factor. This is, statistically speaking, a nominal variable that appears like characters, e.g. “control”, “treatment A”, “treatment B” …, but its levels are internally encoded as integer.\nHere a typical example with three factor levels. In a first step,let’s create a character variable:\n\ntext <- rep(c(\"control\", \"treatment A\", \"treatment B\"), each=5)\ntext\n\n [1] \"control\"     \"control\"     \"control\"     \"control\"     \"control\"    \n [6] \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\" \"treatment A\"\n[11] \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\" \"treatment B\"\n\n\nand then convert it to a factor:\n\nf <- factor(text)\nf\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: control treatment A treatment B\n\n\nWe se that the character variable is printed with quotes and the factor without quotes, but with an additional information about the Levels. The reason for this is, that the factor is internally encoded as integer values with assigned levels as a translation table:\n\nlevels(f)\n\n[1] \"control\"     \"treatment A\" \"treatment B\"\n\n\nTo show encoding, we can convert the factor into an integer\n\nas.integer(f)\n\n [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3\n\n\nThe encoding is done in alphabetical order by default. It can be changed by using an additional levels argument:\n\nf2 <- factor(text, levels=c(\"treatment A\", \"treatment B\", \"control\"))\nf2\n\n [1] control     control     control     control     control     treatment A\n [7] treatment A treatment A treatment A treatment A treatment B treatment B\n[13] treatment B treatment B treatment B\nLevels: treatment A treatment B control\n\nas.numeric(f2)\n\n [1] 3 3 3 3 3 1 1 1 1 1 2 2 2 2 2\n\n\nFactors are useful for statistical analyses like ANOVA and statistical tests, and also as categories for plotting:\n\nx <- c(7.44, 6.45, 6.04, 5.58, 4.5, 8.13, 5.54, 7.34, 8.91, 5.16, 8.7, 7.74, 6.8, 6.49, 6.2)\nplot(x ~ f)\n\n\n\n\nWe see that a boxplot is created and no x-y-plot, because the explanation variable is a factor.\nNumeric variables (especially ordinal) can also be converted to factors. This is useful, if we want to make clear, that numbers are to be treated as name without order.\nHowever, conversion of such factors back into numeric variables types should be done with care, because a character “123” may be encoded with another value (e.g. 1) and not 123, see the following demonstration of a correct and wrong factor conversions:\n\nx <- c(2, 4, 6, 5, 8)\nf <- as.factor(x)\nas.numeric(f)               # wrong !!!\nas.numeric(as.character(f)) # correct\nas.numeric(levels(f))[f]    # even better\n\nSuch a factor coding is not specific to R and appears also in other statistics packages. Then they are sometimes called “dummy variables”."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#matrices-and-arrays",
    "href": "tutorials/s1-introductory-r-session.html#matrices-and-arrays",
    "title": "An Introductory R Session",
    "section": "4.3 Matrices and arrays",
    "text": "4.3 Matrices and arrays\nA matrix is a two-dimensional data structure that can be used for matrix algebra. To create a matrix, we can first create a one-dimensional vector and then reformat it as two-dimensional matrix with nrow rows and ncolcolumns:\n\nx <- 1:20\nx\n\ny <- matrix(x, nrow = 5, ncol = 4)\ny\n\nWe see that the matrix is filled rowwise. We can also convert it back to a vector:\n\nas.vector(y) # flattens the matrix to a vector\n\nAn array extends the matrix concept to more than two dimensions:\n\nx <- array(1:24, dim=c(3, 4, 2))\n\nVectors, matrices and arrays have an important limitation: they can only contain one data type (mode), either numeric or character. So, if a single element is of type character, the whole matrix will be of mode character and appears in quotes:\n\nx <- c(1, 2, 5, 2, \"a\")\nmode(x)\nx"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#lists",
    "href": "tutorials/s1-introductory-r-session.html#lists",
    "title": "An Introductory R Session",
    "section": "4.4 Lists",
    "text": "4.4 Lists\nThe most flexible data type of R is the list. It can contain arbitrary data of different modes. Lists can be nested to form a tree-like structure:\n\nl <- list(x = 1:3, y = c(1,2,3,4), a = \"hello\", L = list(x = 1, y = 2))\n\nLists are extremely powerful and flexible and may be discussed later. The impatient may have a look at the tutorial of w3schools.com."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#data-frames",
    "href": "tutorials/s1-introductory-r-session.html#data-frames",
    "title": "An Introductory R Session",
    "section": "4.5 Data frames",
    "text": "4.5 Data frames\nThe typical data structure for data analysis in R is the so-called data.frame. It can contain both, columns with numeric data and columns of mode character. Some packages use ando extended versions of data frames, a so called tibbles.\nA data frame can be constructed from scratch directly in the R code or read from a file or the internet. As an example, students were asked in different years for their favorite number from one to 9. The results can be put in a data frame like follows:\n\nfavnum <- data.frame(\n  favorite = 1:9,\n  obs2019  = c(1, 1, 6, 2, 2,  5,  8, 6, 3),\n  obs2020  = c(1, 2, 8, 1, 2,  2, 20, 2, 4),\n  obs2021  = c(2, 6, 8, 1, 6,  4, 13, 2, 4),\n  obs2022  = c(2, 3, 7, 8, 2, 10, 12, 6, 1)\n)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#direct-input",
    "href": "tutorials/s1-introductory-r-session.html#direct-input",
    "title": "An Introductory R Session",
    "section": "5.1 Direct input",
    "text": "5.1 Direct input\nWe used this method already when creating vectors with the c (combine)-Function:\n\nx <- c(1, 2, 5, 7, 3, 4, 5, 8)\nx\n\nIn the same way it is possible to create other data types like data frames:\n\ndat <- data.frame(f = c(\"a\", \"a\", \"a\", \"b\", \"b\", \"b\"),\n                  x = c(1,   4,   3,   3,   5,   7)\n       )\ndat\n\nor matrices:\n\nA <- matrix(c(1:9), nrow=3)\nA\n\nWe see that a matrix is not much different from a vector, formatted into rows and columns."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#read-data-from-a-text-file",
    "href": "tutorials/s1-introductory-r-session.html#read-data-from-a-text-file",
    "title": "An Introductory R Session",
    "section": "5.2 Read data from a text file",
    "text": "5.2 Read data from a text file\nR has very flexible functions to read data from text files. Let’s for example use a table that contains some data from a lake area in north-eastern Germany (Table 1).\nTable 1: Morphometrical and chemical properties of selected lakes (S=Stechlinsee, NN=Nehmitzsee Nord, NS=Nehmitzsee Süd, BL=Breiter Luzin, SL = Schmaler Luzin, DA = Dagowsee, HS = Feldberger Haussee; z=mean depth (m), t=theoretical retention time (a), P=phosphorus concentration (\\(\\mathrm{\\mu g L^{-1}}\\)), N=nitrogen concentration (\\(\\mathrm{mg L{^-1}}\\)), Chl=chlorophyll concentration (\\(\\mathrm{\\mu g L^{-1}}\\)), PP=annual primary production (\\(\\mathrm{g C m^{-2} a^{-1}}\\)), SD = secchi depth (m)). The data are an adapted and simplified “toy version” taken from Casper (1985) and Koschel & Scheffler (1985).\n\n\n\n\n\nLake\nz\nt\nP\nN\nChl\nPP\nSD\n\n\n\n\nS\n23.7\n40\n2.5\n0.20\n0.7\n95\n8.4\n\n\nNN\n5.9\n10\n2.0\n0.20\n1.1\n140\n7.4\n\n\nNS\n7.1\n10\n2.5\n0.10\n0.9\n145\n6.5\n\n\nBL\n25.2\n17\n50.0\n0.10\n6.1\n210\n3.8\n\n\nSL\n7.8\n2\n30.0\n0.10\n4.7\n200\n3.7\n\n\nDA\n5.0\n4\n100.0\n0.50\n14.9\n250\n1.9\n\n\nHS\n6.3\n4\n1150.0\n0.75\n17.5\n420\n1.6\n\n\n\n\n\nThe data can be downloaded from https://github.com/tpetzoldt/datasets/tree/main/data\n\n5.2.1 Set working directory\nR needs to know where to find the data on your computer. One way is to provide the full path to the data set, e.g. if it is c:/users/<username>/documents, then\n\nlakes <- read.csv(\"c:/users/julia/documents/lakes.csv\")\n\nThis can be cumbersome and error-prone, so the preferred method is to set the working directory of R to the data directory. This can be done in RStudio like follows:\n\nLocate the folder with the data in the “Files” pane\nSelect “More”\nSelect “Set As Working Directory”\n\n Figure2: Setting the working directory in RStudio\nAfter this, data can be retrieved directly from the working directory :\n\nlakes <- read.csv(\"lakes.csv\", header=TRUE)\n\nWe may also consider to create a sub-folder data of the working direktory and put the data in. Then we could use for example:\n\nlakes <- read.csv(\"../data/lakes.csv\", header=TRUE)\n\nNote also that we use always the ordinary slash “/” and not the backslash “\\”, even on Windows.\nIn some countries that have the comma and not the dot as a decimal separator and then for example a semicolon as column separator, additional arguments dec = \",\", sep=\";\" may be required. The details are found on the read.table help page."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#read-data-from-the-internet",
    "href": "tutorials/s1-introductory-r-session.html#read-data-from-the-internet",
    "title": "An Introductory R Session",
    "section": "5.3 Read data from the internet",
    "text": "5.3 Read data from the internet\nIf the data are available on an internet server, it can be read directly from there:\n\nlakes <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/lakes.csv\")\n\nNow, as the data are saved in the data frame lakes it is possible to access them as usual:\n\nlakes\nsummary(lakes)\nboxplot(lakes[-1])\n\nHere summary shows a quick overview and boxplot creates a boxplot for all columns except the first, that contains no numbers.\nNow, we are ready to inspect the content of this new variable lakes. If we use RStudio a View can be invoked by clicking to lakes in the environment window."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#import-dataset-in-rstudio",
    "href": "tutorials/s1-introductory-r-session.html#import-dataset-in-rstudio",
    "title": "An Introductory R Session",
    "section": "5.4 “Import Dataset” in RStudio",
    "text": "5.4 “Import Dataset” in RStudio\nRStudio contains a handy feature that makes importing of data more convenient. Essentially, this “Import Dataset” wizard helps us to construct the correct read.table, read.csv or read_delim function interactively. It is possible to try different options until a satisfying result is obtained. Current versions of RStudio contain several different ways to import data. Here we demonstrate the “Import Dataset From Text (readr)” assistant:\n\nFrom the menu select: File – Import DataSet – From CSV.\nSelect the requested file and select suitable options like the name of the variable the data are to be assigned to, the delimiter character (comma or Tab) and whether the first row of the file contains variable names.\n\n\nImport Dataset From Text (readr) assistant of RStudio.\nHint: In the exmple above, the name of the data frame is identical to the file name, i.e. “lakes”. If we want to name it differently (e.g.: dat), we must not forget to change this setting.\nNote also that the Code Preview contains the commands that the wizard created. If we copy these commands to the script pane, you can re-read the data several times without going back to the menu system:\n\nlibrary(readr)\nlakes <- read_csv(\"D:/DATA/lakes.csv\")\nView(lakes)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#display-the-content-of-the-data-frame",
    "href": "tutorials/s1-introductory-r-session.html#display-the-content-of-the-data-frame",
    "title": "An Introductory R Session",
    "section": "6.1 Display the content of the data frame",
    "text": "6.1 Display the content of the data frame\nThe easiest way is to just enter the name of the data frame to the R console, e.g.:\n\nlakes\n\nor to click to the name of the data frame in the “Environment” explorer of RStudio. This executes then View(lakes), so that the data are shown.\nFor large tables it is often not very useful to display the full content with View, so it may be better to use the function str (structure) that gives a compact overview over type, size and content of a variable:\n\nstr(mydata)\n\nThe str function is universal and also suitable for complicated object types like lists. Of course, there are many more possibilities for inspecting the content of a variable:\n\nnames(lakes)\nmode(lakes)\nlength(lakes)\n\nand sometimes even:\n\nplot(lakes)"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#access-single-columns-with",
    "href": "tutorials/s1-introductory-r-session.html#access-single-columns-with",
    "title": "An Introductory R Session",
    "section": "6.2 Access single columns with $",
    "text": "6.2 Access single columns with $\nSingle columns of a data frame can be accessed by using indices (with []) similar to a vector or a matrix or by using the column name and the $) operator:\n\nmean(lakes[,2])\nmean(lakes$z)\nmean(lakes[,\"z\"])\nmean(lakes[[\"z\"]])\nplot(lakes$z, lakes$t)\n\nwhere z is the mean depth of the lakes and t the so-called mean residence time.\nWe should also nitice the subtle difference of the output of the [] and the [[]]- version. The difference is as follows: single brackets return a data frame with one column, but double square brackets return the content of the column as a vector without the caption.\nWarning: In some older books, the $-style is sometimes abbreviated using the attach and detach-functions. This “prehistoric relict” is strongly discouraged, as it can lead to data inconsistency and strange errors. If you find it somewhere where it is still used, then it is a good idea to use detach repeatedly until an error message confirms us that there is nothing else that can be detached. Finally: never use attach/detach in a package.\nInstead, it is much better to use another function width, that opens the data frame only temporarily:\n\nwith(lakes, plot(z, t))"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#subsets-and-logical-indices",
    "href": "tutorials/s1-introductory-r-session.html#subsets-and-logical-indices",
    "title": "An Introductory R Session",
    "section": "6.3 Subsets and logical indices",
    "text": "6.3 Subsets and logical indices\nIn the following, we use another data set that we read directly from the internet:\n\nfruits <- read.csv(\"https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/clementines.csv\")\n\nIt contains weight, width and height measurements of two brands of Clementine fruits. After loading the data, we look at it with View(fruits) or the Environment explorer of Rstudio\nA very powerful feature of R is the use of logical vectors as “indices”, with similar results like data base queries. As an example, we can show the weight of all fruits of brand “A” with\n\nfruits[fruits$brand == \"A\", c(\"brand\", \"weight\")]\n\n   brand weight\n6      A     81\n7      A    113\n8      A     94\n9      A     86\n10     A    108\n11     A     91\n12     A     94\n13     A     86\n14     A     91\n15     A     88\n\n\nHere the first indext in the square brackets indicates the subset of rows that we want and the second argument the columns. If we want to see all columns, we leave the argument after the comma empty:\n\nfruits[fruits$brand == \"A\", ]\n\n   id no brand weight width height\n6   6  7     A     81    53     54\n7   7  8     A    113    61     60\n8   8  9     A     94    62     49\n9   9  3     A     86    58     53\n10 10  6     A    108    64     50\n11 11  1     A     91    59     51\n12 12 10     A     94    59     51\n13 13  4     A     86    55     55\n14 14  2     A     91    61     51\n15 15  5     A     88    54     55\n\n\nA logical comparison requires always a double “==”. Logical operations like & (and) and | (or) are also possible. Note that “and” has always precedence before “or”, except this is changed with parenthesis.\nA subset of a data frame can also be extracted with the subset function:\n\nbrand_B <- subset(fruits, brand == \"B\")\nbrand_B\n\nLike in the example before, the condition argument allows also logical expressions with & (and) and | (or).\nWe can also access single elements in matrix-like manner.\nThe element from the 2nd row and the 4th column can be selected with:\n\nfruits[2, 4]\n\nthe complete 5th row with:\n\nfruits[5, ]\n\nand rows 5:10 of the 4th column (weight) with:\n\nfruits[5:10, 4]\n\nAdditional methods for working with matrices, data frames and lists can be found in R textbooks or in the official R documentation."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#pipelines-and-summaries",
    "href": "tutorials/s1-introductory-r-session.html#pipelines-and-summaries",
    "title": "An Introductory R Session",
    "section": "7.1 Pipelines and summaries",
    "text": "7.1 Pipelines and summaries\nThe last examples are intended to demonstrate how powerful a single line can be in R. How to analyse data sets evolved over the history of R, so there is for example a function aggregate to compute statistics (e.g. mean values) depending on given criteria.\nThis works well and is still used, but the modern methods are more compact and easier to understand. Here let’s introduce a modern concept first, that is called “pipelining”. The idea is, that the result of a function is directly pipelined to another function, so instead of writing:\n\nbrand_B <- subset(fruits, brand == \"B\")\ncolumns_B <- brand_B[c(\"weight\", \"width\", \"height\")]\nmeans_B <- colMeans(columns_B)\nmeans_B\n\nwe can directly write:\n\nlibrary(\"dplyr\")\nfruits |> filter(brand == \"B\") |> select(weight, width, height) |> colMeans()\n\nHere we load an add-on package dplyr first, that contains a lot of helpful functions for data management, for example filter that selects rows and select that selects columns. The pipeline operator |> pipes then the data set fruitsto the filter- function and subsequently to the next. The “native pipeline operator” |> was introduced with R 4.1. As an alternative we can also use the %>% pipeline operator, that is loaded by the dplyr package. Its function would be identical in this case.\nTwo other extremely useful dplyr functions are group_by and summary, that allow to calculate arbitrary summary statistics in dependence of grouping variables. If we use the brand for grouping, we can summarize all groups simultaneously:\n\nfruits |> \n  group_by(brand) |>\n  summarise(mean(weight), mean(width), mean(height))\n\nThe summarize line above can still be made better, and there plenty of other stunning possibilities, so we will come back to this later."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#output-of-results",
    "href": "tutorials/s1-introductory-r-session.html#output-of-results",
    "title": "An Introductory R Session",
    "section": "7.2 Output of Results",
    "text": "7.2 Output of Results\nThe most simple method to save outputs from R is to copy it directly from the R console to any other program (e.g. LibreOffice, Microsoft Word or Powerpoint) via the Clipboard. This is convenient, but cannot be automated. Therefore, it is better to use a programmatic approach.\nLet’s use the example before and store the results in a new data frame results:\n\nresults <-\n  fruits |> \n  group_by(brand) |>\n  summarise(mean(weight), mean(width), mean(height))\n\nData frames can be saved as text files with write.table, write.csv or write_csv. Here we use write_csv (with underscore, not dot) from package readr:\n\nlibrary(\"readr\")\nwrite_csv(results, file=\"output-data.csv\")\n\nIn addition to these basic functions R has a wealth of possibilities to save output and data for later use in reports and presentations. All of them are of course documented in the online help, e.g. print, print.table, cat for text files, and pdf, png for figures. The add-on packages xtable contains functions for creating LaTeX or HTML-tables while full HTML output is supported by the R2HTML or knitr packages."
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#plots-with-ggplot2",
    "href": "tutorials/s1-introductory-r-session.html#plots-with-ggplot2",
    "title": "An Introductory R Session",
    "section": "7.3 Plots with ggplot2",
    "text": "7.3 Plots with ggplot2\nIn addition to the plot functions we used so far, other plot packages exist, for example lattice or ggplot2. Here a few small examples with the very popular **ggplot2* package:\n\nlibrary(\"ggplot2\")\nfruits |>\n  ggplot(aes(brand, weight)) + geom_boxplot()\n\n\n\n\nOr a scatterplot to compare weight and width of the fruits\n\nfruits |> ggplot(aes(weight, width)) + geom_point(aes(color=brand))\n\n\n\n\nwhere the brand is indicated as color. Another option could be:\n\nfruits |> ggplot(aes(weight, width)) + \n  geom_point() + \n  geom_smooth(method=\"lm\") + \n  facet_grid(~brand)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "tutorials/s1-introductory-r-session.html#exercises-1",
    "href": "tutorials/s1-introductory-r-session.html#exercises-1",
    "title": "An Introductory R Session",
    "section": "7.4 Exercises",
    "text": "7.4 Exercises\nR contains lots of data sets for exploring its graphical and statistical functions and that can be activated by using the data function, e.g. data(iris) or data(cars). A description of the data set can be found as usual in the help files, e.g. ?iris, ?cars.\nUse one of these data sets and try\n\nways to access columns, to select rows and to create subsets\nways for summary statistics and visualization with R’s base plot functions and optionally with ggplot."
  }
]