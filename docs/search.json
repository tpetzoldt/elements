[
  {
    "objectID": "slides/01-introduction.html#goals-of-the-course",
    "href": "slides/01-introduction.html#goals-of-the-course",
    "title": "01-Introduction",
    "section": "Goals of the course",
    "text": "Goals of the course\n\n\nIntroduction to “Data Science”\nStatistical concepts and selected methods\n\nStatistical parameters\nDistributions and probability\nStatistical tests\nModel selection\n\nPractical experience\n\nData strutures\nBasics of the R language\nApplications with real and simulated data sets\n\n\n\\(\\Rightarrow\\) Practical understanding and “statistical feeling”,\n\\(\\rightarrow\\) More important than facts learned by heart."
  },
  {
    "objectID": "slides/01-introduction.html#topics",
    "href": "slides/01-introduction.html#topics",
    "title": "01-Introduction",
    "section": "Topics",
    "text": "Topics\n\n\nBasic Concepts of Statistics\nAn Introduction to R\nStatistical Parameters and Distributions\nLinear Models\nAnalysis of Variance\nNonlinear Regression\nTime Series Analysis\n(Multivariate Statistics)"
  },
  {
    "objectID": "slides/01-introduction.html#material",
    "href": "slides/01-introduction.html#material",
    "title": "01-Introduction",
    "section": "Material",
    "text": "Material\n\n\nSlides\nExercises\nCourse script for self study “Data Analysis with R – Selected Topics and Examples”\nNote: Slides, script and exercises are regularly updated, depending on the progress of the course.\nExam: Written exam at the end of the semester. \\(\\rightarrow\\) Attend the labs!\n\n\n\nQuestions?"
  },
  {
    "objectID": "slides/01-introduction.html#an-introductory-example",
    "href": "slides/01-introduction.html#an-introductory-example",
    "title": "01-Introduction",
    "section": "An introductory example",
    "text": "An introductory example\nDaily average discharge of River Elbe, pegel Dresden, river km 55.6\ndate,       discharge\n1806-01-01,  472\n1806-01-02, 1050\n1806-01-03, 1310\n1806-01-04, 1020\n1806-01-05,  767\n1806-01-06,  616\n...\n2020-10-11,  216\n2020-10-12,  204\n2020-10-13,  217\n2020-10-14,  288\n2020-10-15,  440\n2020-10-16,  601\n2020-10-17,  570\n2020-10-18,  516\n2020-10-19,  450\n2020-10-20,  422\n2020-10-21,  396\n2020-10-22,  372\n2020-10-23,  356\n2020-10-24,  357\n2020-10-25,  332\n2020-10-26,  303\n2020-10-27,  302\n2020-10-28,  316\n2020-10-29,  321\n2020-10-30,  331\n2020-10-31,  353\n2020-11-01,  395\n\\(>\\) 70,000 measurements. How can we analyse this and what does it mean?\nData Source: Bundesanstalt für Gewässerkunde"
  },
  {
    "objectID": "slides/01-introduction.html#plot-the-last-20-years",
    "href": "slides/01-introduction.html#plot-the-last-20-years",
    "title": "01-Introduction",
    "section": "Plot the last 20 years",
    "text": "Plot the last 20 years\n\nDischarge of the Elbe River, gauge station Dresden, data source BfG"
  },
  {
    "objectID": "slides/01-introduction.html#what-do-these-data-tell-us",
    "href": "slides/01-introduction.html#what-do-these-data-tell-us",
    "title": "01-Introduction",
    "section": "What do these data tell us?",
    "text": "What do these data tell us?\n\n\nWhat is the average discharge? → mean values\nHow much variation is in the data? → variance\nHow likely are droughts or floods? → distribution\nHow precise are our forecasts? → confidence intervals\nWhich factors influence discharge? → correlations"
  },
  {
    "objectID": "slides/01-introduction.html#how-to-start",
    "href": "slides/01-introduction.html#how-to-start",
    "title": "01-Introduction",
    "section": "How to start",
    "text": "How to start\n\n\nMean value: 224\nMedian value: 224\nStandard deviation: 253\nRange: 2, 4500\n\nWhich of these parameters are most appropriate?"
  },
  {
    "objectID": "slides/01-introduction.html#graphics",
    "href": "slides/01-introduction.html#graphics",
    "title": "01-Introduction",
    "section": "Graphics",
    "text": "Graphics"
  },
  {
    "objectID": "slides/01-introduction.html#boxplots",
    "href": "slides/01-introduction.html#boxplots",
    "title": "01-Introduction",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nNote the log scale of y!\nIn the right version, whiskers extend to the most extreme data point which is no more than 1.5 times the interquartile range from the box."
  },
  {
    "objectID": "slides/01-introduction.html#three-ways-to-work-with-statistics",
    "href": "slides/01-introduction.html#three-ways-to-work-with-statistics",
    "title": "01-Introduction",
    "section": "Three ways to work with statistics",
    "text": "Three ways to work with statistics\nDescriptive statistics and graphics\n\nplots, like in the examples\nmean values, standard deviations, …\ninterpret raw data\n\nHypothesis testing\n\ndistinguish effects from random fluctuations\nmake results more convincing\n\nStatistical modelling\n\nmeasure size of effects (e.g. climate trends)\nbuild models that aggregate dependencies\nmachine learning"
  },
  {
    "objectID": "slides/01-introduction.html#statistical-hypothesis-testing",
    "href": "slides/01-introduction.html#statistical-hypothesis-testing",
    "title": "01-Introduction",
    "section": "Statistical hypothesis testing",
    "text": "Statistical hypothesis testing\n\nHow likely is it, that our hypothesis is true?\n\n\nTurn scientific into statistical hypothesis\nEstimate probability (p value) of a given hypothesis Examples\nIs a medical treatment successful or not? → \\(\\chi^2\\)-test\nDoes a specific food diet increase yield of a fish farm? → t-test\nWhich factors (e.g. food, temperature, pH) of a combined treatment influence growth of aquatic animals? → ANOVA\n(How) does observed algal biomass depend on phosphorus?"
  },
  {
    "objectID": "slides/01-introduction.html#statistical-modeling",
    "href": "slides/01-introduction.html#statistical-modeling",
    "title": "01-Introduction",
    "section": "Statistical modeling",
    "text": "Statistical modeling\nFit a statistical model to the data\n\nSelect proper modelling strategy\nDesign statistical models\nMeasure effect size\nSelect the optimum model between different model candidates\n\nExamples\n\nFit a distribution to annual discharge data to estimate the 100 year flood.\nFit an ANOVA model to experimental data to see which factors influence the result most.\nFit a multiple linear model to climate data to see how much climate trends differ between geographical location."
  },
  {
    "objectID": "slides/01-introduction.html#example-compare-two-mean-values",
    "href": "slides/01-introduction.html#example-compare-two-mean-values",
    "title": "01-Introduction",
    "section": "Example: Compare two mean values",
    "text": "Example: Compare two mean values\n\n\nA given data set (Dobson, 1983) contains the birth weight (in g) of 12 boys and 12 girls.\nHas the weight difference something to do with the gender of the babies or is it a purely random fluctuation?"
  },
  {
    "objectID": "slides/01-introduction.html#example-correlation-and-regression",
    "href": "slides/01-introduction.html#example-correlation-and-regression",
    "title": "01-Introduction",
    "section": "Example: Correlation and regression",
    "text": "Example: Correlation and regression\n\n\n\n\n\n\nDependence of chlorophyll concentration in lakes on phosphorus, a regional data set from Koschel and Scheffler (1985) (left) and from Vollenweider and Kerekes (1980) (right).\nWhich of the two figures has greater predictive power? Why?\n\n\n\nThe parameter \\(r\\) is the Pearson correlation coefficient."
  },
  {
    "objectID": "slides/01-introduction.html#required-software",
    "href": "slides/01-introduction.html#required-software",
    "title": "01-Introduction",
    "section": "Required software",
    "text": "Required software\n\nA spreadsheet program, Excel or LibreOffice https://www.libreoffice.org/\nThe R system for data analysis and graphics https://www.r-project.org\nRStudio for making R more user-friendly https://posit.co/download/rstudio-desktop/"
  },
  {
    "objectID": "slides/01-introduction.html#why-r",
    "href": "slides/01-introduction.html#why-r",
    "title": "01-Introduction",
    "section": "Why R?",
    "text": "Why R?\n\n\nStatisticians call it “lingua franca” in computational statistics.\n\nExtremely powerful\nNo other system has so much statistics\nUsed in statistical research\n\nFree (OpenSource)\n\nFree to use\nFree to modify\nFree to contribute\n\nLess complicated than its first appearance:\n\nYes, it needs command line programming\nbut: already a single line can do much\nhuge number of books and online scripts\n\n\n\n\n\n\nIn contrast to other systems Copy & Paste is allowed! – just cite it."
  },
  {
    "objectID": "slides/01-introduction.html#books",
    "href": "slides/01-introduction.html#books",
    "title": "01-Introduction",
    "section": "Books",
    "text": "Books\nStatistics\n\nWell-readable introductions\n\nDalgaard, P., 2008: Introductory Statistics with R. Springer, New York, 2nd edition. (fulltext of the 1st edition freely available)\nVerzani, J. (2019). Using R for introductory statistics. CRC press. Fulltext available via DOI https://doi.org/10.1111/anzs.12146\n\nA very well understandable introduction into many fields: of statistics, especially regression and time series analysis:\n\nKleiber, C. and Zeileis, A., 2008: Applied Econometrics with R, Springer Verlag, New York. https://link.springer.com/book/10.1007/978-0-387-77318-6\n\n\nR Programming\n\nAn introduction to data science using the modern “tidyverse” approach:\n\nWickham, H., Çetinkaya-Rundel, M and Grolemund, G, 2023: R for Data Science. https://r4ds.hadley.nz/\n\n\n\n\n\n\n\n\nAnd lots of material available freely on the internet …"
  },
  {
    "objectID": "slides/05-classtests.html#statistical-test",
    "href": "slides/05-classtests.html#statistical-test",
    "title": "05-Classical Tests",
    "section": "Statistical test",
    "text": "Statistical test\n\nA statistical hypothesis test is a method of statistical inference.\n\nCommonly, two samples are compared, or a sample is compared against properties from an idealized model.\nA hypothesis \\(H_a\\) for the statistical relationship between the two data sets, is compared to an idealized null hypothesis H0 that proposes no relationship between two data sets.\nThe comparison is considered statistically significant if the relationship between the data sets would be an unlikely realization of the null hypothesis according to a threshold probability – the significance level.\n\nadapted from: https://en.wikipedia.org/wiki/Statistical hypothesis testing"
  },
  {
    "objectID": "slides/05-classtests.html#effect-size-and-significance",
    "href": "slides/05-classtests.html#effect-size-and-significance",
    "title": "05-Classical Tests",
    "section": "Effect size and significance",
    "text": "Effect size and significance\n\nIn case of relative mean differences, the relative effect size is:\n\n\\[\n  \\delta = \\frac{\\bar{\\mu}_1-\\bar{\\mu}_2}{\\sigma}=\\frac{\\Delta}{\\sigma}\n\\]\n\nwith:\n\nmean values of two populations \\(\\mu_1, \\mu_2\\)\neffect size \\(\\Delta\\)\nrelative effect size \\(\\delta\\) (also called Cohen’s d)\nsignificance means that an observed effect is unlikely the result of pure random variation."
  },
  {
    "objectID": "slides/05-classtests.html#null-hypothesis-and-alternative-hypothesis",
    "href": "slides/05-classtests.html#null-hypothesis-and-alternative-hypothesis",
    "title": "05-Classical Tests",
    "section": "Null hypothesis and alternative hypothesis",
    "text": "Null hypothesis and alternative hypothesis\n\n\\(H_0\\) null hypothesis: two populations are not different with respect to a certain property.\n\nAssumption: observed effect occured purely at random, true effect is zero.\n\n\\(H_a\\) alternative hypothesis (experimental hypothesis): existence of a certain effect.\n\nAn alternative hypothesis is never completely true or “proven”.\nAcceptance of \\(H_A\\) means only than \\(H_0\\) is unlikely.\n\n“Not significant” means either no effect or sample size too small!\n\nNote: Different meaning of significance (\\(H_0\\) unlikely) and relevance (effect large enough to play a role in practice)."
  },
  {
    "objectID": "slides/05-classtests.html#the-p-value",
    "href": "slides/05-classtests.html#the-p-value",
    "title": "05-Classical Tests",
    "section": "The p-value",
    "text": "The p-value\n\nThe interpretation of the p-value was often confused in the past, even in statistics textbooks, so it is good to refer to a clear definition:\n\n\nThe p-value is defined as the probability of obtaining a result equal to or ‘more extreme’ than what was actually observed, when the null hypothesis is true.\n\n\n\n\nhttps://en.wikipedia.org/wiki/P-value:\nHubbard (2004) Alphabet Soup: Blurring the Distinctions Between p’s and a’s in Psychological Research, Theory Psychology 14(3), 295-327. DOI: 10.1177/0959354304043638"
  },
  {
    "objectID": "slides/05-classtests.html#alpha-and-beta-errors",
    "href": "slides/05-classtests.html#alpha-and-beta-errors",
    "title": "05-Classical Tests",
    "section": "Alpha and beta errors",
    "text": "Alpha and beta errors\n\n\n\n\n\n\n\n\n\nReality\nDecision of the test\ncorrect?\nprobability\n\n\n\n\n\\(H_0\\) = true\nsignificant\nno\n\\(\\alpha\\)-error\n\n\n\\(H_0\\) = false\nnot significant\nno\n\\(\\beta\\)-error\n\n\n\\(H_0\\) = true\nnot significant\nyes\n\\(1-\\alpha\\)\n\n\n\\(H_0\\) = false\nsignificant\nyes\n\\(1-\\beta\\) (power)\n\n\n\n\n\n\n\n\n\n1.\\(H_0\\) falsely rejected (error of the first kind or \\(\\alpha\\)-error)\n\nwe claim an effect, that does not exist, e.g. a drug with no effect\n\n2.\\(H_0\\) falsely retained (error of the second kind or \\(\\beta\\)-error)\n\ntypical case in small studies, where effect was not enough to detect existing effects\n\nUse in practice\n\ncommon convention in environmental sciences: \\(\\alpha=0.05\\), must be set beforehand\n\\(\\beta=f(\\alpha, \\text{effectsize}, \\text{sample size}, \\text{kind of test})\\), should be \\(\\le 0.2\\)"
  },
  {
    "objectID": "slides/05-classtests.html#significance-and-relevance",
    "href": "slides/05-classtests.html#significance-and-relevance",
    "title": "05-Classical Tests",
    "section": "Significance and relevance",
    "text": "Significance and relevance\n\nSignificance is not the only important. It is often more important to focus on effect size and relevance.\nWhen evaluating significant effects, it is always necessary to look also at the effect size. While significance means that the null hypothesis \\(H_0\\) is unlikely in a statistical sense, relevance means that the effect size is large enough to play a role in practice. This means that whether an effect can be relevant or not depends on its effect size and the field of application.\nLet’s for example consider a vaccination. If a vaccine had a significant effect in a clinical test, but protected only 10 out of 1000 people, one would not consider this effect as relevant and not produce this vaccine.\nOn the other hand, even small effects can be relevant. So if a toxic substance would have an effect on 1 out of 1000 people to produce cancer, we would consider this as relevant. To detect this as a significant effect would need an epidemiological study with a large number of people. But as it is highly relevant, it is worth the effort."
  },
  {
    "objectID": "slides/05-classtests.html#take-home-messages",
    "href": "slides/05-classtests.html#take-home-messages",
    "title": "05-Classical Tests",
    "section": "Take home messages",
    "text": "Take home messages\n\n\nA p-value measures the probability that a purely random effect would be equally or more extreme than an observed effect.\n“Significant” means that an observed result is unlikely to have occurred by chance alone.\n“Not significant” means either “no effect” or “sample size too small”.\nDon’t focus on p-values alone. Never forget to report also sample size, effect size and relevance of your results.\nWith large data sets, the p-value loses importance. It is then easy to find significant effects, but it is often very small and not relevant in practice.\nThe p-value is an important tool in classical statistics, but its abuse can lead to mis-interpretation."
  },
  {
    "objectID": "slides/05-classtests.html#one-sample-t-test",
    "href": "slides/05-classtests.html#one-sample-t-test",
    "title": "05-Classical Tests",
    "section": "One sample t-Test",
    "text": "One sample t-Test\n\n\ntests if a sample is from a population with given mean value \\(\\mu\\)\nbased on checking if the population mean \\(\\mu\\) is in the confidence interval of \\(\\bar{x}\\)\n\n\nLet’s assume a sample of size with \\(n=10, \\bar{x}=5.5, s=1\\) and \\(\\mu=5\\).\nEstimate the 95% confidence interval of \\(\\bar{x}\\):\n\n\\[\nCI = \\bar{x} \\pm t_{1-\\alpha/2, n-1} \\cdot s_{\\bar{x}}\n\\] with \\[\ns_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\qquad \\text{(standard error)}\n\\]\nDifferent ways of calculation shown at the next slides"
  },
  {
    "objectID": "slides/05-classtests.html#remember-standard-deviation-and-standard-error",
    "href": "slides/05-classtests.html#remember-standard-deviation-and-standard-error",
    "title": "05-Classical Tests",
    "section": "Remember: standard deviation and standard error",
    "text": "Remember: standard deviation and standard error\n\n Visualization of a one-sample t-test. Left: original distribution of the data measured by standard deviation, right: distribution of mean values, measured by its standard error. \n\\[\ns_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\qquad \\text{(standard error)}\n\\]\n\nstandard error < standard deviation\nmeasures precision of the mean value\nCLT!\n\nThe test is based on the distribution of the means, not distribution of original data."
  },
  {
    "objectID": "slides/05-classtests.html#method-1-is-mu-in-the-confidence-interval",
    "href": "slides/05-classtests.html#method-1-is-mu-in-the-confidence-interval",
    "title": "05-Classical Tests",
    "section": "Method 1: Is \\(\\mu\\) in the confidence interval?",
    "text": "Method 1: Is \\(\\mu\\) in the confidence interval?\n\n\nSample: \\(n=10, \\bar{x}=5.5, s=1\\) and \\(\\mu=5\\)\nLet \\(\\alpha = 0.05\\), we get a two-sided 95% confidence interval with:\n\n\\[\\bar{x} \\pm t_{0,975, n-1} \\cdot \\frac{s}{\\sqrt{n}}\\]\n\n\n5.5 + c(-1, 1) * qt(0.975, 10-1) * 1/sqrt(10)\n\n[1] 4.784643 6.215357\n\n\n\n\n\nCheck if \\(\\mu=5.0\\) is in this interval?\nYes, it is inside \\(\\Rightarrow\\) difference not significant."
  },
  {
    "objectID": "slides/05-classtests.html#method-2-comparison-with-a-tabulated-t-value",
    "href": "slides/05-classtests.html#method-2-comparison-with-a-tabulated-t-value",
    "title": "05-Classical Tests",
    "section": "Method 2: Comparison with a tabulated t-value",
    "text": "Method 2: Comparison with a tabulated t-value\n\nRearrange the equation of the confidence interval, to calculate an observed \\(t_{obs}\\)\n\n\\[\nt_{obs} = |\\bar{x}-\\mu | \\cdot \\frac{1}{s_{\\bar{x}}} = \\frac{|\\bar{x}-\\mu |}{s} \\cdot \\sqrt{n} = \\frac{|5.5 -5.0|}{1.0} \\cdot \\sqrt{10}\n\\]\nWe can calculate this in R:\n\nt <- abs(5.5 - 5.0) / 1.0 * sqrt(10)\nt\n\n[1] 1.581139\n\n\n\nCompare \\(t_{obs}\\) with a tabulated value\n\n\n“Old style”: find critical t-value in a table for given \\(\\alpha\\) and degrees of freedom (\\(n-1\\))\nFor \\(\\alpha=0.05\\) and two-sided, this is: \\(t_{1-\\alpha/2, n-1} = 2.26\\).\n\nComparison: \\(1.58 < 2.26\\) \\(\\Rightarrow\\) no significant difference between \\(\\bar{x}\\) and \\(\\mu\\)."
  },
  {
    "objectID": "slides/05-classtests.html#method-3-calculation-of-the-p-value-from-t_obs",
    "href": "slides/05-classtests.html#method-3-calculation-of-the-p-value-from-t_obs",
    "title": "05-Classical Tests",
    "section": "Method 3: Calculation of the p-value from \\(t_{obs}\\)",
    "text": "Method 3: Calculation of the p-value from \\(t_{obs}\\)\n\n\nuse computerized probability function (pt) instead of table lookup\n\\(t = t_{obs}\\) and the degrees of freedom (\\(n-1\\)):\n\n\n\n2 * (1 - pt(t, df = 10 - 1)) # 2 * (1 - p) is re-arranged from 1-alpha/2\n\n[1] 0.1483047\n\n\nThis p-value = 0.1483047 is greater than \\(0.05\\) so we consider the difference as not significant.\n\nFAQ: less than or greater than?\n\n\n\n\n\n\n\n\n\n\np-value\n\\(\\text{p-value} < \\alpha\\)\nnull hypothesis unlikely\nsignificant\n\n\ntest statistic\n\\(t_{obs} > t_{1-\\alpha/2, n-1}\\)\neffect exceeds confint.\nsignificant"
  },
  {
    "objectID": "slides/05-classtests.html#method-4-built-in-t-test-function-in-r",
    "href": "slides/05-classtests.html#method-4-built-in-t-test-function-in-r",
    "title": "05-Classical Tests",
    "section": "Method 4: Built-in t-test function in R",
    "text": "Method 4: Built-in t-test function in R\n\nThe same can be done much easier with the computer in R.\nLet’s assume we have a sample with \\(\\bar{x}=5, s=1\\):\n\n## define sample\nx <- c(5.5, 3.5, 5.4, 5.3, 6, 7.2, 5.4, 6.3, 4.5, 5.9)\n\n## perform one-sample t-test\nt.test(x, mu=5)\n\n\n    One Sample t-test\n\ndata:  x\nt = 1.5811, df = 9, p-value = 0.1483\nalternative hypothesis: true mean is not equal to 5\n95 percent confidence interval:\n 4.784643 6.215357\nsample estimates:\nmean of x \n      5.5 \n\n\nThe test returns the observed t-value, the 95% confidence interval and the p-value.\nAn important difference is, that this method needs the original data, while the other methods need only mean, standard deviation and sample size."
  },
  {
    "objectID": "slides/05-classtests.html#two-sample-t-test",
    "href": "slides/05-classtests.html#two-sample-t-test",
    "title": "05-Classical Tests",
    "section": "Two sample t-test",
    "text": "Two sample t-test\n\nThe two-sample t-test compares two independent samples:\n\nx1 <- c(5.3, 6.0, 7.1, 6.4, 5.7, 4.9, 5.0, 4.6, 5.7, 4.0, 4.5, 6.5)\nx2 <- c(5.8, 7.1, 5.8, 7.0, 6.7, 7.7, 9.2, 6.0, 7.2, 7.8, 7.8, 5.7)\nt.test(x1, x2)\n\n\n    Welch Two Sample t-test\n\ndata:  x1 and x2\nt = -3.7185, df = 21.611, p-value = 0.001224\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -2.3504462 -0.6662205\nsample estimates:\nmean of x mean of y \n 5.475000  6.983333 \n\n\n\n\n\\(\\rightarrow\\) both samples differ significantly (\\(p < 0.05\\))\nNote: R has not performed the “ordinary” t-test but the Welch test (= heteroscedastic t-test)\nwhere variances of both samples don’t need to be identical."
  },
  {
    "objectID": "slides/05-classtests.html#hypothesis-and-formula-of-the-two-sample-t-test",
    "href": "slides/05-classtests.html#hypothesis-and-formula-of-the-two-sample-t-test",
    "title": "05-Classical Tests",
    "section": "Hypothesis and formula of the two-sample t-test",
    "text": "Hypothesis and formula of the two-sample t-test\n\n\n\\(H_0\\) \\(\\mu_1 = \\mu_2\\)\n\\(H_a\\) the two means are different\ntest criterion\n\\[\nt_{obs} =\\frac{|\\bar{x}_1-\\bar{x}_2|}{s_{tot}} \\cdot \\sqrt{\\frac{n_1 n_2}{n_1+n_2}}\n\\]\n\n\n\n\n\n\n\n\npooled standard deviation\n\\[\ns_{tot} = \\sqrt{{({n}_1 - 1)\\cdot s_1^2 + ({n}_2 - 1)\\cdot s_2^2\n\\over ({n}_1 + {n}_2 - 2)}}\n\\]\nassumptions: independence, equal variances, approximate normal distribution"
  },
  {
    "objectID": "slides/05-classtests.html#the-welch-test",
    "href": "slides/05-classtests.html#the-welch-test",
    "title": "05-Classical Tests",
    "section": "The Welch test",
    "text": "The Welch test\n\nKnown as t-test for samples with unequal variance, works also for equal variance!\n\nTest criterion:\n\\[\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{s^2_{\\bar{x}_1} + s^2_{\\bar{x}_2}}}\n\\]\nStandard error of each sample:\n\\[\ns_{\\bar{x}_i} = \\frac{s_i}{\\sqrt{n_i}}\n\\] Corrected degrees of freedom:\n\\[\n\\text{df} = \\frac{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2}}{\\frac{s^4_1}{n^2_1(n_1-1)} + \\frac{s^4_2}{n^2_2(n_2-1)}}\n\\]"
  },
  {
    "objectID": "slides/05-classtests.html#equality-of-variance-f-test",
    "href": "slides/05-classtests.html#equality-of-variance-f-test",
    "title": "05-Classical Tests",
    "section": "Equality of variance: F-test",
    "text": "Equality of variance: F-test\n\n\\(H_0\\): \\(\\sigma_1^2 = \\sigma_2^2\\)\n\\(H_a\\): variances unequal\nTest criterion:\n\\[F = \\frac{s_1^2}{s_2^2} \\]\n\nlarger of the two variances in the enumerator \\((s^2_1 > s^2_2)\\)\nseparate degrees of freedom (\\(n-1\\))\n\n\n\n\n\n\n\n\n\nExample:\n\n\\(s_1=1\\), \\(s_2 =2\\), \\(n_1=5, n_2=10, F=\\frac{2^2}{1^2}=4\\)\ndeg. of freedom: \\(9 \\atop 4\\)\n\n\\(\\Rightarrow\\) \\(F_{9, 4, \\alpha=0.975} = 8.9 > 4 \\quad\\rightarrow\\) not significant"
  },
  {
    "objectID": "slides/05-classtests.html#homogeneity-of-variances-with-2-samples",
    "href": "slides/05-classtests.html#homogeneity-of-variances-with-2-samples",
    "title": "05-Classical Tests",
    "section": "Homogeneity of variances with > 2 samples",
    "text": "Homogeneity of variances with > 2 samples\n\n\n\n\n\n\n\n\nBartlett’s test:\n\nbartlett.test(list(x1, x2, x3))\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  list(x1, x2, x3)\nBartlett's K-squared = 7.7136, df = 2, p-value = 0.02114\n\n\n Fligner-Killeen test (recommended):\n\nfligner.test(list(x1, x2, x3))\n\n\n    Fligner-Killeen test of homogeneity of variances\n\ndata:  list(x1, x2, x3)\nFligner-Killeen:med chi-squared = 2.2486, df = 2, p-value = 0.3249\n\n\n\n\n\n\n\n\n\n\n\ntests are often used to check assumptions of the ANOVA"
  },
  {
    "objectID": "slides/05-classtests.html#recommendation-for-two-sample-t-tests",
    "href": "slides/05-classtests.html#recommendation-for-two-sample-t-tests",
    "title": "05-Classical Tests",
    "section": "Recommendation for two sample t-tests",
    "text": "Recommendation for two sample t-tests\n\nTraditional procedure:\n\nTest for equal variances using the F-test: var.test(x, y)\nIf variances are equal: t.test(x, y, var.equal=TRUE)\notherwise, use t.test(x, y) (= Welch test)\nCheck if both samples follow a normal distribution.\n\n\nMore modern recommendation:\n\nDon’t use pre-tests!\nUse always the Welch test: t.test(x, y)\nCheck approximate normal distribution by using box-plots. Not necessary if \\(n\\) is large.\n\nsee Zimmerman (2004) or Wikipedia."
  },
  {
    "objectID": "slides/05-classtests.html#paired-t-test",
    "href": "slides/05-classtests.html#paired-t-test",
    "title": "05-Classical Tests",
    "section": "Paired t-Test",
    "text": "Paired t-Test\n\nsometimes also called “t-test of dependent samples”\n\nthe term “dependent” can be misleading, better “pairwise”\nvalues within samples must still be independent\n\nexamples: left arm / right arm; before / after\nis essentially a one-sample t-test of pairwise differences against \\(\\mu=0\\)\n\nadvantage: eliminates “covariate”\n\n\n\nx1 <- c(2, 3, 4, 5, 6)\nx2 <- c(3, 4, 7, 6, 8)\nt.test(x1, x2, var.equal=TRUE)\n\n\n    Two Sample t-test\n\ndata:  x1 and x2\nt = -1.372, df = 8, p-value = 0.2073\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.28924  1.08924\nsample estimates:\nmean of x mean of y \n      4.0       5.6 \n\n\np=0.20, not significant\n\n\n\nx1 <- c(2, 3, 4, 5, 6)\nx2 <- c(3, 4, 7, 6, 8)\nt.test(x1, x2, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  x1 and x2\nt = -4, df = 4, p-value = 0.01613\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.710578 -0.489422\nsample estimates:\nmean difference \n           -1.6 \n\n\np=0.016, significant\n\nIt can be seen that the paired t-test has a greater discriminatory power in this case."
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney-and-wilcoxon-test",
    "href": "slides/05-classtests.html#mann-whitney-and-wilcoxon-test",
    "title": "05-Classical Tests",
    "section": "Mann-Whitney and Wilcoxon-test",
    "text": "Mann-Whitney and Wilcoxon-test\n\n\nNon-parametric tests:\n\nNo assumptions about shape and parameters of distribution, but\ndistributions should be similar, otherwise test may be misleading.\n\nMann-Whitney U-test and Wilcoxon-test are very similar.\nIn a strict sense, “Wilcoxon” is the version for paired data\n\n Basic principle: Count of so-called “inversions” of ranks, where samples overlap\n\nSample A: 1, 3, 4, 5, 7\nSample B: 6, 8, 9, 10, 11\nBoth samples ordered together: 1, 3, 4, 5, 6, 7, 8, 9, 10, 11\nInversions: \\(\\rightarrow\\) \\(U = 1\\)"
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney-test-procedure-in-practice",
    "href": "slides/05-classtests.html#mann-whitney-test-procedure-in-practice",
    "title": "05-Classical Tests",
    "section": "Mann-Whitney test procedure in practice",
    "text": "Mann-Whitney test procedure in practice\n\n\nAssign ranks \\(R_A\\) and \\(R_B\\) to both samples \\(A\\), and \\(B\\) with sample size \\(m\\) and \\(n\\).\nCalculate number of inversions \\(U\\):\n\n\\[\\begin{align*}\n     U_A &= m \\cdot n + \\frac{m (m + 1)}{2} - \\sum_{i=1}^m R_A \\\\\n     U_B &= m \\cdot n + \\frac{n (n + 1)}{2} - \\sum_{i=1}^n R_B \\\\\n     U   &= \\min(U_A, U_B)\n\\end{align*}\\]\n\nCritical values of \\(U\\) can be found in common statistics text books.\nNot necessary in R, p-value directly printed.\nNote: Use special version wilcox.exact with correction if sample has ties."
  },
  {
    "objectID": "slides/05-classtests.html#mann-whitney---wilcoxon-test-in-r",
    "href": "slides/05-classtests.html#mann-whitney---wilcoxon-test-in-r",
    "title": "05-Classical Tests",
    "section": "Mann-Whitney - Wilcoxon-test in R",
    "text": "Mann-Whitney - Wilcoxon-test in R\n\n\nA <- c(1, 3, 4, 5, 7)\nB <- c(6, 8, 9, 10, 11)\n\nwilcox.test(A, B) # use optional argument `paired = TRUE` for paired data.\n\n\n    Wilcoxon rank sum exact test\n\ndata:  A and B\nW = 1, p-value = 0.01587\nalternative hypothesis: true location shift is not equal to 0\n\n\n\nMann-Whitney - Wilcoxon-test with tie correction\n\napplied if the rank differences contain doubled values\n\n\nA <- c(1, 3, 4, 5, 7)\nB <- c(6, 8, 9, 10, 11)\n\n\nlibrary(\"exactRankTests\")\nwilcox.exact(A, B, paired=TRUE)\n\n\n    Exact Wilcoxon signed rank test\n\ndata:  A and B\nV = 0, p-value = 0.0625\nalternative hypothesis: true mu is not equal to 0"
  },
  {
    "objectID": "slides/05-classtests.html#permutation-methods",
    "href": "slides/05-classtests.html#permutation-methods",
    "title": "05-Classical Tests",
    "section": "Permutation methods",
    "text": "Permutation methods\n\nBasic principle: Estimation of a test statistic \\(\\xi_{obs}\\) from sample,\nResampling: Simulate many \\(\\xi_{i, sim}\\) from randomly permuted data set (\\(n = 999\\) or more)\nWhere does \\(\\xi_{est}\\) appear within the ordered series of simulated values \\(\\xi_{i, sim}\\)?\n\n\nLet \\(\\xi_{obs}\\) be \\(4.5\\) in our example, then \\(\\Rightarrow\\) \\(p= 0.97\\)."
  },
  {
    "objectID": "slides/05-classtests.html#testing-for-distributions",
    "href": "slides/05-classtests.html#testing-for-distributions",
    "title": "05-Classical Tests",
    "section": "Testing for distributions",
    "text": "Testing for distributions\nNominal variables\n\n\\(\\chi^2\\)-test\nFisher’s exact test\n\nOrdinal variables\n\nCramér-von-Mises-Test\n\\(\\rightarrow\\) more powerful than \\(\\chi^2\\) or KS-test\n\nMetric scales\n\nKolmogorov-Smirnov-Test (KS-test)\nShapiro-Wilks-Test (for normal distribution)"
  },
  {
    "objectID": "slides/05-classtests.html#contingency-tables-for-nominal-variables",
    "href": "slides/05-classtests.html#contingency-tables-for-nominal-variables",
    "title": "05-Classical Tests",
    "section": "Contingency tables for nominal variables",
    "text": "Contingency tables for nominal variables\n\nused for nominal (i.e. categorical or qualitative) data\nexamples: eye and hair color, medical treatment and the number of cured/not cured\nimportant: use absolute mesurements (true numbers!), not percentages or other calculated data (e.g. not something like biomass per area)\n\nData example\n\nDaphnia (water flee)-clones and their preferred depth in a lake\nfood algae in the deep water zone, poor of oxygen\nonly adapted clones with high haemoglobin can dive into deep water\n\n\n\n\nClone\nUpper layer\nDeep layer\n\n\n\n\nA\n50\n87\n\n\nB\n37\n78\n\n\nC\n72\n45"
  },
  {
    "objectID": "slides/05-classtests.html#calculation-of-the-chi2-test",
    "href": "slides/05-classtests.html#calculation-of-the-chi2-test",
    "title": "05-Classical Tests",
    "section": "Calculation of the \\(\\chi^2\\)-test",
    "text": "Calculation of the \\(\\chi^2\\)-test\n\nObserved frequencies \\(O_{ij}\\) and sums of rows and columns:\n\n\n\n\n\nClone A\nClone B\nClone C\nSum \\(s_i\\)\n\n\n\n\nEpilimnion\n50\n37\n72\n159\n\n\nHypolimnion\n87\n78\n45\n210\n\n\nSum {\\(s_j\\)}\n137\n115\n117\n\\(n=369\\)\n\n\n\n\n\n\n\n\n\n\n\nExpected frequencies \\(E_{ij}\\) under the \\(H_0\\): \\({\\mathbf E = s_i \\otimes s_j} / n\\)\n\n\n\n\n\nClone A\nClone B\nClone C\n\n\n\n\nEpilimnion\n59.0\n49.6\n50.4\n\n\nHypolimnion\n78.0\n65.4\n66.6\n\n\n\n\n\n\n\n\n\n\nCalculate \\(\\hat{\\chi}^2 = \\sum_{i, j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\\) with \\((n_{row} - 1) \\cdot (n_{col} - 1)\\) degrees of freedom.\n\n\nCompare with critical \\(\\chi^2\\) from table.\nNote: The results are only reliable if all observed frequencies are \\(\\geq 5\\).\nFor smaller samples, use Fisher’s exact test"
  },
  {
    "objectID": "slides/05-classtests.html#the-chi2-test-in-r",
    "href": "slides/05-classtests.html#the-chi2-test-in-r",
    "title": "05-Classical Tests",
    "section": "The \\(\\chi^2\\)-test in R",
    "text": "The \\(\\chi^2\\)-test in R\n\nOrganize data in a matrix with 3 rows (for the clones) and 2 columns (for the depths):\n\n\nx <- matrix(c(50, 37, 72, 87, 78, 45), ncol=2)\nx\n\n     [,1] [,2]\n[1,]   50   87\n[2,]   37   78\n[3,]   72   45\n\n\n\n\n\nchisq.test(x)\n\n\n    Pearson's Chi-squared test\n\ndata:  x\nX-squared = 24.255, df = 2, p-value = 5.408e-06"
  },
  {
    "objectID": "slides/05-classtests.html#fishers-exact-test",
    "href": "slides/05-classtests.html#fishers-exact-test",
    "title": "05-Classical Tests",
    "section": "Fisher’s exact test",
    "text": "Fisher’s exact test\n\n\n\nx <- matrix(c(50, 37, 72, 87, 78, 45), ncol=2)\nx\n\n     [,1] [,2]\n[1,]   50   87\n[2,]   37   78\n[3,]   72   45\n\n\n\nfisher.test(x)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  x\np-value = 5.807e-06\nalternative hypothesis: two.sided\n\n\n\n\n\\(\\rightarrow\\) significant correlation between the clones and their location.\n\ndependency between clones and vertical distribution in the lake"
  },
  {
    "objectID": "slides/05-classtests.html#favorite-numbers-of-hse-students",
    "href": "slides/05-classtests.html#favorite-numbers-of-hse-students",
    "title": "05-Classical Tests",
    "section": "Favorite numbers of HSE students",
    "text": "Favorite numbers of HSE students\n\n\nNumbers from 1..9, \\(n=34\\)\n\\(H_0\\): equal probability of all numbers \\(1/9\\) (discrete uniform distribution)\n\\(H_A\\): some numbers are favored \\(\\rightarrow\\) departure from discrete uniform"
  },
  {
    "objectID": "slides/05-classtests.html#chisquare-test",
    "href": "slides/05-classtests.html#chisquare-test",
    "title": "05-Classical Tests",
    "section": "Chisquare test",
    "text": "Chisquare test\n\n\n\nobsfreq <- c(1, 1, 6, 2, 2, 5, 8, 6, 3)\nchisq.test(obsfreq)\n\n\n    Chi-squared test for given probabilities\n\ndata:  obsfreq\nX-squared = 13.647, df = 8, p-value = 0.09144\n\nchisq.test(obsfreq, simulate.p.value=TRUE, B=1000)\n\n\n    Chi-squared test for given probabilities with simulated p-value (based\n    on 1000 replicates)\n\ndata:  obsfreq\nX-squared = 13.647, df = NA, p-value = 0.0969\n\n\n\n\n\none-sample \\(\\chi^2\\)-test. It tests for equality of frequency in all classes.\nThe simulation-based version of the test (with 1000 replicates) is slightly more precise than the standard \\(\\chi^2\\)-test, but both ar not significant."
  },
  {
    "objectID": "slides/05-classtests.html#cramér-von-mises-test",
    "href": "slides/05-classtests.html#cramér-von-mises-test",
    "title": "05-Classical Tests",
    "section": "Cramér-von-Mises-Test",
    "text": "Cramér-von-Mises-Test\n\n\\[\nT = n \\omega^2 = \\frac{1}{12n} + \\sum_{i=1}^n \\left[ \\frac{2i-1}{2n}-F(x_i) \\right]^2\n\\]"
  },
  {
    "objectID": "slides/05-classtests.html#cramér-von-mises-test-in-r",
    "href": "slides/05-classtests.html#cramér-von-mises-test-in-r",
    "title": "05-Classical Tests",
    "section": "Cramér-von-Mises-Test in R",
    "text": "Cramér-von-Mises-Test in R\n\nlibrary(dgof)\nobsfreq <- c(1, 1, 6, 2, 2, 5, 8, 6, 3)\n\n## CvM-test needs individual values, not class frequencies\nx <- rep(1:length(obsfreq), obsfreq)\nx\n\n [1] 1 2 3 3 3 3 3 3 4 4 5 5 6 6 6 6 6 7 7 7 7 7 7 7 7 8 8 8 8 8 8 9 9 9\n\n\n\n\n## create a cumulative function with equal probability of all cases\ncdf <- stepfun(1:9, cumsum(c(0, rep(1/9, 9))))\ncdf <- ecdf(1:9)\n\n## perform the test\ncvm.test(x, cdf)\n\n\n    Cramer-von Mises - W2\n\ndata:  x\nW2 = 0.51658, p-value = 0.03665\nalternative hypothesis: Two.sided\n\n\n\nThe Cramér-von-Mises-test works with the original, unbinned values\nUse of cumulative function respects order of classes \\(\\rightarrow\\) more powerful, than \\(\\chi^2\\)-test."
  },
  {
    "objectID": "slides/05-classtests.html#test-distribution-type-of-metric-variables",
    "href": "slides/05-classtests.html#test-distribution-type-of-metric-variables",
    "title": "05-Classical Tests",
    "section": "Test distribution type of metric variables",
    "text": "Test distribution type of metric variables\n\n\n\nhistogram, boxplot, quantile-quantile plot\nShapiro Wilk W-test\nBox-Cox method\nsee section Distributions"
  },
  {
    "objectID": "slides/05-classtests.html#correlation",
    "href": "slides/05-classtests.html#correlation",
    "title": "05-Classical Tests",
    "section": "Correlation",
    "text": "Correlation\n\nFrequencies of nominal variables\n\n\\(\\chi^2\\)-test\nFisher’s exact test\n\n⇒ dependence between plant society and soil type\n(see before)\nOrdinal variables\n\nSpearman-Correlation\n\n\\(\\rightarrow\\) rank numbers\nMetric scales\n\nPearson-correlation\nSpearman-correlation"
  },
  {
    "objectID": "slides/05-classtests.html#variance-and-covariance",
    "href": "slides/05-classtests.html#variance-and-covariance",
    "title": "05-Classical Tests",
    "section": "Variance and Covariance",
    "text": "Variance and Covariance\n\n\nVariance\n\nmeasures variation of a single variable\n\n\\[\n  s^2_x = \\frac{\\text{sum of squares}}{\\text{degrees of freedom}}=\\frac{\\sum_{i=1}^n (x_i-\\bar{x})^2}{n-1}\n\\]\nCovariance\n\nmeasures how two variables change together\n\n\\[\n  q_{x,y} = \\frac{\\sum_{i=1}^n (x_i-\\bar{x})(y_i-\\bar{y})}{n-1}\n\\]\nCorrelation: scaled to \\((-1, +1)\\)\n\\[\n  r_{x,y} = \\frac{q_{x,y}}{s_x \\cdot s_y}\n\\]"
  },
  {
    "objectID": "slides/05-classtests.html#correlation-coefficient-after-pearson",
    "href": "slides/05-classtests.html#correlation-coefficient-after-pearson",
    "title": "05-Classical Tests",
    "section": "Correlation coefficient after Pearson",
    "text": "Correlation coefficient after Pearson\n\n\n\nthe usual correlation coefficient that we all know\ntests for linear dependence\n\n\\[\nr_p=\\frac{\\sum{(x_i-\\bar{x})  (y_i-\\bar{y})}}\n       {\\sqrt{\\sum(x_i-\\bar{x})^2\\sum(y_i-\\bar{y})^2}}\n\\]\nOr:\n\\[\nr_p=\\frac {\\sum xy - \\sum y \\sum y / n}\n        {\\sqrt{(\\sum x^2-(\\sum x)^2/n)(\\sum y^2-(\\sum y)^2/n)}}\n\\] \nRange of values: \\(-1 \\le r_p \\le +1\\)\n\n\n\n\\(0\\)\nno interdependence\n\n\n\\(+1 \\,\\text{or}\\,-1\\)\nstrictly positive resp. negative dependence\n\n\n\\(0 < |r_p| < 1\\)\npositive resp. negative dependence"
  },
  {
    "objectID": "slides/05-classtests.html#which-size-of-correlation-indicates-dependency",
    "href": "slides/05-classtests.html#which-size-of-correlation-indicates-dependency",
    "title": "05-Classical Tests",
    "section": "Which size of correlation indicates dependency?",
    "text": "Which size of correlation indicates dependency?\n\n\n\n\n\n\n\\(r=0.4, \\quad p=0.0039\\)\n\n\n\n\n\n\n\n\\(r=0.85, \\quad p=0.07\\)"
  },
  {
    "objectID": "slides/05-classtests.html#significant-correlation",
    "href": "slides/05-classtests.html#significant-correlation",
    "title": "05-Classical Tests",
    "section": "Significant correlation?",
    "text": "Significant correlation?\n\\[\n\\hat{t}_{\\alpha/2;n-2} =\\frac{|r_p|\\sqrt{n-2}}{\\sqrt{1-r^2_p}}\n\\]\n\\(t=0.829 \\cdot \\sqrt{1000-2}/\\sqrt{1-0.829^2}=46.86, df=998\\)\n Quick test: critical values for \\(r_p\\)\n\n\n\n\\(n\\)\nd.f.\n\\(t\\)\n\\(r_{crit}\\)\n\n\n3\n1\n12.706\n0.997\n\n\n5\n3\n3.182\n0.878\n\n\n10\n8\n2.306\n0.633\n\n\n20\n18\n2.101\n0.445\n\n\n50\n48\n2.011\n0.280\n\n\n100\n98\n1.984\n0.197\n\n\n1000\n998\n1.962\n0.062"
  },
  {
    "objectID": "slides/05-classtests.html#rank-correlation-according-to-spearman",
    "href": "slides/05-classtests.html#rank-correlation-according-to-spearman",
    "title": "05-Classical Tests",
    "section": "Rank-correlation according to Spearman",
    "text": "Rank-correlation according to Spearman\n\n\nmeasures monotonous (and not necessarily linear) dependence\nestimation from rank differences:\n\n\\[\nr_s=1-\\frac{6 \\sum d^2_i}{n(n^2-1)}\n\\]\n\nor, alternatively: Pearson-correlation of ranked data (necessary in case of ties).\nTest: for \\(n < 10\\) \\(\\rightarrow\\) table of critical values\n\nfor \\(10 \\leq n\\) \\(\\rightarrow\\) \\(t\\)-distribution\n\\[\n   \\hat{t}_{1-\\frac{\\alpha}{2};n-2}\n      =\\frac{|r_s|}{\\sqrt{1-r^2_S}} \\sqrt{n-2}\n\\]\n\n\nComputer statistics packages use a special algorithm (algorithm AS 89 according to Best and Roberts, 1975)."
  },
  {
    "objectID": "slides/05-classtests.html#example",
    "href": "slides/05-classtests.html#example",
    "title": "05-Classical Tests",
    "section": "Example",
    "text": "Example\n\n\n\n\n\\(x\\)\n\\(y\\)\n\\(R_x\\)\n\\(R_y\\)\n\\(d\\)\n\\(d^2\\)\n\n\n\n\n1\n2.7\n1\n1\n0\n0\n\n\n2\n7.4\n2\n2\n0\n0\n\n\n3\n20.1\n3\n3\n0\n0\n\n\n4\n500.0\n4\n5\n-1\n1\n\n\n5\n148.4\n5\n4\n+1\n1\n\n\n\n\n\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\n\\[\nr_s=1-\\frac{6 \\cdot 2}{5\\cdot (25-1)}=1-\\frac{12}{120}=0.9\n\\]\nFor comparison: \\(r_p=0.58\\)"
  },
  {
    "objectID": "slides/05-classtests.html#application-of-spearmans-r_s",
    "href": "slides/05-classtests.html#application-of-spearmans-r_s",
    "title": "05-Classical Tests",
    "section": "Application of Spearman’s-\\(r_s\\)",
    "text": "Application of Spearman’s-\\(r_s\\)\n\nAdvantages\n\ndistribution free (does not require normal distribution),\ndetects any dependence,\nnot much affected by outliers.\n\nDisadvantages:\n\ncertain information loss due to ranking,\nno information about type of dependency,\nno direct relationship to coefficient of determination.\n\nConclusion: \\(r_s\\) is nevertheless highly recommended!"
  },
  {
    "objectID": "slides/05-classtests.html#correlation-coefficients-in-r",
    "href": "slides/05-classtests.html#correlation-coefficients-in-r",
    "title": "05-Classical Tests",
    "section": "Correlation coefficients in R",
    "text": "Correlation coefficients in R\n\nPearson’s product-moment correlation coefficient\nSpearman’s rank correlation coefficient\n\n\nx <- c(1, 2, 3, 5, 7,  9)\ny <- c(3, 2, 5, 6, 8, 11)\ncor.test(x, y, method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = 7.969, df = 4, p-value = 0.001344\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7439930 0.9968284\nsample estimates:\n      cor \n0.9699203 \n\n\nIf linearity or normality of residuals is doubtful, use a rank correlation\n\ncor.test(x, y, method=\"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  x and y\nS = 2, p-value = 0.01667\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.9428571"
  },
  {
    "objectID": "slides/05-classtests.html#problematic-cases",
    "href": "slides/05-classtests.html#problematic-cases",
    "title": "05-Classical Tests",
    "section": "Problematic cases",
    "text": "Problematic cases"
  },
  {
    "objectID": "slides/05-classtests.html#outlook-more-than-two-independent-variables",
    "href": "slides/05-classtests.html#outlook-more-than-two-independent-variables",
    "title": "05-Classical Tests",
    "section": "Outlook: More than two independent variables",
    "text": "Outlook: More than two independent variables\n\nMultiple correlation\n\nExample: Chl-a=\\(f(x_1, x_2, x_3, \\dots)\\), where \\(x_i\\) = biomass of the \\(i\\)th phytoplankton species.\nmultiple correlation coefficient\npartial correlation coefficient\nattractive method \\(\\leftrightarrow\\) but difficult in practice:\n\n“independent” variables may correlate with each other (multi-collinearity) \\(\\Rightarrow\\) bias of the multiple \\(r\\).\nnon-linearities are even more difficult to handle than in the two-sample case.\n\n\nRecommendation:\n\nUse multivariate methods (NMDS, PCA, …) for a first overview,\napply multiple regression with care and use process knowledge."
  },
  {
    "objectID": "slides/05-classtests.html#determining-the-power-of-statistical-tests",
    "href": "slides/05-classtests.html#determining-the-power-of-statistical-tests",
    "title": "05-Classical Tests",
    "section": "Determining the power of statistical tests",
    "text": "Determining the power of statistical tests\n\nHow many replicates will I need?\n\nDepends on:\n\nthe relative effect size \\(\\frac{\\mathrm{effect}}{\\mathrm{standard ~ deviation}}\\)\n\n\\[\\delta=\\frac{(\\bar{x}_1-\\bar{x}_2)}{s}\\]\n\nthe sample size \\(n\\)\nand the pre-defined significance level \\(\\alpha\\)\nand the applied method\n\nThe smaller \\(\\alpha\\), \\(n\\) and \\(\\delta\\), the bigger the type II (\\(\\beta\\)) error.\nThis is the probability to overlook effects despite of their existence."
  },
  {
    "objectID": "slides/05-classtests.html#power-analysis-1",
    "href": "slides/05-classtests.html#power-analysis-1",
    "title": "05-Classical Tests",
    "section": "Power analysis",
    "text": "Power analysis\n\nFormula for minimum sample size in the one-sample case:\n\\[\nn = \\bigg(\\frac{z_\\alpha + z_{1-\\beta}}{\\delta}\\bigg)^2\n\\]\n\n\\(z\\): the quantiles (qnorm) of the standard normal distribution for \\(\\alpha\\) and for \\(1-\\beta\\)\n\\(\\delta=\\Delta / s\\): relative effect size.\n\nExample\nTwo-tailed test with \\(\\alpha=0.025\\) and \\(\\beta=0.2\\)\n\\(\\rightarrow\\) \\(z_\\alpha = 1.96\\), \\(z_\\beta=0.84\\), then:\n\\[\nn= (1.96 \\pm 0.84)^2 \\cdot 1/\\delta^2 \\approx 8 /\\delta^2\n\\]"
  },
  {
    "objectID": "slides/05-classtests.html#power-of-the-t-test",
    "href": "slides/05-classtests.html#power-of-the-t-test",
    "title": "05-Classical Tests",
    "section": "Power of the t-test",
    "text": "Power of the t-test\nThe power of a t-test, or the minimum sample size, can be calculated with: power.t.test():\n\npower.t.test(n=5, delta=0.5, sig.level=0.05)\n\n\n     Two-sample t test power calculation \n\n              n = 5\n          delta = 0.5\n             sd = 1\n      sig.level = 0.05\n          power = 0.1038399\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\\(\\rightarrow\\) power = 0.10\n\nFor \\(n=5\\) an existing effect of \\(0.5\\sigma\\) is only detected in 1 out of 10 cases.\nFor a power of 80% at \\(n=5\\) we need an effect size of at least \\(2\\sigma\\):\n\n\npower.t.test(n=5, power=0.8, sig.level=0.05)\n\nFor a weak effect of \\(0.5\\sigma\\) we need a sample size of \\(n\\ge64\\) in each group:\n\npower.t.test(delta=0.5,power=0.8,sig.level=0.05)\n\n\\(\\Rightarrow\\) we ned either a large sample size or a strong effect."
  },
  {
    "objectID": "slides/05-classtests.html#simulated-power-of-a-t-test",
    "href": "slides/05-classtests.html#simulated-power-of-a-t-test",
    "title": "05-Classical Tests",
    "section": "Simulated power of a t-test",
    "text": "Simulated power of a t-test\n\n# population parameters\nn      <- 10\nxmean1 <- 50\nxmean2 <- 55\nxsd1   <- xsd2 <- 10\nalpha  <- 0.05\n\n# number of test runs in the simulation\nnn <- 1000\na <- b <- 0\nfor (i in 1:nn) {\n  # creating random numbers\n  x1 <- rnorm(n, xmean1, xsd1)\n  x2 <- rnorm(n, xmean2, xsd2)\n  # results of the t-test\n  p <- t.test(x1,x2,var.equal = TRUE)$p.value \n  if (p < alpha) {\n     a <- a+1\n   } else {\n     b <- b+1\n  }\n}\nprint(paste(\"a=\", a, \", b=\", b, \", a/n=\", a/nn, \", b/n=\", b/nn))"
  },
  {
    "objectID": "slides/05-classtests.html#references",
    "href": "slides/05-classtests.html#references",
    "title": "05-Classical Tests",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nHubbard, R. (2004). Alphabet soup: Blurring the distinctions betweenp’s anda’s in psychological research. Theory & Psychology, 14(3), 295–327. https://doi.org/10.1177/0959354304043638\n\n\nZimmerman, D. W. (2004). A note on preliminary tests of equality of variances. British Journal of Mathematical and Statistical Psychology, 57(1), 173–181. https://doi.org/10.1348/000711004849222"
  },
  {
    "objectID": "slides/10-multivariate.html#data-sets-and-terms-of-use",
    "href": "slides/10-multivariate.html#data-sets-and-terms-of-use",
    "title": "Multivariate methods",
    "section": "Data sets and terms of use",
    "text": "Data sets and terms of use\n\n\nThe “UBA-lakes” data set originates from the public data repository of the German Umweltbundesamt (Umweltbundesamt, 2021). The data set provided can be used freely according to the terms and conditions published at the UBA web site, that refer to § 12a EGovG with respect of the data, and to the Creative Commons CC-BY ND International License 4.0 with respect to other objects directly created by UBA.\nThe “bm-lakes” data set is a teaching data set, derived from historical measurements of lakes in Brandenburg and Mecklenburg. The data werde taken from the literature Koschel & Scheffler (1985) and adapted to teaching purposes.\nThe “gauernitz” data set contains simplified teaching versions from research data, of the study from Winkelmann et al. (2011)\nThe document itself, the codes and the ebedded images are own work and can be shared according to CC BY 4.0."
  },
  {
    "objectID": "slides/10-multivariate.html#an-introductory-example",
    "href": "slides/10-multivariate.html#an-introductory-example",
    "title": "Multivariate methods",
    "section": "An introductory example",
    "text": "An introductory example"
  },
  {
    "objectID": "slides/10-multivariate.html#correlation-between-all-variables",
    "href": "slides/10-multivariate.html#correlation-between-all-variables",
    "title": "Multivariate methods",
    "section": "Correlation between all variables?",
    "text": "Correlation between all variables?\n\nlibrary(\"readxl\") # read Excel files directly\nlakes <- as.data.frame(\n  read_excel(\"../data/uba/3_tab_kenndaten-ausgew-seen-d_2021-04-08.xlsx\", sheet=\"Tabelle1\", skip=3)\n)\nnames(lakes) <- c(\"name\", \"state\", \"drainage\", \"population\", \"altitude\", \n                  \"z_mean\", \"z_max\", \"t_ret\", \"volume\", \"area\", \"shore_length\", \n                  \"shore_devel\", \"drain_ratio\", \"wfd_type\")\nstr(lakes)\n\n'data.frame':   56 obs. of  14 variables:\n $ name        : chr  \"Ammersee\" \"Arendsee\" \"Bleilochtalsperre\" \"Bodensee\" ...\n $ state       : chr  \"BY\" \"ST\" \"TH\" \"BW\" ...\n $ drainage    : num  993 29.8 1239.9 11477 28.2 ...\n $ population  : num  114900 3200 180000 1400000 28 ...\n $ altitude    : num  532.9 22.8 404 395.4 13.1 ...\n $ z_mean      : num  37.6 28.6 23.3 85 2.4 ...\n $ z_max       : num  81.1 48.7 55 254 4.8 58.3 32.5 73.4 1.7 18.8 ...\n $ t_ret       : num  2.7 50 0.526 4.2 1.9 16.3 NA 1.26 0.1 2.3 ...\n $ volume      : num  1.75 0.147 0.215 48.522 0.009 ...\n $ area        : num  46.6 5.14 9.2 571.5 3.9 ...\n $ shore_length: num  43 9 NA 273 10.4 13.7 17.5 64 7.5 10.1 ...\n $ shore_devel : num  1.78 1.12 NA 2.26 1.48 2.09 1.64 2.02 2.22 1.6 ...\n $ drain_ratio : num  20.3 5.8 NA 21.9 7.2 ...\n $ wfd_type    : chr  \"Typ 4\" \"Typ 13\" \"Typ 5\" \"Typ 4\" ...\n\n\n\nnames(lakes) replaces the original German column names by abbreviated English abbreviations"
  },
  {
    "objectID": "slides/10-multivariate.html#create-pairwise-scatter-plots-for-all-variables",
    "href": "slides/10-multivariate.html#create-pairwise-scatter-plots-for-all-variables",
    "title": "Multivariate methods",
    "section": "Create pairwise scatter plots for all variables?",
    "text": "Create pairwise scatter plots for all variables?\n\nplot(lakes)"
  },
  {
    "objectID": "slides/10-multivariate.html#create-pairwise-scatter-plots-for-all-variables-1",
    "href": "slides/10-multivariate.html#create-pairwise-scatter-plots-for-all-variables-1",
    "title": "Multivariate methods",
    "section": "Create pairwise scatter plots for all variables?",
    "text": "Create pairwise scatter plots for all variables?\n\n\nnot a good idea, 14 variables would produce 182 (or 91) plots\ncan lead to “statistical fishing”\nwe need methods to extract the main information with a small number of plots"
  },
  {
    "objectID": "slides/10-multivariate.html#another-example",
    "href": "slides/10-multivariate.html#another-example",
    "title": "Multivariate methods",
    "section": "Another example",
    "text": "Another example\n\n\n\n\n\n \n  \n    Site \n    Mollusca \n    Diptera \n    Baetis \n    Plecoptera \n    Coleoptera \n    Turbellaria \n    Heptageniidae \n    Ephemeroptera \n    Gammarus \n    Trichoptera \n    Acari \n    Nematoda \n    Oligochaeta \n  \n \n\n  \n    GP9 \n    3 \n    165 \n    91 \n    14 \n    6 \n    3 \n    9 \n    136 \n    256 \n    45 \n    6 \n    0 \n    11 \n  \n  \n    GR9 \n    31 \n    438 \n    728 \n    31 \n    728 \n    11 \n    31 \n    0 \n    65 \n    367 \n    3 \n    0 \n    503 \n  \n  \n    TP9 \n    0 \n    26 \n    3 \n    20 \n    9 \n    0 \n    3 \n    20 \n    119 \n    40 \n    0 \n    0 \n    23 \n  \n  \n    TR9 \n    0 \n    11 \n    6 \n    37 \n    11 \n    0 \n    0 \n    3 \n    68 \n    26 \n    0 \n    0 \n    23 \n  \n  \n    GP8 \n    23 \n    913 \n    31 \n    14 \n    3 \n    9 \n    6 \n    26 \n    901 \n    37 \n    3 \n    20 \n    0 \n  \n  \n    GR8 \n    225 \n    1066 \n    310 \n    199 \n    461 \n    48 \n    91 \n    23 \n    688 \n    600 \n    26 \n    0 \n    284 \n  \n  \n    TP8 \n    17 \n    2204 \n    54 \n    117 \n    11 \n    0 \n    11 \n    20 \n    2525 \n    77 \n    3 \n    3 \n    68 \n  \n  \n    TR8 \n    3 \n    520 \n    74 \n    762 \n    125 \n    20 \n    65 \n    0 \n    668 \n    173 \n    3 \n    0 \n    267 \n  \n  \n    GP7 \n    26 \n    247 \n    68 \n    6 \n    3 \n    3 \n    3 \n    20 \n    813 \n    9 \n    6 \n    0 \n    0 \n  \n  \n    GR7 \n    117 \n    509 \n    290 \n    63 \n    191 \n    6 \n    26 \n    11 \n    682 \n    117 \n    60 \n    9 \n    131 \n  \n  \n    TP7 \n    26 \n    3477 \n    17 \n    28 \n    0 \n    0 \n    3 \n    37 \n    2693 \n    17 \n    0 \n    0 \n    0 \n  \n  \n    TR7 \n    48 \n    429 \n    57 \n    412 \n    97 \n    9 \n    63 \n    9 \n    808 \n    102 \n    26 \n    6 \n    57 \n  \n  \n    GP10 \n    3 \n    159 \n    14 \n    31 \n    3 \n    0 \n    48 \n    91 \n    100 \n    23 \n    0 \n    0 \n    17 \n  \n  \n    GR10 \n    0 \n    68 \n    191 \n    26 \n    51 \n    3 \n    253 \n    0 \n    80 \n    233 \n    3 \n    0 \n    11 \n  \n  \n    TP10 \n    0 \n    51 \n    0 \n    6 \n    9 \n    0 \n    0 \n    6 \n    71 \n    0 \n    0 \n    0 \n    31 \n  \n  \n    TR10 \n    0 \n    28 \n    6 \n    40 \n    14 \n    0 \n    0 \n    0 \n    40 \n    54 \n    0 \n    0 \n    0 \n  \n\n\n\n\n\n\n\nAggregated part of taxa list from two small streams."
  },
  {
    "objectID": "slides/10-multivariate.html#how-to-aggregate-the-data",
    "href": "slides/10-multivariate.html#how-to-aggregate-the-data",
    "title": "Multivariate methods",
    "section": "How to aggregate the data?",
    "text": "How to aggregate the data?\n\n\n\nSimpson index\n\\[\nD = \\sum_{i=1}^S p_i^2\n\\]\n\n\\(p_i\\): relative abundance of species\nin most cases, Simpson index is given as \\(\\tilde{D} = 1 - D\\) (large values – high diversity)\nalso possible: inverse Simpson index: \\(D' = 1 / D\\)\n\n\n\nShannon index\n\\[\nH = -\\sum_{i=1}^S p_i \\log_b p_i\n\\]\n\nin most cases log base \\(b=e\\) (natural log), some prefer \\(b=2\\) (information theory)\n\nEveness \n\\[\n  E = \\frac{H}{\\log(S)}\n  \\]\n\n\\(S\\): number of species\n\n\n\n\n\nmore indices: species richness, species deficit, Fisher’s \\(\\alpha\\) …"
  },
  {
    "objectID": "slides/10-multivariate.html#diversity-indices",
    "href": "slides/10-multivariate.html#diversity-indices",
    "title": "Multivariate methods",
    "section": "Diversity indices",
    "text": "Diversity indices\n\n\n\n\n\n\n\n\n\n \n  \n    Site \n    Habitat \n    Stream \n    Flood \n    shannon \n    simpson \n    invsimpson \n    eveness \n    fisher_alpha \n  \n \n\n  \n    GP9 \n    p \n    g \n    n \n    1.75 \n    0.78 \n    4.55 \n    0.68 \n    2.03 \n  \n  \n    GR9 \n    r \n    g \n    n \n    1.79 \n    0.81 \n    5.23 \n    0.70 \n    1.44 \n  \n  \n    TP9 \n    p \n    t \n    n \n    1.70 \n    0.74 \n    3.87 \n    0.66 \n    1.80 \n  \n  \n    TR9 \n    r \n    t \n    n \n    1.74 \n    0.78 \n    4.57 \n    0.68 \n    1.70 \n  \n  \n    GP8 \n    p \n    g \n    v \n    1.11 \n    0.58 \n    2.39 \n    0.43 \n    1.70 \n  \n  \n    GR8 \n    r \n    g \n    v \n    2.08 \n    0.85 \n    6.57 \n    0.81 \n    1.52 \n  \n  \n    TP8 \n    p \n    t \n    v \n    1.04 \n    0.57 \n    2.32 \n    0.41 \n    1.47 \n  \n  \n    TR8 \n    r \n    t \n    v \n    1.81 \n    0.80 \n    5.04 \n    0.71 \n    1.46 \n  \n  \n    GP7 \n    p \n    g \n    v \n    1.04 \n    0.50 \n    1.99 \n    0.40 \n    1.67 \n  \n  \n    GR7 \n    r \n    g \n    v \n    1.97 \n    0.82 \n    5.45 \n    0.77 \n    1.83 \n  \n  \n    TP7 \n    p \n    t \n    v \n    0.80 \n    0.51 \n    2.05 \n    0.31 \n    0.90 \n  \n  \n    TR7 \n    r \n    t \n    v \n    1.80 \n    0.77 \n    4.33 \n    0.70 \n    1.84 \n  \n  \n    GP10 \n    p \n    g \n    n \n    1.83 \n    0.80 \n    5.00 \n    0.71 \n    1.78 \n  \n  \n    GR10 \n    r \n    g \n    n \n    1.79 \n    0.80 \n    4.99 \n    0.70 \n    1.57 \n  \n  \n    TP10 \n    p \n    t \n    n \n    1.42 \n    0.71 \n    3.46 \n    0.55 \n    1.20 \n  \n  \n    TR10 \n    r \n    t \n    n \n    1.62 \n    0.78 \n    4.64 \n    0.63 \n    1.19 \n  \n\n\n\n\n\n\n\n\naggregated data but which of the indices tells what?\n\\(\\rightarrow\\) information loss compared to the original list"
  },
  {
    "objectID": "slides/10-multivariate.html#the-multivariate-approach",
    "href": "slides/10-multivariate.html#the-multivariate-approach",
    "title": "Multivariate methods",
    "section": "The multivariate approach",
    "text": "The multivariate approach\n\nWork with the complete original variables directly\n\n\\(\\rightarrow\\) Multivariate statistics\n\ndependent variables + explanation variables optional\nanalyze distance and location in multidimensional space\nfind way to vizualize relationship in lower dimensions\n\n\nFor comparison\n\nunivariate: 1 variable\nbivariate: 1 dependent, 1 independent variable\nmultiple: 1 dependent, >1 independent variables"
  },
  {
    "objectID": "slides/10-multivariate.html#two-approches-of-multivariate-statistics",
    "href": "slides/10-multivariate.html#two-approches-of-multivariate-statistics",
    "title": "Multivariate methods",
    "section": "Two approches of multivariate statistics",
    "text": "Two approches of multivariate statistics\n\n\n\n\nOrdination\n\n\n\n\n\n\ndimension reduction\nrelate observations and variables\n\n\n\nCluster analysis\n\n\n\n\n\n\ndistance and similarity\nidentification of groups"
  },
  {
    "objectID": "slides/10-multivariate.html#basic-concepts",
    "href": "slides/10-multivariate.html#basic-concepts",
    "title": "Multivariate methods",
    "section": "Basic concepts",
    "text": "Basic concepts\n\nSimilarity and correlation\n\ndistance and similarity: \\(\\rightarrow\\) How different or similar are the observations?\ncorrelation and covariance: \\(\\rightarrow\\) Are variables interdependent?\ndimension reduction: \\(\\rightarrow\\) Try to show essential parts of information on a lower number of dimensions.\ncluster analysis: \\(\\rightarrow\\) Show which observations are closely together.\nordination: \\(\\rightarrow\\) Plot data at lower dimensions, similar observations closely together."
  },
  {
    "objectID": "slides/10-multivariate.html#distance-and-dissimilarity",
    "href": "slides/10-multivariate.html#distance-and-dissimilarity",
    "title": "Multivariate methods",
    "section": "Distance and dissimilarity",
    "text": "Distance and dissimilarity\n\nAxiomatic definition\nMeasure of distance \\(d\\) between multidimensional points \\(x_i\\) and \\(x_j\\):\n\n\\(d(x_i, x_j) \\ge 0\\), distances are similar or equal to zero\n\\(d(x_i, x_j)=d(x_j,x_i)\\), the distance from A to B is the same as from B to A,\n\\(d(x_i, x_i)=0\\), the distance from a given point to itself is zero\n\nA distance measure is termed metric, if:\n\n\\(d=0\\) applies in the case of equality only, and\nthe triangle inequality aapplies. The indirect route is longer than the direct route\n\nIf one or both of the additional conditions are violated, we speak about nonmetric measures and use the term dissimilarity instead of distance."
  },
  {
    "objectID": "slides/10-multivariate.html#similarity",
    "href": "slides/10-multivariate.html#similarity",
    "title": "Multivariate methods",
    "section": "Similarity",
    "text": "Similarity\n\nA measure of similarity \\(s\\) can be defined in a similar way:\n\n\\(s(x_i,x_j) \\le s_{max}\\)\n\\(s(x_i,x_j)=s(x_j,x_i)\\)\n\\(s(x_i,x_i)=s_{max}\\)\n\nit is metric, if:\n\n\\(s_{max}\\) applies only in the case of equality and\nthe triangle inequality applies"
  },
  {
    "objectID": "slides/10-multivariate.html#conversion-between-dissimilarity-and-similarity",
    "href": "slides/10-multivariate.html#conversion-between-dissimilarity-and-similarity",
    "title": "Multivariate methods",
    "section": "Conversion between dissimilarity and similarity",
    "text": "Conversion between dissimilarity and similarity\n\n\n\n\n\n\nsimilarity\ndissimilarity\n\n\n\n\n\\(s=1-d/d_{max}\\)\n\\(d=1-s/s_{max}\\)\n\n\n\\(s=\\exp(-d)\\)\n\\(d= - \\ln(s-s_{min})\\)\n\n\n\n\n\n\ndistance goes from \\(0\\) to \\(\\infty\\)\ndifferent transformations, as long as the \\(\\Rightarrow\\) transformation is monotonic\nin most cases similarity \\(s\\) is limited between \\((0, 1)\\) or between 0 and 100%."
  },
  {
    "objectID": "slides/10-multivariate.html#common-distance-and-dissimilarity-measures",
    "href": "slides/10-multivariate.html#common-distance-and-dissimilarity-measures",
    "title": "Multivariate methods",
    "section": "Common distance and dissimilarity measures",
    "text": "Common distance and dissimilarity measures\n\n\nEuclidean distance: shortest connection between 2 points in space\nManhattan distance: around the corner, as in Manhattans grid-like streets\nChi-square distance: for comparison of frequencies,\nMahalanobis distance: takes covariance into account\nBray-Curtis dissimilarity: comparison of species lists in ecology\nJaccard index: for binary (presence-absence) data\nGower dissimilarity: used for mixed-type variables"
  },
  {
    "objectID": "slides/10-multivariate.html#distance-and-dissimilarity-of-metric-variables",
    "href": "slides/10-multivariate.html#distance-and-dissimilarity-of-metric-variables",
    "title": "Multivariate methods",
    "section": "Distance and dissimilarity of metric variables",
    "text": "Distance and dissimilarity of metric variables\nwith \\(x_{ij}, x_{ik}\\) abundance of species \\(i\\) at sites (\\(j, k\\)).\nEuclidean distance:\n\\[\nd_{jk} = \\sqrt{\\sum (x_{ij}-x_{ik})^2}\n\\]\nManhattan distance: \\[\nd_{jk} = \\sum |x_{ij}-x_{ik}|\n\\]\nGower distance: \\[\nd_{jk} = \\frac{1}{M} \\sum\\frac{|x_{ij}-x_{ik}|}{\\max(x_i)-\\min(x_i)}\n\\]\nBray-Curtis dissimilarity: \\[\nd_{jk} = \\frac{\\sum{|x_{ij}-x_{ik}|}}{\\sum{(x_{ij}+x_{ik})}}\n\\]"
  },
  {
    "objectID": "slides/10-multivariate.html#distance-and-dissimilarity-of-binary-variables",
    "href": "slides/10-multivariate.html#distance-and-dissimilarity-of-binary-variables",
    "title": "Multivariate methods",
    "section": "Distance and dissimilarity of binary variables",
    "text": "Distance and dissimilarity of binary variables\n\n\nEuclidean: \\(\\sqrt{A+B-2J}\\)\nManhattan: \\(A+B-2J\\)\nGower: \\(\\frac{A+B-2J}{M}\\)\nBray-Curtis: \\(\\frac{A+B-2J}{A+B}\\)\nJaccard: \\(\\frac{2b}{1+b}\\) with \\(b\\) = Bray-Curtis dissimilarity\n\nwhere:\n\n\\(A, B\\) = numbers of species on compared sites\n\\(J\\) = (joint) is the number of species that occur on both compared sites\n\\(M\\) = number of columns (excluding missing values)\n\n Applications\nAdditional distance measures and application suggestions in the vegdist help page."
  },
  {
    "objectID": "slides/10-multivariate.html#map-of-the-lakes",
    "href": "slides/10-multivariate.html#map-of-the-lakes",
    "title": "Multivariate methods",
    "section": "Map of the lakes",
    "text": "Map of the lakes"
  },
  {
    "objectID": "slides/10-multivariate.html#the-data-set",
    "href": "slides/10-multivariate.html#the-data-set",
    "title": "Multivariate methods",
    "section": "The data set",
    "text": "The data set\nExample: A simplified subset from the UBA lake data.\n\n\n\n\n\n \n  \n      \n    name \n    shortname \n    z_mean \n    z_max \n    t_ret \n    volume \n    area \n    p_tot \n    n_no3 \n    chl \n  \n \n\n  \n    Ammer \n    Ammersee \n    Ammer \n    37.60 \n    81.1 \n    2.70 \n    1.75000 \n    46.600 \n    7.3 \n    1.09 \n    2.80 \n  \n  \n    Arend \n    Arendsee \n    Arend \n    28.60 \n    48.7 \n    50.00 \n    0.14700 \n    5.140 \n    375.0 \n    0.05 \n    22.30 \n  \n  \n    Boden \n    Bodensee \n    Boden \n    85.00 \n    254.0 \n    4.20 \n    48.52150 \n    571.500 \n    6.9 \n    0.84 \n    2.10 \n  \n  \n    Chiem \n    Chiemsee \n    Chiem \n    25.60 \n    73.4 \n    1.26 \n    2.04800 \n    79.900 \n    9.2 \n    0.55 \n    3.80 \n  \n  \n    Dober \n    Dobersdorfer See \n    Dober \n    5.40 \n    18.8 \n    2.30 \n    0.01690 \n    3.120 \n    63.9 \n    0.64 \n    27.30 \n  \n  \n    Mügg \n    Großer Müggelsee \n    Mügg \n    4.85 \n    7.5 \n    0.20 \n    0.03500 \n    7.200 \n    189.9 \n    0.17 \n    32.90 \n  \n  \n    Plön \n    Großer Plöner See \n    Plön \n    12.40 \n    58.0 \n    3.10 \n    0.37200 \n    29.970 \n    62.3 \n    0.22 \n    8.80 \n  \n  \n    Kumme \n    Kummerower See \n    Kumme \n    8.10 \n    23.3 \n    1.50 \n    0.26300 \n    32.500 \n    65.3 \n    0.78 \n    16.60 \n  \n  \n    MürA \n    Müritz (Außenmüritz) \n    MürA \n    6.50 \n    28.1 \n    6.00 \n    0.68000 \n    105.300 \n    19.7 \n    0.11 \n    6.30 \n  \n  \n    MürB \n    Müritz (Binnenmüritz) \n    MürB \n    9.80 \n    30.3 \n    6.00 \n    0.03800 \n    3.910 \n    34.2 \n    0.11 \n    6.70 \n  \n  \n    Plaue \n    Plauer See \n    Plaue \n    6.80 \n    25.5 \n    3.00 \n    0.30000 \n    38.400 \n    26.0 \n    0.09 \n    6.80 \n  \n  \n    Sacro \n    Sacrower See \n    Sacro \n    18.01 \n    36.0 \n    15.00 \n    0.01930 \n    1.072 \n    79.8 \n    0.04 \n    8.60 \n  \n  \n    Schar \n    Scharmützelsee \n    Schar \n    9.00 \n    29.5 \n    16.00 \n    0.10823 \n    12.090 \n    35.3 \n    0.12 \n    10.40 \n  \n  \n    SchwA \n    Schweriner See (Außensee) \n    SchwA \n    9.40 \n    52.4 \n    10.00 \n    0.33100 \n    35.200 \n    100.0 \n    0.23 \n    11.70 \n  \n  \n    SchwI \n    Schweriner See (Innensee) \n    SchwI \n    13.50 \n    44.6 \n    5.30 \n    0.35600 \n    26.400 \n    246.5 \n    0.19 \n    5.86 \n  \n  \n    Starn \n    Starnberger See \n    Starn \n    53.20 \n    127.8 \n    21.00 \n    2.99900 \n    56.400 \n    5.9 \n    0.32 \n    1.84 \n  \n  \n    Stech \n    Stechlinsee \n    Stech \n    22.80 \n    68.0 \n    32.00 \n    0.09700 \n    4.250 \n    15.8 \n    0.04 \n    2.60 \n  \n  \n    Stein \n    Steinhuder Meer \n    Stein \n    1.35 \n    2.9 \n    2.30 \n    0.04200 \n    29.100 \n    53.3 \n    0.12 \n    29.00 \n  \n\n\n\n\n\n\n\n\nData set from UBA = Umweltbundesamt = German Federal Environmental Agency"
  },
  {
    "objectID": "slides/10-multivariate.html#data-inspection",
    "href": "slides/10-multivariate.html#data-inspection",
    "title": "Multivariate methods",
    "section": "Data inspection",
    "text": "Data inspection\n\npar(mfrow = c(1, 4), mar = c(6, 4, 3, 1), las = 2)\nboxplot(lakedata, main=\"raw data\")\nboxplot(scale(lakedata), main=\"normalized\")\nboxplot(scale(sqrt(lakedata)), main=\"sqrt + normalized\")\nboxplot(scale(log(lakedata)), main=\"log + normalized\")\n\n\n\nNote: scale() that does normalisation (z-transformation)"
  },
  {
    "objectID": "slides/10-multivariate.html#principal-components-analysis-pca",
    "href": "slides/10-multivariate.html#principal-components-analysis-pca",
    "title": "Multivariate methods",
    "section": "Principal Components Analysis: PCA",
    "text": "Principal Components Analysis: PCA\n\n\n\n\npc <- prcomp(scale(lakedata))\nsummary(pc)\n\nImportance of components:\n                          PC1    PC2   PC3     PC4    PC5     PC6     PC7     PC8\nStandard deviation     2.0692 1.2735 1.047 0.76067 0.5499 0.30497 0.12230 0.10618\nProportion of Variance 0.5352 0.2027 0.137 0.07233 0.0378 0.01163 0.00187 0.00141\nCumulative Proportion  0.5352 0.7379 0.875 0.94729 0.9851 0.99672 0.99859 1.00000\n\nplot(pc)"
  },
  {
    "objectID": "slides/10-multivariate.html#biplot",
    "href": "slides/10-multivariate.html#biplot",
    "title": "Multivariate methods",
    "section": "Biplot",
    "text": "Biplot\n\nbiplot(pc3)"
  },
  {
    "objectID": "slides/10-multivariate.html#pca-with-the-vegan-package",
    "href": "slides/10-multivariate.html#pca-with-the-vegan-package",
    "title": "Multivariate methods",
    "section": "PCA with the vegan package",
    "text": "PCA with the vegan package\n\npc3 <- rda(lakedata2, scale = TRUE)\nsummary(pc3)\n\n\nCall:\nrda(X = lakedata2, scale = TRUE) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal               8          1\nUnconstrained       8          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                        PC1    PC2    PC3     PC4     PC5     PC6      PC7      PC8\nEigenvalue            4.456 1.7053 0.9503 0.50170 0.25322 0.08846 0.029105 0.016020\nProportion Explained  0.557 0.2132 0.1188 0.06271 0.03165 0.01106 0.003638 0.002003\nCumulative Proportion 0.557 0.7702 0.8889 0.95165 0.98330 0.99436 0.997997 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  3.414953 \n\n\nSpecies scores\n\n           PC1     PC2      PC3      PC4       PC5      PC6\nz_mean -1.0598  0.4289 -0.21113  0.23873 -0.008753  0.18441\nz_max  -1.1318  0.3420 -0.12121  0.10258  0.072128  0.04149\nt_ret   0.0321  1.1531 -0.07499  0.10386 -0.291203 -0.15956\nvolume -1.0984 -0.1075 -0.36435 -0.28489 -0.088096  0.07254\narea   -1.0368 -0.2858 -0.25303 -0.44554 -0.025908 -0.17654\np_tot   0.7169  0.2934 -0.85503  0.06207  0.345841 -0.05495\nn_no3  -0.7044 -0.7316 -0.18149  0.60719 -0.072833 -0.13748\nchl     0.8938 -0.3753 -0.59964 -0.02895 -0.381711  0.09702\n\n\nSite scores (weighted sums of species scores)\n\n           PC1     PC2      PC3      PC4      PC5      PC6\nAmmer -0.83902 -0.6075  0.51716  1.81616  0.22343 -0.15112\nArend  0.61718  1.8219 -1.92971  0.44353 -0.51334 -0.46420\nBoden -2.56671 -0.3066 -1.32007 -1.14721 -0.41861  0.35821\nChiem -0.64712 -0.5918  0.55561  0.35138  0.48915  0.23752\nDober  0.57998 -1.0029 -0.35592  1.09957 -1.11137  0.09904\nMügg   0.98336 -0.8687 -1.03143 -0.33065  0.31544  1.71907\nPlön   0.05148 -0.1788  0.12415 -0.07719  0.74087  0.42564\nKumme  0.20231 -1.0792 -0.29790  0.92094 -0.25802 -1.13785\nMürA   0.01805 -0.1716  0.69453 -1.37602 -0.04136 -1.55657\nMürB   0.32308  0.1145  0.83401 -0.12085  0.39231  0.75409\nPlaue  0.21775 -0.2308  0.80820 -0.98103  0.44885  0.06816\nSacro  0.40494  0.8219  0.29088 -0.04609  0.23456  1.24642\nSchar  0.34038  0.3961  0.50515 -0.19722 -0.82282 -0.52792\nSchwA  0.19197  0.1243 -0.30591 -0.03972  0.15528 -1.05932\nSchwI  0.24471  0.2379 -0.69605  0.04506  2.41490 -0.72493\nStarn -0.95511  0.9136  0.55372  0.66291 -0.52409  0.55554\nStech -0.05030  1.4337  1.12433  0.06976 -0.49103  0.09703\nStein  0.88307 -0.8259 -0.07074 -1.09331 -1.23415  0.06121"
  },
  {
    "objectID": "slides/10-multivariate.html#biplot-1",
    "href": "slides/10-multivariate.html#biplot-1",
    "title": "Multivariate methods",
    "section": "Biplot",
    "text": "Biplot\n\nplot(pc3)"
  },
  {
    "objectID": "slides/10-multivariate.html#nonmetric-multidimensional-scaling-nmds",
    "href": "slides/10-multivariate.html#nonmetric-multidimensional-scaling-nmds",
    "title": "Multivariate methods",
    "section": "Nonmetric Multidimensional Scaling: NMDS",
    "text": "Nonmetric Multidimensional Scaling: NMDS\n\nmd <- metaMDS(lakedata2, scale = TRUE, distance = \"euclid\", trace=FALSE)\nplot(md, type=\"text\")\nabline(h=0, col=\"grey\", lty=\"dotted\")\nabline(v=0, col=\"grey\", lty=\"dotted\")"
  },
  {
    "objectID": "slides/10-multivariate.html#overview",
    "href": "slides/10-multivariate.html#overview",
    "title": "Multivariate methods",
    "section": "Overview",
    "text": "Overview\n\nCluster analysis aims to group data sets in clusters\nHierarchical clustering\n\nbuild a dendrogram (a tree of grouping)\nagglomerative methods\ndivisive methods\n\nDifferent agglomeration methods\n\ndefine how distance is measured between clusters\n\nNonhierarchical clustering\n\nsubdivide in a given number of groups\nusually no dendrogram\niterative methods\ne.g. k-means, k-centroids\n\n\n\npar(mfrow=c(1,2))\nhc <- hclust(dist(scale(lakedata2)), method=\"complete\") # the default\nplot(hc)\n\nhc2 <- hclust(dist(scale(lakedata2)), method=\"ward.D2\")\nplot(hc2)"
  },
  {
    "objectID": "slides/10-multivariate.html#identification-of-clusters-in-the-tree",
    "href": "slides/10-multivariate.html#identification-of-clusters-in-the-tree",
    "title": "Multivariate methods",
    "section": "Identification of clusters in the tree",
    "text": "Identification of clusters in the tree\n\nplot(hc, hang = -1)    # -1: extend vertical lines to the bottom\nrect.hclust(hc, 5)\n\ngrp <- cutree(hc, 5)\n# grp                  # can be used to show the groups"
  },
  {
    "objectID": "slides/10-multivariate.html#color-nmds-according-to-clusters",
    "href": "slides/10-multivariate.html#color-nmds-according-to-clusters",
    "title": "Multivariate methods",
    "section": "Color NMDS according to clusters",
    "text": "Color NMDS according to clusters\n\nplot(md, type = \"n\")\ntext(md$points, row.names(lakedata2), col = grp)"
  },
  {
    "objectID": "slides/10-multivariate.html#non-hierarchical-clustering",
    "href": "slides/10-multivariate.html#non-hierarchical-clustering",
    "title": "Multivariate methods",
    "section": "Non-hierarchical clustering",
    "text": "Non-hierarchical clustering\nInstead of hierarchical clustering, we can also use a non-hierarchical method, e.g. k-means clustering. This is an iterative method, and avoids the problem that cluster assignment depends on the order of clustering and the agglomeration method.\nDepending on the question, it may be a disadvantage, that the number of clusters needs to be specified beforehand (e.g. from hierarchical clustering) and that we do not get a tree diagramm."
  },
  {
    "objectID": "slides/10-multivariate.html#references",
    "href": "slides/10-multivariate.html#references",
    "title": "Multivariate methods",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nCasper, S. J. (1985). Lake stechlin: A temperate oligotrophic lake. Dr. W. Junk Publishers.\n\n\nKoschel, R., & Scheffler, W. (1985). The primary production. In S. J. Casper (Ed.), Lake stechlin. A temperate oligotrophic lake (pp. 287–345). Dr. W. Junk Publishers.\n\n\nUmweltbundesamt. (2021). Kenndaten ausgewählter Seen Deutschlands. https://www.umweltbundesamt.de/daten/wasser/zustand-der-seen#okologischer-zustand-der-seen\n\n\nWinkelmann, C., Hellmann, C., Worischka, S., Petzoldt, T., & Benndorf, J. (2011). Fish predation affects the structure of a benthic community. Freshwater Biology, 56(6), 1030–1046. https://doi.org/10.1111/j.1365-2427.2010.02543.x"
  },
  {
    "objectID": "slides/10-multivariate.html#some-lakes-in-germany",
    "href": "slides/10-multivariate.html#some-lakes-in-germany",
    "title": "Multivariate methods",
    "section": "Some lakes in Germany",
    "text": "Some lakes in Germany"
  },
  {
    "objectID": "slides/10-multivariate.html#a-data-set-from-german-lakes",
    "href": "slides/10-multivariate.html#a-data-set-from-german-lakes",
    "title": "Multivariate methods",
    "section": "A data set from German lakes",
    "text": "A data set from German lakes"
  },
  {
    "objectID": "slides/10-multivariate.html#example-a-simplified-subset-from-the-uba-lake-data.",
    "href": "slides/10-multivariate.html#example-a-simplified-subset-from-the-uba-lake-data.",
    "title": "Multivariate methods",
    "section": "Example: A simplified subset from the UBA lake data.",
    "text": "Example: A simplified subset from the UBA lake data.\n\n\n\n\n\n \n  \n      \n    name \n    shortname \n    z_mean \n    z_max \n    t_ret \n    volume \n    area \n    p_tot \n    n_no3 \n    chl \n    wfd_type \n  \n \n\n  \n    1 \n    Ammersee \n    Ammer \n    37.60 \n    81.1 \n    2.70 \n    1.75000 \n    46.600 \n    7.3 \n    1.09 \n    2.80 \n    Typ 4 \n  \n  \n    2 \n    Arendsee \n    Arend \n    28.60 \n    48.7 \n    50.00 \n    0.14700 \n    5.140 \n    375.0 \n    0.05 \n    22.30 \n    Typ 13 \n  \n  \n    4 \n    Bodensee \n    Boden \n    85.00 \n    254.0 \n    4.20 \n    48.52150 \n    571.500 \n    6.9 \n    0.84 \n    2.10 \n    Typ 4 \n  \n  \n    8 \n    Chiemsee \n    Chiem \n    25.60 \n    73.4 \n    1.26 \n    2.04800 \n    79.900 \n    9.2 \n    0.55 \n    3.80 \n    Typ 4 \n  \n  \n    10 \n    Dobersdorfer See \n    Dober \n    5.40 \n    18.8 \n    2.30 \n    0.01690 \n    3.120 \n    63.9 \n    0.64 \n    27.30 \n    Typ 14 \n  \n  \n    14 \n    Großer Müggelsee \n    Mügg \n    4.85 \n    7.5 \n    0.20 \n    0.03500 \n    7.200 \n    189.9 \n    0.17 \n    32.90 \n    Typ 11 \n  \n  \n    15 \n    Großer Plöner See \n    Plön \n    12.40 \n    58.0 \n    3.10 \n    0.37200 \n    29.970 \n    62.3 \n    0.22 \n    8.80 \n    Typ 13 \n  \n  \n    21 \n    Kummerower See \n    Kumme \n    8.10 \n    23.3 \n    1.50 \n    0.26300 \n    32.500 \n    65.3 \n    0.78 \n    16.60 \n    Typ 11 \n  \n  \n    25 \n    Müritz (Außenmüritz) \n    MürA \n    6.50 \n    28.1 \n    6.00 \n    0.68000 \n    105.300 \n    19.7 \n    0.11 \n    6.30 \n    Typ 14 \n  \n  \n    26 \n    Müritz (Binnenmüritz) \n    MürB \n    9.80 \n    30.3 \n    6.00 \n    0.03800 \n    3.910 \n    34.2 \n    0.11 \n    6.70 \n    Typ 10 \n  \n  \n    30 \n    Plauer See \n    Plaue \n    6.80 \n    25.5 \n    3.00 \n    0.30000 \n    38.400 \n    26.0 \n    0.09 \n    6.80 \n    Typ 10 \n  \n  \n    34 \n    Sacrower See \n    Sacro \n    18.01 \n    36.0 \n    15.00 \n    0.01930 \n    1.072 \n    79.8 \n    0.04 \n    8.60 \n    Typ 10 \n  \n  \n    36 \n    Scharmützelsee \n    Schar \n    9.00 \n    29.5 \n    16.00 \n    0.10823 \n    12.090 \n    35.3 \n    0.12 \n    10.40 \n    Typ 13 \n  \n  \n    39 \n    Schweriner See (Außensee) \n    SchwA \n    9.40 \n    52.4 \n    10.00 \n    0.33100 \n    35.200 \n    100.0 \n    0.23 \n    11.70 \n    Typ 13 \n  \n  \n    40 \n    Schweriner See (Innensee) \n    SchwI \n    13.50 \n    44.6 \n    5.30 \n    0.35600 \n    26.400 \n    246.5 \n    0.19 \n    5.86 \n    Typ 13 \n  \n  \n    44 \n    Starnberger See \n    Starn \n    53.20 \n    127.8 \n    21.00 \n    2.99900 \n    56.400 \n    5.9 \n    0.32 \n    1.84 \n    Typ 3 \n  \n  \n    45 \n    Stechlinsee \n    Stech \n    22.80 \n    68.0 \n    32.00 \n    0.09700 \n    4.250 \n    15.8 \n    0.04 \n    2.60 \n    Typ 13 \n  \n  \n    46 \n    Steinhuder Meer \n    Stein \n    1.35 \n    2.9 \n    2.30 \n    0.04200 \n    29.100 \n    53.3 \n    0.12 \n    29.00 \n    Typ 11 \n  \n\n\n\n\n\n\n\n\nData set from UBA = Umweltbundesamt = German Federal Environmental Agency"
  },
  {
    "objectID": "slides/10-multivariate.html#example-a-simplified-subset-from-the-uba-lake-data",
    "href": "slides/10-multivariate.html#example-a-simplified-subset-from-the-uba-lake-data",
    "title": "Multivariate methods",
    "section": "Example: A simplified subset from the UBA lake data",
    "text": "Example: A simplified subset from the UBA lake data\n\n\n\n\n\n \n  \n      \n    name \n    shortname \n    z_mean \n    z_max \n    t_ret \n    volume \n    area \n    p_tot \n    n_no3 \n    chl \n    wfd_type \n  \n \n\n  \n    1 \n    Ammersee \n    Ammer \n    37.60 \n    81.1 \n    2.70 \n    1.75000 \n    46.600 \n    7.3 \n    1.09 \n    2.80 \n    Typ 4 \n  \n  \n    2 \n    Arendsee \n    Arend \n    28.60 \n    48.7 \n    50.00 \n    0.14700 \n    5.140 \n    375.0 \n    0.05 \n    22.30 \n    Typ 13 \n  \n  \n    4 \n    Bodensee \n    Boden \n    85.00 \n    254.0 \n    4.20 \n    48.52150 \n    571.500 \n    6.9 \n    0.84 \n    2.10 \n    Typ 4 \n  \n  \n    8 \n    Chiemsee \n    Chiem \n    25.60 \n    73.4 \n    1.26 \n    2.04800 \n    79.900 \n    9.2 \n    0.55 \n    3.80 \n    Typ 4 \n  \n  \n    10 \n    Dobersdorfer See \n    Dober \n    5.40 \n    18.8 \n    2.30 \n    0.01690 \n    3.120 \n    63.9 \n    0.64 \n    27.30 \n    Typ 14 \n  \n  \n    14 \n    Großer Müggelsee \n    Mügg \n    4.85 \n    7.5 \n    0.20 \n    0.03500 \n    7.200 \n    189.9 \n    0.17 \n    32.90 \n    Typ 11 \n  \n  \n    15 \n    Großer Plöner See \n    Plön \n    12.40 \n    58.0 \n    3.10 \n    0.37200 \n    29.970 \n    62.3 \n    0.22 \n    8.80 \n    Typ 13 \n  \n  \n    21 \n    Kummerower See \n    Kumme \n    8.10 \n    23.3 \n    1.50 \n    0.26300 \n    32.500 \n    65.3 \n    0.78 \n    16.60 \n    Typ 11 \n  \n  \n    25 \n    Müritz (Außenmüritz) \n    MürA \n    6.50 \n    28.1 \n    6.00 \n    0.68000 \n    105.300 \n    19.7 \n    0.11 \n    6.30 \n    Typ 14 \n  \n  \n    26 \n    Müritz (Binnenmüritz) \n    MürB \n    9.80 \n    30.3 \n    6.00 \n    0.03800 \n    3.910 \n    34.2 \n    0.11 \n    6.70 \n    Typ 10 \n  \n  \n    30 \n    Plauer See \n    Plaue \n    6.80 \n    25.5 \n    3.00 \n    0.30000 \n    38.400 \n    26.0 \n    0.09 \n    6.80 \n    Typ 10 \n  \n  \n    34 \n    Sacrower See \n    Sacro \n    18.01 \n    36.0 \n    15.00 \n    0.01930 \n    1.072 \n    79.8 \n    0.04 \n    8.60 \n    Typ 10 \n  \n  \n    36 \n    Scharmützelsee \n    Schar \n    9.00 \n    29.5 \n    16.00 \n    0.10823 \n    12.090 \n    35.3 \n    0.12 \n    10.40 \n    Typ 13 \n  \n  \n    39 \n    Schweriner See (Außensee) \n    SchwA \n    9.40 \n    52.4 \n    10.00 \n    0.33100 \n    35.200 \n    100.0 \n    0.23 \n    11.70 \n    Typ 13 \n  \n  \n    40 \n    Schweriner See (Innensee) \n    SchwI \n    13.50 \n    44.6 \n    5.30 \n    0.35600 \n    26.400 \n    246.5 \n    0.19 \n    5.86 \n    Typ 13 \n  \n  \n    44 \n    Starnberger See \n    Starn \n    53.20 \n    127.8 \n    21.00 \n    2.99900 \n    56.400 \n    5.9 \n    0.32 \n    1.84 \n    Typ 3 \n  \n  \n    45 \n    Stechlinsee \n    Stech \n    22.80 \n    68.0 \n    32.00 \n    0.09700 \n    4.250 \n    15.8 \n    0.04 \n    2.60 \n    Typ 13 \n  \n  \n    46 \n    Steinhuder Meer \n    Stein \n    1.35 \n    2.9 \n    2.30 \n    0.04200 \n    29.100 \n    53.3 \n    0.12 \n    29.00 \n    Typ 11 \n  \n\n\n\n\n\nmean and maximum depth (m): z_mean, z_max; retention time (years): t_ret; volume (10^9 m^3); area (km^2), total phosphorus P (µg/L): p_tot; nitrogen-N (mg/L): n_no3, chlorophyll (µg/L): chl, water framework directive lake type: wfd_type \n\n\nData set from UBA = Umweltbundesamt = German Federal Environmental Agency"
  },
  {
    "objectID": "slides/10-multivariate.html#code-to-read-the-data",
    "href": "slides/10-multivariate.html#code-to-read-the-data",
    "title": "Multivariate methods",
    "section": "Code to read the data",
    "text": "Code to read the data\n\nlakes <- read.csv(file=\"lakes-combined-data.csv\")\nvalid_columns <- c(\"name\", \"shortname\", \"z_mean\", \"z_max\",  \"t_ret\", \"volume\", \n  \"area\", \"p_tot\", \"n_no3\", \"chl\", \"wfd_type\")\nlakes <- lakes[valid_columns] |> na.omit()\nrow.names(lakes) <- lakes$shortname\n\nlake_ids <- lakes[c(\"name\", \"shortname\")]\nlakedata <- lakes[, -c(1, 2)]\n\n## remove wfd_type for now\nlakedata$wfd_type <- NULL\n\n\ndata available from …………………."
  },
  {
    "objectID": "slides/10-multivariate.html#data-transformation-and-normalization",
    "href": "slides/10-multivariate.html#data-transformation-and-normalization",
    "title": "Multivariate methods",
    "section": "Data transformation and normalization",
    "text": "Data transformation and normalization\n\npar(mfrow = c(1, 4), mar = c(6, 4, 3, 1), las = 2)\nboxplot(lakedata, main = \"raw data\")\nboxplot(scale(lakedata), main = \"normalized\")\nboxplot(scale(sqrt(lakedata)), main = \"sqrt + normalized\")\nboxplot(scale(log(lakedata)), main = \"log + normalized\")\n\n\n\nscale() performs normalisation (z-transformation)\naim: make different scales better comparable"
  },
  {
    "objectID": "slides/10-multivariate.html#pca-biplot",
    "href": "slides/10-multivariate.html#pca-biplot",
    "title": "Multivariate methods",
    "section": "PCA Biplot",
    "text": "PCA Biplot\n\nbiplot(pc)"
  },
  {
    "objectID": "slides/10-multivariate.html#pca-with-sqrt-transformed-data",
    "href": "slides/10-multivariate.html#pca-with-sqrt-transformed-data",
    "title": "Multivariate methods",
    "section": "PCA with sqrt transformed data",
    "text": "PCA with sqrt transformed data\n\n\nlakedata2 <- sqrt(lakedata)\npc2 <- prcomp(scale(lakedata2))\nsummary(pc2)\n\nImportance of components:\n                         PC1    PC2    PC3     PC4     PC5     PC6     PC7    PC8\nStandard deviation     2.111 1.3059 0.9748 0.70830 0.50321 0.29742 0.17060 0.1266\nProportion of Variance 0.557 0.2132 0.1188 0.06271 0.03165 0.01106 0.00364 0.0020\nCumulative Proportion  0.557 0.7702 0.8889 0.95165 0.98330 0.99436 0.99800 1.0000\n\n\n * The PCA with the untransformed data looked very asymmetric, we repeat it with square root transformed data. * helps to get a better “resolution” * must be taken into account when interpreting the results * log transformation is also possible"
  },
  {
    "objectID": "slides/10-multivariate.html#biplot-of-sqrt-transformed-data",
    "href": "slides/10-multivariate.html#biplot-of-sqrt-transformed-data",
    "title": "Multivariate methods",
    "section": "Biplot of sqrt transformed data",
    "text": "Biplot of sqrt transformed data\n\npar(mfrow=c(1,2))\npar(mar=c(5, 4, 4, 2) + 0.1)\nbiplot(pc2, cex=0.6)\nbiplot(pc2, cex=0.6, choices=c(3, 2))\n\n\n\nIn addition, also the 3rd PC is plotted."
  },
  {
    "objectID": "slides/10-multivariate.html#principal-component-analysis-pca",
    "href": "slides/10-multivariate.html#principal-component-analysis-pca",
    "title": "Multivariate methods",
    "section": "Principal Component Analysis: PCA",
    "text": "Principal Component Analysis: PCA\n\n\n\n\npc <- prcomp(scale(lakedata))\n\nEigenvalues (proportion of variance) indicate importance of components.\n\nsummary(pc)\n\nImportance of components:\n                          PC1    PC2   PC3     PC4    PC5     PC6     PC7     PC8\nStandard deviation     2.0692 1.2735 1.047 0.76067 0.5499 0.30497 0.12230 0.10618\nProportion of Variance 0.5352 0.2027 0.137 0.07233 0.0378 0.01163 0.00187 0.00141\nCumulative Proportion  0.5352 0.7379 0.875 0.94729 0.9851 0.99672 0.99859 1.00000"
  },
  {
    "objectID": "slides/10-multivariate.html#biplot-of-sqrt-transformed-data-here-also-3rd-pc",
    "href": "slides/10-multivariate.html#biplot-of-sqrt-transformed-data-here-also-3rd-pc",
    "title": "Multivariate methods",
    "section": "Biplot of sqrt transformed data (here also 3rd PC)",
    "text": "Biplot of sqrt transformed data (here also 3rd PC)\n\npar(mfrow=c(1, 2), mar=c(5, 4, 4, 2.4), las=1)\nbiplot(pc)\nbiplot(pc2, choices=c(3, 2))"
  },
  {
    "objectID": "slides/10-multivariate.html#a-taxonomic-table",
    "href": "slides/10-multivariate.html#a-taxonomic-table",
    "title": "Multivariate methods",
    "section": "A Taxonomic Table",
    "text": "A Taxonomic Table\n\n\n\n\n\n \n  \n    Site \n    Mollusca \n    Diptera \n    Baetis \n    Plecoptera \n    Coleoptera \n    Turbellaria \n    Heptageniidae \n    Ephemeroptera \n    Gammarus \n    Trichoptera \n    Acari \n    Nematoda \n    Oligochaeta \n  \n \n\n  \n    GP9 \n    3 \n    165 \n    91 \n    14 \n    6 \n    3 \n    9 \n    136 \n    256 \n    45 \n    6 \n    0 \n    11 \n  \n  \n    GR9 \n    31 \n    438 \n    728 \n    31 \n    728 \n    11 \n    31 \n    0 \n    65 \n    367 \n    3 \n    0 \n    503 \n  \n  \n    TP9 \n    0 \n    26 \n    3 \n    20 \n    9 \n    0 \n    3 \n    20 \n    119 \n    40 \n    0 \n    0 \n    23 \n  \n  \n    TR9 \n    0 \n    11 \n    6 \n    37 \n    11 \n    0 \n    0 \n    3 \n    68 \n    26 \n    0 \n    0 \n    23 \n  \n  \n    GP8 \n    23 \n    913 \n    31 \n    14 \n    3 \n    9 \n    6 \n    26 \n    901 \n    37 \n    3 \n    20 \n    0 \n  \n  \n    GR8 \n    225 \n    1066 \n    310 \n    199 \n    461 \n    48 \n    91 \n    23 \n    688 \n    600 \n    26 \n    0 \n    284 \n  \n  \n    TP8 \n    17 \n    2204 \n    54 \n    117 \n    11 \n    0 \n    11 \n    20 \n    2525 \n    77 \n    3 \n    3 \n    68 \n  \n  \n    TR8 \n    3 \n    520 \n    74 \n    762 \n    125 \n    20 \n    65 \n    0 \n    668 \n    173 \n    3 \n    0 \n    267 \n  \n  \n    GP7 \n    26 \n    247 \n    68 \n    6 \n    3 \n    3 \n    3 \n    20 \n    813 \n    9 \n    6 \n    0 \n    0 \n  \n  \n    GR7 \n    117 \n    509 \n    290 \n    63 \n    191 \n    6 \n    26 \n    11 \n    682 \n    117 \n    60 \n    9 \n    131 \n  \n  \n    TP7 \n    26 \n    3477 \n    17 \n    28 \n    0 \n    0 \n    3 \n    37 \n    2693 \n    17 \n    0 \n    0 \n    0 \n  \n  \n    TR7 \n    48 \n    429 \n    57 \n    412 \n    97 \n    9 \n    63 \n    9 \n    808 \n    102 \n    26 \n    6 \n    57 \n  \n  \n    GP10 \n    3 \n    159 \n    14 \n    31 \n    3 \n    0 \n    48 \n    91 \n    100 \n    23 \n    0 \n    0 \n    17 \n  \n  \n    GR10 \n    0 \n    68 \n    191 \n    26 \n    51 \n    3 \n    253 \n    0 \n    80 \n    233 \n    3 \n    0 \n    11 \n  \n  \n    TP10 \n    0 \n    51 \n    0 \n    6 \n    9 \n    0 \n    0 \n    6 \n    71 \n    0 \n    0 \n    0 \n    31 \n  \n  \n    TR10 \n    0 \n    28 \n    6 \n    40 \n    14 \n    0 \n    0 \n    0 \n    40 \n    54 \n    0 \n    0 \n    0 \n  \n\n\n\n\n\n\n\nAggregated part of taxa list from two small streams."
  },
  {
    "objectID": "slides/10-multivariate.html#distance-and-similarity-measures",
    "href": "slides/10-multivariate.html#distance-and-similarity-measures",
    "title": "Multivariate methods",
    "section": "Distance and similarity measures",
    "text": "Distance and similarity measures\n\n\n\nPCA works with Euclidean distance\nrule of Pythagoras\n\n\\[\na^2 + b^2 = c^2 \\quad \\Rightarrow\\quad c = \\sqrt{a^2 + b^2}\n\\]\n\nbut: Euclidean distance is not always the best option."
  },
  {
    "objectID": "slides/10-multivariate.html#euclidean-distance",
    "href": "slides/10-multivariate.html#euclidean-distance",
    "title": "Multivariate methods",
    "section": "Euclidean distance",
    "text": "Euclidean distance\n\n\n\nPCA works with Euclidean distance\nrule of Pythagoras\n\n\\[\na^2 + b^2 = c^2 \\quad \\Rightarrow\\quad c = \\sqrt{a^2 + b^2} = \\sqrt{\\Delta x^2 + \\Delta y^2}\n\\]\n\nbut: Euclidean distance is not always the best option."
  }
]