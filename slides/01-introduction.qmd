---
title: "01-Introduction"
subtitle: "Applied Statistics -- A Practical Course"
date:   "`r Sys.Date()`"
---


# Preface{data-background-color="#006ab2"}

## Goals of the course

<br>

1. Introduction to "Data Science"
2. Statistical concepts and selected methods
    - Statistical parameters
    - Distributions and probability
    - Statistical tests
    - Model selection
3. Practical experience
    - Data strutures
    - Basics of the R language
    - Applications with real and simulated data sets

$\Rightarrow$ Practical understanding and "statistical feeling",

$\rightarrow$ More important than facts learned by heart.

## Topics

<br>

1. Basic Concepts of Statistics
2. An Introduction to R
3. Statistical Parameters and Distributions
4. Linear Models
5. Analysis of Variance
5. Nonlinear Regression
7. Time Series Analysis
6. (Multivariate Statistics)



## Material

<br>

* Slides
* Exercises
* Course script for self study "Data Analysis with R – Selected Topics and Examples"
* **Note:** Slides, script and exercises are regularly updated, depending on the progress of the course.
* **Exam:** Written exam at the end of the semester.<br>
  $\rightarrow$ [Attend the labs!]{.red}

<br>

::: {.bigfont .fragment .highlight-red}
Questions?
:::


# Why Statistics?{data-background-color="#006ab2"}

$\rightarrow$ a few examples before we begin

## An introductory example

Daily average discharge of River Elbe, pegel Dresden, river km 55.6

```
date,       discharge
1806-01-01,  472
1806-01-02, 1050
1806-01-03, 1310
1806-01-04, 1020
1806-01-05,  767
1806-01-06,  616
...
2020-10-11,  216
2020-10-12,  204
2020-10-13,  217
2020-10-14,  288
2020-10-15,  440
2020-10-16,  601
2020-10-17,  570
2020-10-18,  516
2020-10-19,  450
2020-10-20,  422
2020-10-21,  396
2020-10-22,  372
2020-10-23,  356
2020-10-24,  357
2020-10-25,  332
2020-10-26,  303
2020-10-27,  302
2020-10-28,  316
2020-10-29,  321
2020-10-30,  331
2020-10-31,  353
2020-11-01,  395
```


$>$ 70,000 measurements. How can we analyse this and what does it mean?

Data Source: [Bundesanstalt für Gewässerkunde](https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/elbe_info.txt)

## Plot the last 20 years

```{r elbe-timeseries1, echo=FALSE}

library(ggplot2)
dat <- read.csv("https://raw.githubusercontent.com/tpetzoldt/datasets/main/data/elbe.csv")
dat$date <- as.Date(dat$date)
dat <- na.omit(dat)

plot(discharge ~ date, data=dat, type="l")
```
Discharge of the Elbe River, gauge station Dresden, data source BfG

## What do these data tell us?

```{r elbe-timeseries2, echo=FALSE, fig.height=2.5}
par(mar=c(2,4,0.5,1))
plot(discharge ~ date, data=dat, type="l")
```

* What is the average discharge? → mean values
* How much variation is in the data? → variance
* How likely are droughts or floods? → distribution
* How precise are our forecasts? → confidence intervals
* Which factors influence discharge? → correlations

## How to start

```{r elbe-timeseries3, echo=FALSE, fig.height=2.5}
par(mar=c(2,4,0.5,1))
plot(discharge ~ date, data=dat, type="l")
```

* Mean value: `r round(mean(dat$discharge, 2))`
* Median value: `r round(median(dat$discharge, 2))`
* Standard deviation: `r round(sd(dat$discharge, 2))`
* Range: `r round(range(dat$discharge, 2))`

Which of these parameters are most appropriate?

## Graphics

```{r elbe-barplot, echo=FALSE}
par(mar=c(4.1,5,3,1))
par(mfrow=c(2,2))
dat$year <- as.numeric(format(dat$date, "%Y"))
with(dat, plot(date, discharge, ylab=expression(m^3~s^{-1}), type="l", las=1, main="Time series"))
with(dat, boxplot(discharge ~ year, ylab=expression(m^3~s^{-1}), range=0, las=2, main="Boxplot"))
avg <- with(dat, aggregate(list(Q=discharge), list(year=year), mean))
with(dat, barplot(avg$Q, las=2, names.arg=avg$year, ylab=expression(m^3~s^{-1}), main="Barplot"))
with(dat, hist(discharge, xlab=expression(m^3~s^{-1}), las=1, main="Histogram", col="gray"))
```

## Boxplots

```{r elbe-boxplot}
par(mfrow=c(1,2))
par(mar=c(4.1,5,1,1))
with(dat, boxplot(discharge, ylab=expression(m^3~s^{-1}), range=0, las=2, main="", log="y"))
with(dat, text(rep(0.6, 3), c(min(discharge), median(discharge), max(discharge)), c("min", "median", "max")))
text(rep(1.3, 3), quantile(dat$discharge, c(0.25, 0.5, 0.75)), c("25%", "50%", "75%"))
with(dat, boxplot(discharge, ylab=expression(m^3~s^{-1}), las=2, main="", log="y"))
```

* Note the log scale of y!
* In the right version, whiskers extend to the most extreme data point
which is no more than 1.5 times the interquartile range from the box.

## Three ways to work with statistics

**Descriptive statistics and graphics**

* plots, like in the examples
* mean values, standard deviations, ...
* interpret raw data

**Hypothesis testing**

* distinguish effects from random fluctuations
* make results more convincing

**Statistical modelling**

* measure size of effects (e.g. climate trends)
* build models that aggregate dependencies
* machine learning

## Statistical hypothesis testing

<br>

**How likely is it, that our hypothesis is true?**

<br>

* Turn scientific into statistical hypothesis
* Estimate probability (p value) of a given hypothesis
Examples
* Is a medical treatment successful or not? → $\chi^2$-test
* Does a specific food diet increase yield of a fish farm? → t-test
* Which factors (e.g. food, temperature, pH) of a combined
treatment influence growth of aquatic animals? → ANOVA
* (How) does observed algal biomass depend on phosphorus?<br>

## Statistical modeling

**Fit a statistical model to the data**

* Select proper modelling strategy
* Design statistical models
* Measure effect size
* Select the optimum model between different model candidates

**Examples**

* Fit a distribution to annual discharge data to estimate the 100year
flood.
* Fit an ANOVA model to experimental data to see which factors
influence the result most.
* Fit a multiple linear model to climate data to see how much climate
trends differ between geographical location.

## Example: Compare two mean values

```{r dobson-boxplot, fig.align='center'}
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  gender = gl(2, 12, labels=c("male","female"))
)
with(dobson, boxplot(weight ~ gender, las=1, main="Birth weight of babies (g)"))
```

* A given data set (Dobson, 1983) contains the birth weight (in g) of
12 boys and 12 girls.
* Has the weight difference something to do with the gender of the
babies or is it a purely random fluctuation?

## Example: Correlation and regression

```{r regression-example, fig.height=3, fig.width=8}
par(mfrow=c(1,2))
dat <- read.table("../data/seen_bb.txt", header=TRUE)
#dat <- dat[c(1,2,5,6), ]
plot(log(Chl) ~ log(P), data=dat, pch=16, col="red",
  main=paste("r =", round(with(dat, cor(log(P), log(Chl))), 2), collapse="="))
m1 <- lm(log(Chl) ~ log(P), data=dat)
abline(m1)
oecd <- read.table("../data/oecd.txt", header=TRUE)
plot(log(CHLa) ~ log(TP), data=oecd, pch=16, col="navy",
  main=paste("r =", round(with(oecd, cor(log(TP), log(CHLa))), 2), collapse="="))
m2 <- lm(log(CHLa) ~ log(TP), data=oecd)
abline(m2)
```


* Dependence of chlorophyll concentration in lakes on phosphorus, a
regional data set from Koschel and Scheffler (1985) (left) and from
Vollenweider and Kerekes (1980) (right).
* Which of the two figures has greater predictive power? Why?


# How to do this in practice?{data-background-color="#006ab2"}

## Required software

* A spreadsheet program, Excel or LibreOffice [https://www.libreoffice.org/](https://www.libreoffice.org/)
* The **R** system for data analysis and graphics [https://www.r-project.org](https://www.r-project.org)
* RStudio for making R more user-friendly [https://posit.co/download/rstudio-desktop/](https://posit.co/download/rstudio-desktop/)

![](../img/r-homepage.png){fig-align="center"}

## Why R?

::: {.column width="58%"}

1. Statisticians call it "lingua franca" in computational statistics.
    * Extremely powerful
    * No other system has so much statistics
    * Used in statistical research
2. Free (OpenSource)
    * Free to use
    * Free to modify
    * Free to contribute
3. Less complicated than its first appearance:
    * Yes, it needs command line programming
    * but: already a single line can do much
    * huge number of books and online scripts
    
:::

::: {.column width="41%"}

![](../img/r-homepage.png)
::: 

In contrast to other systems Copy & Paste is allowed! – just cite it.


## Books

**Statistics**

* Well-readable introductions
    - Dalgaard, P., 2008: Introductory Statistics with **R**. Springer, New York, 2nd edition. (fulltext of the 1st edition [freely available](https://link.springer.com/book/10.1007/b97671))
    - Verzani, J. (2019). Using R for introductory statistics. CRC press. Fulltext available via DOI [https://doi.org/10.1111/anzs.12146](https://doi.org/10.1111/anzs.12146)

* A very well understandable introduction into many fields:
   of statistics, especially regression and time series analysis:
  - Kleiber, C. and Zeileis, A., 2008: Applied Econometrics with R,
    Springer Verlag, New York. [https://link.springer.com/book/10.1007/978-0-387-77318-6](https://link.springer.com/book/10.1007/978-0-387-77318-6)

**R Programming**
    
* An introduction todata science using the modern "tidyverse" approach:
  - Wickham, H., Çetinkaya-Rundel, M and Grolemund, G, 2023: R for Data Science.
  [https://r4ds.hadley.nz/](https://r4ds.hadley.nz/)


::: aside
And lots of material available freely on the internet ...
:::


