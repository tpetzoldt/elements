---
title: "07-One and two-way ANOVA"
subtitle: "Applied Statistics -- A Practical Course" 
date:   "`r Sys.Date()`"
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library("dplyr")
library("tidyr")
library("kableExtra")
library("car")
mypar <- list(las=1, cex.lab=1.4, cex.axis=1.4, lwd=2)
```


## ANOVA â€“ Analysis of Variances

<br>

* Testing of complex hypothesis as a whole, e.g.:
    * more than two samples (multiple test problem),
    * several multiple factors (multiway ANOVA)
    * elimination of covariates (ANCOVA)
    * fixed and/or random effects
    (variance decomposition methods, mixed effects models)
* Different application scenarios:
    * explorative use: Which influence factors are important?
    * descriptive use: Fitting of models for process description and
    forecasting.
    * significance tests.
* ANOVA methods are (in most cases) based on linear models.



## A practical example


::: {.column width="49%"}

[Find a suitable medium for growth experiments with green algae]{.darkred}

* cheap, easy to handle
* suitable for students courses and classroom experiments

:::

::: {.column width="49%"}
![](../img/ansaetze.jpg)

:::

**Idea**

* use a commercial fertilizer with the main nutrients N and P
* mineral water with trace elements
* does non-sparkling mineral water contain enough $\mathrm{CO_2}$?
* test how to improve ($\mathrm{CO_2}$) availability for photosynthesis


## Application

<br>

**7 Different treatments**

<br>

1. fertilizer solution in closed bottles 
2. fertilizer solution in open bottles ($\mathrm{CO_2}$ from air)
3. fertilizer + sugar (organic C source)
4. fertilizer + additional $\mathrm{HCO_3^-}$ (add $\mathrm{CaCO_3}$ to sparkling mineral water)
5. a standard algae growth medium ("Basal medium") for comparison
6. deionized ("destilled") water and 
7. tap water for comparison


## Experimental design



![](../img/ruettler.jpg){fig-align="center" fig-alt="bottles with algae on a shaker"}

* each treatment with 3 replicates
* randomized placement on a shaker
* 16:8 light:dark-cycle
* measurement directly in the bottles using a self-made [turbidity meter](https://tpetzoldt.github.io/growthlab/doc/versuchsaufbau.html)

## Results


<div class="vbox"></div>
<div class="hbox">
![](../img/ansaetze2.jpg)
Fertilizer -- Open Bottle -- F. + Sugar -- F. + CaCO3 -- Basal medium -- A. dest -- Tap water
</div>


## The data set

<br>

```{r, echo=FALSE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)

xalgae <- 
  algae |> 
  pivot_wider(id_cols = treat, names_from = rep, values_from = growth, names_prefix = "replicate ")
```


```{r}
#| label: tbl-algae-growth
#| tbl-cap: "Growth from day 2 to day 6 (relative units)"

xalgae |>
  kable('html') |> 
  kable_styling(bootstrap_options = "striped", full_width = FALSE)
```

* [NA]{.red} means "not available", i.e. a missing value
* the crosstable structure is compact and esy to read, but not suitable for data analysis
* $\Rightarrow$ convert it to long format


## Data in long format

::: {.column width="59%"}

<br>

### Advantages

* looks "stupid" but is better for data analysis
* dependent variable **growth** and <br>explanation variable **treat** clearly visible
* model formula: `growth ~ treat`
* easily extensible to $>1$ explanation variable

:::


::: {.column width="39%"}
```{r}
algae |> 
  head(12) |>
  kable('html') |>
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```
:::


## The data in R

<br><br>

```{r, echo=TRUE}
algae <- data.frame(
  treat  = factor(c("Fertilizer", "Fertilizer", "Fertilizer", 
             "F. open", "F. open", "F. open", 
             "F.+sugar", "F.+sugar", "F.+sugar", 
             "F.+CaCO3", "F.+CaCO3", "F.+CaCO3", 
             "Bas.med.", "Bas.med.", "Bas.med.", 
             "A.dest", "A.dest", "A.dest", 
             "Tap water", "Tap water"),
             levels=c("Fertilizer", "F. open", "F.+sugar", 
                    "F.+CaCO3", "Bas.med.", "A.dest", "Tap water")),
  rep   = c(1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2), 
  growth = c(0.02, -0.217, -0.273, 0.94, 0.78, 0.555, 0.188, -0.1, 0.02, 
             0.245, 0.236, 0.456, 0.699, 0.727, 0.656, -0.01, 0, -0.01, 0.03, -0.07)
)
```

... can be entered directly in the code. A csv-file in long format is also possible.

## Boxplot

```{r algae-boxplot, echo=TRUE}
boxplot(growth ~ treat, data = algae)
abline(h = 0, lty = "dashed", col = "grey")
```

## Stripchart

```{r algae-stripchart, echo=TRUE}
stripchart(growth ~ treat, data = algae, vertical = TRUE)
```
Better, because we have only 2-3 replicates. Boxplot needs more.


## Turn scientific question into a statistical hypothesis

<br>

**Scientific Questions**

* Are the treatments different?
* Which medium is the best?
* Is the best medium significantly better than the others?

<br>
**Statistical Hypotheses**

* $H_0$: growth is the same in all treatments
* $H_A$: differences between media

## Why can't we apply just several t-tests?

<br>

* If we have 7 treatments and want to test all against each other, we would need: 

$$7 \cdot (7 - 1) / 2 = 21 \qquad\text{tests.}$$

* If we set $\alpha = 0.05$ we get 5% false positives. $\Rightarrow$ [One]{.red} of 20 tests is on average a [false positive]{.red}
* If we do $N$ tests, we increase the overall $\alpha$ error to $N\cdot\alpha$ in the worst case.
* This is called **alpha-error-inflation** or the **Bonferroni** law:

$$
\alpha_{total} \le \sum_{i=1}^{N} \alpha_i = N \cdot \alpha
$$


If we ignore the Bonferroni law, we end in **statistical fishing** and
get spurious results just by chance. See [https://xkcd.com/882/](https://xkcd.com/882/).

# Solutions

:::{.bigfont}
1. Down-correct the alpha errors so that $\alpha_{total} = 0.05$.<br> $\rightarrow$ Bonferroni rule.
2. Use a method that does all tests simultanaeously: the ANOVA.
:::

## ANOVA: Analysis of variances

<br>

**Basic Idea**

* Split the total variance into effect(s) and errors:


:::{.bigfont}
$$
s_y^2 = s^2_\mathrm{effect} + s^2_{\varepsilon}
$$
:::

* Somewhat surprising: we use variances to compare mean values. 
* **Explanation:** differences of means contribute to the total variance of the
whole sample. 
* Variance components can be called **variance within** ($s^2_\varepsilon$) and variance **between** samples.
* The way how to separate variances is a [linear model]{.blue}.

## Example

<br>

Two brands of Clementine fruits from a shop "E", that we encode as "EB" and "EP".
We want to know whether the premium brand ("P") and the basic brand ("B") have
a different weight.


```{r, echo=TRUE, eval=TRUE}
clem <- data.frame(
  brand = c("EP", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", "EB", 
            "EB", "EB", "EB", "EP", "EP", "EP", "EP", "EP", "EP", "EP", "EB", "EP"),
  weight = c(88, 96, 100, 96, 90, 100, 92, 92, 102, 99, 86, 89, 99, 89, 75, 80, 
             81, 96, 82, 98, 80, 107, 88))
```

<br>
We encode one sample ("EB") with 1 and the other sample ("EP") with 2: 


```{r, echo=TRUE, eval=TRUE}
clem$code <- as.numeric(factor(clem$brand))
clem$code
```

## Then we fit a linear regression:


```{r eb-ep-linear, echo=TRUE, eval=TRUE}
plot(weight ~ code, data = clem, axes = FALSE)
m <- lm(weight ~ code, data = clem)
axis(1, at = c(1,2), labels = c("EB", "EP")); axis(2); box()
abline(m, col = "blue")
```




## Variance components

<br>

We fit a linear model and compare the variances:

```{r eval=FALSE, echo=TRUE}
m <- lm(weight ~ code, data = clem)
```


**total variance**

```{r, echo=TRUE}
(var_tot <- var(clem$weight))
```

**residual variance (= within variance)**

```{r, echo=TRUE}
(var_res <- var(residuals(m)))
```

**explained variance (= between variance)**

```{r, echo=TRUE}
var_tot - var_res
```
Now we can analyse whether the between variance is big enough to justify a 
significant effect.

This is called an ANOVA.

## ANOVA

```{r, echo=TRUE}
anova(m)
```

<br>

**A t-test for comparison**

```{r, echo=TRUE}
t.test(weight ~ code, data = clem, var.equal=TRUE)
```

$\Rightarrow$ the p-values are exactly the same.




## ANOVA with more than 2 samples


Back to the algae growth data. Let's call the linear model `m`:

```{r echo=TRUE}
m <- lm(growth ~ treat, data = algae)
```

<br>

* We can print the coefficients of the linear model with `summary(m)`
* But we are interested in the overall effect and use `anova`

```{r echo=TRUE}
anova(m)
```

* The ANOVA table shows F-tests testing for significance of all factors.
* In the table above, we have only one single factor.

$\Rightarrow$ We see that the treatment had a significant effect.


## Posthoc tests


* The test showed, that the **factor** "treatment" had a significant effect.
* We don't know yet, which **factor levels** were different. 

**Tukey HSD test** is the most common.

```{r, echo=TRUE}
tk <- TukeyHSD(aov(m))
tk
```

## Graphical output

```{r algae-tukey, echo=TRUE}
par(las = 1)             # las = 1 make y annotation horizontal
par(mar = c(4, 10, 3, 1)) # more space at the left for axis annotation
plot(tk)
```



## ANOVA assumptions and diagnostics



::: {.column width="49%"}

ANOVA has same assumptions as the linear model.

<br>

1. Independence of errors
2. Variance homogeneity
3. Approximate normality of errors

Graphical checks are preferred.

:::

::: {.column width="49%"}
```{r algae-diagnostics, echo=TRUE, fig.height=5, fig.width=5}
par(mfrow=c(2, 2))
plot(m)
```
:::

## Numerical tests

<br><br>

::: {.column width="49%"}

**Test variance homogeneity**

* F-test compares only two variances.
* Several tests for multiple variances available, e.g. Bartlett, Levene, Fligner-Killeen
* Recommended: Fligner-Killeen-test

```{r, echo=TRUE}
fligner.test(growth ~ treat, 
             data = algae)
```

:::

::: {.column width="49%"}
**Test of normal distribution**

* The Shapiro-Wilks test can be misleading.
* Use a graphical method!

```{r algae-qqnorm, echo=TRUE, fig.width=6, fig.height=3}
qqnorm(residuals(m))
qqline(residuals(m))
```

:::


## One-way ANOVA with heterogeneous variances

<br><br>

* extension of the Welch test for $\ge 2$ samples
* in R called `oneway.test`

```{r, echo=TRUE}
oneway.test(growth ~ treat, data = algae)
```


## Two-way ANOVA


```{r}
hams <- data.frame(No=1:12,
  growth =c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
           8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
  diet = rep(c("A", "B", "C"), each=2),
  coat = rep(c("light", "dark"), each=6)
)
```


* Example from a statistics text book [@Crawley2002]
* Effects of diet and coat color on growth of Hamsters in gramm per time

| diet | light coat  | dark coat   |
|------|-------------|-------------|
| A    | 8.3         | 6.6         |
| A    | 8.7         | 7.2         |
| B    | 8.1         | 6.9         |
| B    | 8.5         | 8.3         |
| C    | 9.1         | 7.9         |
| C    | 9.0         | 9.2         |
|      |             |             |


* factorial experiment (**with replicates**): each factor combination has more than one observation.
* without replication: 
   - no replicates per factor combination
   - this is possible, but does not allow identification of interactions

## Enter data in long format

::: {.column width="59%"}

<br><br>

```{r, echo=TRUE}
hams <- data.frame(No = 1:12,
                   growth = c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   diet = rep(c("A", "B", "C"), each=2),
                   coat = rep(c("light", "dark"), each=6)
                   )
```
:::

::: {.column width="39%"}

```{r}
hams %>% 
  kable('html') %>% 
  kable_styling(bootstrap_options = c("striped"), full_width = FALSE)
```

:::


## Linear model and ANOVA

```{r hams-boxplot, fig.align='center'}
par(mfrow=c(1, 2))
boxplot(growth ~ diet, data = hams, col = "wheat")
boxplot(growth ~ coat, data = hams, col = "wheat")
```

**ANOVA**

```{r, echo=TRUE}
m <- lm(growth ~ coat * diet, data = hams)
anova(m)
```

## Interaction plot

```{r hams-interaction, echo=TRUE}
with(hams, interaction.plot(diet, coat, growth, 
                            col = c("brown", "orange"), lty = 1, lwd = 2))
```

## Diagnostics


**Assumptions**

1. Independence of measurements (within samples)
2. Variance homogeneity of residuals
3. Normal distribution of residuals

<br>
[Test of assumptions needs residuals of the fitted model.]{.red}
$\Rightarrow$ Fit the ANOVA model first, then check if it was correct!

<br>

**Diagnostic tools**

* Box plot
* Plot of residuals vs. mean values
* Q-Q-plot of residuals
* Fligner-Killeen test (alternative: some people recommend the Levene-Test)

## Diagnostics II

```{r hams-diagnostics, echo=TRUE, fig.align='center'}
par(mfrow=c(1, 2))
par(cex=1.2, las=1)
qqnorm(residuals(m))
qqline(residuals(m))

plot(residuals(m)~fitted(m))
abline(h=0)
```  

```{r, echo=TRUE}  
fligner.test(growth ~ interaction(coat, diet), data=hams)
```

Residuals: look ok and p-value of the Fligner test $< 0.05$, $\rightarrow$ looks fine. 

## Notes

**Linear regression or ANOVA?**

* essentially the same
* independent variables are **metric**: linear model
* independent variables are nominal (= factor): ANOVA
* mix of metric and nominal variables: ANCOVA

**Use of pre-tests**

Pre-tests are in general questionable for theoretical reasons:

1. The null hypotheses $H_0$ can only be rejected and not ultimately confirmed. 
2. If the sample size is large, normality of residuals is not required
3. If $p$ is close to the threshold and sample size is small, we would be 
left in uncertainty.



All this can only be overcome with careful thinking and some experience.

It is always a good idea to discuss results with colleagues and supervisors.

## Sequential Holm-Bonferroni method

* Also called Holm procedure [@Holm1979]
* Easy to use
* Can be applied to any multiple test problem
* Less conservative that ordinary Bonferroni correction, but ...
* ... still a very conservative approach
* see also [Wikipedia](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method)

**Algorithm**

1. Select smallest $p$ out of all $n$ $p$-values
2. If $p \cdot n < \alpha$ $\Rightarrow$ significant, else <bf>STOP</bf>
3. Set $n âˆ’ 1 \rightarrow n$, remove smallest $p$ from the list and go to step 1.


## Example

Growth rate per day ($d^{-1}$) of blue-green algae cultures (*Pseudanabaena*) after adding
toxic peptides from another blue-green algae (*Microcystis*).

The original hypothesis was that Microcystin LR (MCYST) or a derivative of it 
(Substance A) inhibits growth.

```{r, echo=TRUE}
mcyst <-  data.frame(treat = factor(c(rep("Control", 5),
                                       rep("MCYST", 5),
                                       rep("Subst A", 5)),
                                levels=c("Control", "MCYST", "Subst A")),
                      mu   = c(0.086, 0.101, 0.086, 0.086, 0.099,
                               0.092, 0.088, 0.093, 0.088, 0.086,
                               0.095, 0.102, 0.106, 0.106, 0.106)
                     )
```

## Approach 1: one-way ANOVA

```{r mcyst-tukey, echo=TRUE}
par(mar=c(4, 8, 2, 1), las=1)
m <- lm(mu ~ treat, data=mcyst)
anova(m)
plot(TukeyHSD(aov(m)))
```

## Approach 2: multiple t-Tests with sequential Bonferroni correction

We separate the data set in single subsets:

```{r, echo=TRUE}
Control <- mcyst$mu[mcyst$treat == "Control"]
MCYST   <- mcyst$mu[mcyst$treat == "MCYST"]
SubstA  <- mcyst$mu[mcyst$treat == "Subst A"]
```

and perform 3 t-Tests:

```{r, echo=TRUE}
p1 <- t.test(Control, MCYST)$p.value
p2 <- t.test(Control, SubstA)$p.value
p3 <- t.test(MCYST, SubstA)$p.value
```

The following shows the raw p-values without correction:

```{r, echo=TRUE}
c(p1, p2, p3)
```

and with Holm correction:

```{r, echo=TRUE}
p.adjust(c(p1, p2, p3))
```

## Conclusions


**Statistical methods**

* In case of Holm-corrected t-tests, only a single p-value (MCYST vs. Subst A) remains significant. 
This indicates that in this case, Holm's method is more conservative than TukeyHSD 
(only one compared to two significant) effects.
* An ANOVA with posthoc test is in general preferred,
* but the sequential Holm-Bonferroni can be helpful in special cases. 
* Moreover, it demonstrates clearly that massive
multiple testing needs to be avoided.

$\Rightarrow$  ANOVA is to be preferred, when possible.

**Interpretation**

* Regarding our original hypothesis, we can see that MCYST and SubstA did not
inhibit growth of *Pseudanabaena*. In fact SubstA stimulated growth.
* This was contrary to our expectations -- the biological reason was then found 10 years later.

More about this can be found in @Jahnichen2001, @Jahnichen2007, @Jahnichen2011, @Zilliges2011 or @Dziallas2011.


## ANCOVA


**Statistical question**

* Comparison of regression lines
* Similar to ANOVA, but contains also **metric** variables (covariates)


**Example**

Annette Dobson's birthweight data. A data set from a statistics textbook 
[@Dobson2013], birth weight of boys and girls in dependence of the
pregnancy week.

```{r dobson-lines, echo=FALSE}
## Birth Weight Data see stats/demo/lm.glm.R
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  sex = gl(2, 12, labels=c("M","F"))
)
plot(weight ~ week, data=dobson, col=c("blue", "red")[as.numeric(sex)], pch=16)
fem <- lm(weight ~ week, data=dobson, subset = sex=="F")
mal <- lm(weight ~ week, data=dobson, subset = sex=="M")
abline(fem, col = "red")
abline(mal, col = "blue")
```

## The birthweight data set

The data set is found at different places on the internet and in different versions.

Here the version that is found in an R demo: `demo(lm.glm)`

```{r echo=TRUE, eval=FALSE}
## Birth Weight Data see stats/demo/lm.glm.R
dobson <- data.frame(
  week = c(40, 38, 40, 35, 36, 37, 41, 40, 37, 38, 40, 38,
	 40, 36, 40, 38, 42, 39, 40, 37, 36, 38, 39, 40),
  weight = c(2968, 2795, 3163, 2925, 2625, 2847, 3292, 3473, 2628, 3176,
	    3421, 2975, 3317, 2729, 2935, 2754, 3210, 2817, 3126, 2539,
	    2412, 2991, 2875, 3231),
  sex = gl(2, 12, labels=c("M", "F"))
)
```

<!------------------------------------------------------------------------------
## Linear regression, ANOVA and ANCOVA


* ANCOVA (analysis of covariance) deals with the comparison of regression lines
* Simply speaking, we can distinguish the following:
    * independent variables have metric scale: linear regression
    * independent variables all nominal (factor): ANOVA
    * independent variables are mixed nominal and metric: ANCOVA
    
For the linear models discussed so far, the **dependent** variable is always 
metric, while binary or nominal dependent variables can be handled with generalized
linear models (GLM).
------------------------------------------------------------------------------->

## Anette Dobson's birthweight data

Why not just using a t-test?

```{r dobson-boxplot, fig.align='center', echo=TRUE}
boxplot(weight ~ sex,data=dobson, ylab="weight")
t.test(weight ~ sex, data=dobson, var.equal=TRUE)
```

The box plot shows much overlap and the difference is not significant, because
the t-test ignores important information: the pregnancy week.


## ANCOVA makes use of covariates


```{r, echo=TRUE}
m <- lm(weight ~ week * sex, data = dobson)
anova(m)
```

```{r dobson-ancova, echo=FALSE, fig.align='center'}
plot(weight ~ week, data=dobson, col=c("blue","red")[as.numeric(sex)], pch=16)
p <- coef(m)
abline(a=p[1], b=p[2], col="red")
abline(a=p[1]+p[3], b=p[2]+p[4], col="blue")

fem <- lm(weight ~ week, data=dobson, subset = sex=="F")
mal <- lm(weight ~ week, data=dobson, subset = sex=="M")
abline(fem, col="black", lty="dashed")
abline(mal, col="black", lty="dashed")
```

<!---------------------
## How this works

```{r, echo=TRUE, eval=FALSE}
plot(weight ~ week, data=dobson, col=c("blue","red")[as.numeric(sex)], pch=16)

#summary(m)
p <- coef(m)

## lines fitted by the ANCOVA
abline(a=p[1],      b=p[2],      col="red")
abline(a=p[1]+p[3], b=p[2]+p[4], col="blue")

## the result is the same as when we would fit separate linear models
fem <- lm(weight ~ week, data=dobson, subset = sex=="F")
mal <- lm(weight ~ week, data=dobson, subset = sex=="M")
abline(fem, col="black", lty="dashed")
abline(mal, col="black", lty="dashed")
```
--------------------------->

## Pitfalls of ANOVA and ANCOVA described so far

<br>

1. Heterogeneity of variance
    * p-values can be biased (i.e. misleading or wrong)
    * use of a one-way ANOVA for uneaqual variances (in R: `oneway.test`)
2. Unbalanced case:<br>
  unequal number of samples for each factor combination<br>
  $\rightarrow$ ANOVA results depend on the order of factors in the model formula.
    * Classical method: Type II or Type III ANOVA
    * Modern approach: model selection and likelihood ratio tests


## Type II and type III ANOVA

<br>

* function `Anova` (with upper case `A`) in package **car**
* Help file of function `Anova`:

> "Type-II tests are calculated according to the principle of
> marginality, testing each term after all others, except ignoring
> the termâ€™s higher-order relatives; so-called type-III tests violate
> marginality, testing each term in the model after all of the others."

* Conclusion:<br>
use Type II and donâ€™t try to interpret single terms in case of significant 
interactions.

## Type II ANOVA: Example


```{r hams-boxplot-ancova, echo=FALSE, fig.height=3}
par(mar=c(4.1, 5.1, 1.1, 1.1))
par(cex=1.2, las=1)
par(mfrow=c(1,2))
boxplot(growth~diet, data=hams, col="wheat", xlab="diet", ylab="growth")
boxplot(growth~coat, data=hams, col="wheat", xlab="coat")
```


```{r, echo=TRUE}
library("car")
m <- lm(growth ~ coat * diet, data = hams)
Anova(m, type="II")
```


## Model selection -- a paradigm change

<br>

**Problem:**

* In complicated models, p-values depend on number (and sometimes
  of order) of included factors and interactions.
* The $H_0$-based approach becomes confusing, e.g. because of
  contradictory p-values.

**Alternative approach:**

Comparison of different model candidates instead of p-value based testing.

* Model with all potentiall effects â†’ <span style="color:blue">full model</span>,
* Omit single factors â†’ <span style="color:blue">reduced models</span> (several!),
* No influence factors (ony mean value) â†’ <span style="color:blue">null model</span>.
* Which model is the best â†’ <span style="color:blue">minimal adequate model</span>?

## How can we measure which model is the best?

<br>

Compromise between model fit and model complexity (number of
parameters, k).

* Goodness of fit: Likelihood L (measures how good the data match a
given model).
* Log Likelihood: makes the criterion additive.
* AIC (Akaike Information Criterion):

$$AIC = âˆ’2 \ln(L) + 2k$$

* BIC (Bayesian Information Criterion), takes sample size
into account ($n$):

$$BIC = âˆ’2 \ln(L) + k Â· \ln(n)$$

The model with the smallest AIC (or BIC) is the
<span style="color:blue">minimal adequate</span> (i.e. optimal) model.

# Self study

Read the paper of @JohnsonOmland2004 
to gain more understanding of the model selection paradigm. 

[https://doi.org/10.1016/j.tree.2003.10.013](https://doi.org/10.1016/j.tree.2003.10.013)


## Model Selection and Likelihood Ratio Tests


**Approach**

1. Fit several models individually
2. Compare the models pairwise with ANOVA (likelihood ratio test)

**Data and example**

```{r, echo=TRUE}
hams <- data.frame(No=1:12,
                   growth=c(6.6, 7.2, 6.9, 8.3, 7.9, 9.2,
                            8.3, 8.7, 8.1, 8.5, 9.1, 9.0),
                   diet= rep(c("A", "B", "C"), each=2),
                   coat= rep(c("light", "dark"), each=6)
                   )
```

```{r, echo=TRUE}
m1 <- lm(growth ~ diet * coat, data=hams)
m2 <- lm(growth ~ diet + coat, data=hams)
anova(m1, m2)
```

* Likelihood ratio test compares two models (`anova` with > 1 model)
* Model with interaction (`m1`) not significantly better than model without
interaction (`m2`).

## AIC-based model selection

<br>

Pairwise model comparison is cumbersome, especially for large number of models.

**Solution**

Use Akaike Information Criterion and select the optimal (or: [minimal adequate]{.blue}) model.

```{r, echo=TRUE}
AIC(m1, m2)
```


**Conclusion:** take the simpler model (`m2`)

**Exercise:** Generate all possible models and select the model with minimum AIC.


## Automatic Model Selection


* The full model is supplied to the `step` function.
* The model with the smallest AIC ist the optimal model:

::: {.column width="49%"}
```{r, echo=TRUE}
m1 <- lm(growth ~ diet * coat, data=hams)
opt <- step(m1)
```
:::

::: {.column width="49%"}
```{r, echo=TRUE}
summary(opt)
```
:::

## Summary

* Linear models form the basis of many statistical methods
    * Linear regression
    * ANOVA, ANCOVA, GLM, GAM, GLMM, . . .
    * ANOVA/ANCOVA instead of multiple testing
* ANOVA is more powerful than multiple tests: 
    * one big experiment needs less n than many small experiments together
    * identification of interaction effects
    * elimination of co-variates
* Model selection vs. p-value based testing
    * paradigm shift in statistics: AIC instead of p-value
    * more reliable, especially for imbalanced or complex designs
    * but: p-value based tests are sometimes easier to understand


# Avoid p-value hacking


**Do NOT repeat experiments until a significant p-value is found.**

"As debate rumbles on about how and how much poor statistics is to
blame for poor reproducibility, Nature asked influential statisticians to
recommend one change to improve science. The common theme? The
problem is not our maths, but ourselves." Leek et al. (2017)


## Five ways to fix statistics. Comment on Nature

<br>

Leek et al. (2017) [https://doi.org/10.1038/d41586-017-07522-z](https://doi.org/10.1038/d41586-017-07522-z)

1. Jeff Leek: Adjust for human cognition
2. Blakeley B. McShane & Andrew Gelman: Abandon statistical significance
3. David Colquhoun: State false-positive risk, too
4. MichÃ¨le B. Nuijten: Share analysis plans and results
5. Steven N. Goodman: Change norms from within


Another blog post that aims to improve understanding:
http://daniellakens.blogspot.de/2017/12/understanding-common-misconceptions.html?m=1

<hr></hr>

**My conclusion:** The p-value is still useful but apply it with great care.

## Bibliography
