---
subtitle: "Applied Statistics -- A Practical Course"
title: "09-Time Series Basics"
date:   "`r Sys.Date()`"
--- 
```{r packages, echo=FALSE, include=FALSE}
library(dplyr)
library(readr)
library(ggplot2)
library(lubridate)
```

# Introductory examples

## Example 1: CO2 in the atmosphere

<!-- shown code reads data directly from NOAA -->

```{r co2-maunaloa-show, eval=FALSE, echo=TRUE}
#| code-fold: true
#| code-summary: "Show the code"
library(dplyr)
library(readr)
library(ggplot2)
library(lubridate)

co2 <- read_csv("https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv", 
                skip = 40, show_col_types = FALSE)

co2 |> 
  mutate(date=as_date(paste(year, month, 15, sep="."))) |>
  ggplot(aes(date, average)) + 
  geom_line() + ylab(expression(CO[2]~"in the atmosphere (ppm)")) + 
  ggtitle("Mauna Loa Observatory, Hawaii, Monthly Averages") +
  geom_smooth()
```

<!-- slides use locally cached data -->

```{r co2-maunaloa, echo=FALSE, fig.align='center'}
co2 <- read_csv("../data/co2_mm_mlo.csv", skip=40, show_col_types = FALSE) |>
  mutate(date=as_date(paste(year, month, 15, sep=".")))

co2 |> ggplot(aes(date, average)) + 
  geom_line() + 
  ylab(expression(CO[2]~"in the atmosphere (ppm)")) + 
  ggtitle("Mauna Loa Observatory, Hawaii, Monthly Averages") +
  geom_smooth()
```


Data source:

@keeling_exchanges_2001, @tans_maunaloa_2023, [https://gml.noaa.gov/ccgg/trends/data.html](https://gml.noaa.gov/ccgg/trends/data.html)

<!--
https://gml.noaa.gov/ccgg/trends/data.html
License of the data: CC BY 4.0 (see https://scrippsco2.ucsd.edu/data/atmospheric_co2/primary_mlo_co2_record.html)
-->

## Example 2: Monthly mean air temperature

```{r airtemp-monthly, echo=TRUE}
#| code-fold: true
#| code-summary: "Show the code"
library(dplyr)
library(readr)
library(ggplot2)
library(lubridate)

tempdata <- read_csv("../data/airtemp_dresden_daily.csv") |>
  select(ZEIT, TM) |>
  rename(date = ZEIT) |>
  mutate(year = year(date), month = month(date)) |>
  group_by(year, month) |>
  summarise(temp = mean(TM)) |>
  mutate(date = date(paste(year, month, 15, sep="-")))

tempdata |>
  ggplot(aes(date, temp)) + 
  geom_line() +
  ylab("Temperature (°C)") + 
  ggtitle("Monthly mean air temperature in Dresden")

```

Data downloaded from [https://rekis.hydro.tu-dresden.de](https://rekis.hydro.tu-dresden.de) 
[@kronenberg_rekis_2021], original source Deutscher Wetterdienst, https://www.dwd.de, data modified and averaged.


## Example 3: Annual mean air temperature

```{r airtemp-annual, echo=TRUE}
#| code-fold: true
#| code-summary: "Show the code"
read_csv("../data/airtemp_dresden_daily.csv") |>
  select(ZEIT, TM) |>
  rename(date = ZEIT) |>
  mutate(year = year(date)) |>
  group_by(year) |>
  summarise(temp = mean(TM)) |>
  ggplot(aes(year, temp)) + 
  geom_line() +
  geom_smooth(method="lm") +
  ylab("Temperature (°C)") + 
  ggtitle("Annual average air temperature in Dresden")
```

Data downloaded from [https://rekis.hydro.tu-dresden.de](https://rekis.hydro.tu-dresden.de) 
[@kronenberg_rekis_2021], original source Deutscher Wetterdienst, https://www.dwd.de, data modified and averaged.

## Characteristics of the examples

<br>

* Observations as a function of time
* Measurements can be serially interdependent, e.g.:
    - trend
    - seasonality
* No "true" replicates

<br>

$\Rightarrow$ independency assumption of simple linear regression is violated


## Time series analysis

<br>

* Deals with development of processes in time: $x(t)$,
* Huge number of specific approaches, only a few examples can be
  presented here.


**Aims**

* Does a trend exist? (significance)
* How strong is a trend? (effect size)
* Identification of covariates (influencing factors)
* Trend, seasonality and random error (component model)
* Statistical modeling and forecasting
* Breakpoint analysis, intervention analysis, ..., and more

# Fundamental time series concepts

## Stationarity

<br>

* Time series methods have certain assumptions.
* One of the most common assumptions is **stationarity**.

<br>


**Note:** We are usually not primarily interested in stationarity itself!

$\rightarrow$ It is just "the ticket" for further analyses.

<br>


**Example 1: trend analysis**

* We test stationarity to check if a (simple) trend test would be appropriate.

**Example 2: linear models**

* Estimation of a linear trend or a breakpoint model. 
* We check residuals for stationarity to get in formation about reliability of the fitted model.

## Stationarity: a central concept in time series analysis

```{r stat-nonstat, echo=TRUE, fig.align='center'}
#| code-fold: true
#| code-summary: "Show the code"
  set.seed(123)
  x <- 1:100
  par(mfrow = c(1, 3), cex=1.4)
  plot(x, rnorm(x), type="l", main="stationary", xlab="time", ylab="x")
  plot(x, 0.01 * x + rnorm(x), type="l", main="linear trend", xlab="time", ylab="x")
  plot(x, rnorm(x, sd=seq(0.1,1,length=100)), type="l",
    main="increasing variance", xlab="time", ylab="x")
```

* Strictly or **strong stationary process**: distribution of
  $(x_{s+t})$ independent from index $s$.
* Wide-sense or **weakly stationary processes**: requires only that
  1st and 2nd moments (mean, variance and covariance) do not vary with
  time.

## Three types of basic time series

```{r gen-LTDsp}
set.seed(1237)
time <- 1:100

LSP <- 4 + rnorm(time)

TSP <- 4 + 0.2 * time + rnorm(time)

DSP <- numeric(length(time))
DSP[1] <- rnorm(1)
for (tt in time[-1])  DSP[tt] <- DSP[tt-1] + 0.2 + rnorm(1)
```


::: {.column width="32%"}

$x_t = \beta_0 + \varepsilon_t$

```{r LSP, fig.height=6, fig.width=6}
par(cex=2, las=1, mar=c(4,4,2,1))
plot(ts(LSP), ylim=c(0, 8), main="LSP", col = "forestgreen")
```


* "level stationary process"
* mean, variance and covariance constant
* example: white noise
* $=$ **stationary**

:::

::: {.column width="32%"}

$x_t = \beta_0 + \beta_1 t + \varepsilon_t$

```{r TSP, fig.height=6, fig.width=6}
par(cex=2, las=1, mar=c(4,4,2,1))
plot(ts(TSP), main="TSP", col = "red")
```



* "trend stationary process"
* linear regression model
* can be made stationary by detrending
* $\rightarrow$ **instationary**

:::

::: {.column width="32%"}

$x_t = x_{t-1} + c + \varepsilon_t$

```{r DSP, fig.height=6, fig.width=6}
par(cex=2, las=1, mar=c(4,4,2,1))
plot(ts(DSP), col = "red", main = "DSP")
```


* "difference stationary process" (random walk)
* can be made stationary by differencing
* $\rightarrow$ **instationary**

:::

## 

```{r gen-LTDsp-show, echo=TRUE}
#| code-fold: true
#| code-summary: "Show the code"

set.seed(1237)
time <- 1:100

LSP <- 4 + rnorm(time)

TSP <- 4 + 0.2 * time + rnorm(time)

DSP <- numeric(length(time))
DSP[1] <- rnorm(1)
for (tt in time[-1])  DSP[tt] <- DSP[tt-1] + 0.2 + rnorm(1)

par(mfrow=c(1,3))

plot(ts(LSP), ylim=c(0, 8), main="LSP", col = "forestgreen")
plot(ts(TSP), main="TSP", col = "red")
plot(ts(DSP), main="DSP", col = "red")
```


## Time series classes in R

* `ts` for regularly spaced time series,
* `zoo` irregularly spaced time series.


```{r ts-example1, echo=TRUE, fig.height=5, fig.width=12, fig.align='center'}
par(mfrow=c(1, 3), las=1)
LSP <- ts(LSP)
TSP <- ts(TSP)
DSP <- ts(DSP)

plot(LSP, main="level stationary process")
plot(TSP, main="trend stationary process")
plot(DSP, main="difference stationary process")
```

## Why is this important?

<br>

* simple linear models require "independent data"
* or, more precisely: **independence of residuals**

**But**

* time series data can be serially dependent
* dependent data have "less value" [(contain less information than independent data)]{.gray}
* important for calculation of degrees of freedom for the sigificance tests

**Approaches**

1. measure serial dependency (autocorrelation)
2. if yes, handle autocorrelation
    a) remove it, [or]{.gray}
    b) model it

* autocorrelation is correlation between a time series and the shifted (= lagged) version of itself

## Autocorrelation

<br>

```{r}
laggedMatrix <- function(x, k) {
  L <- length(x + k)
  z <- matrix(NA, nrow = L + k - 1, ncol = k)
  for (i in 1:k) {
    z[(1:L) + (i - 1), i] <- x
  }
  return(z)
}
```

**A time series**

```{r}
options(knitr.kable.NA = '')
x  <- c(1, 3, 2, 4, 5, 4, 3, 2, 8, 5, 4, 3, 6, 7)
knitr::kable(t(data.frame("x_t" = c(x, NA, NA))))
```

**Shifting to the right $\rightarrow$ lags +1 and +2**

```{r}
options(knitr.kable.NA = '')
df <- data.frame(laggedMatrix(x, 3))
names(df) <- c("x_t", "x_t+1", "x_t+2")
knitr::kable(t(df))
```

Correlation between $x_t$ and $x_{t+1}$ and $x_{t+2}$:

```{r, echo=TRUE}
cor(df, use = "pairwise.complete.obs")[1,]
```

Similar results with `acf`, [deviations for small sample size, because missing values handled differently]{.gray}

```{r, echo=TRUE}
acf(x, lag = 2, plot = FALSE)
```



## Autocorrelation function (ACF)

* ... correlation between time series and its time-shifted (= lagged) versions,
* the time shift (lag) is being varied $\rightarrow$ correlogram.
* considers both, direct and indirect dependency, e.g. $x_{t}$ on $x_{t-2}$ because $x_{t-1}$ depends on $x_{t-2}$.
* without indirect effects it is called **partial autocorrelation**, PACF.
* Cross-correlation (CCF): **two** variables; lag is positive or negative.
* Examples: 
    - CCF between solar radiation and water temperature.
    - CCF of discharge at two river kilometers can be used to estimate flow velocity of a flood wave

```{r acf-example, fig.align='center'}
par(mfrow=c(1,2), cex=1.4)
acf(TSP)
pacf(TSP)
```

## Typical patterns of ACF and PACF

```{r acfpatterns, echo=FALSE, eval=TRUE, fig.width=12, fig.height=6, fig.align='center'}
par(mfrow=c(2,3), cex=1)
acf(TSP)
acf(diff(TSP))
acf(residuals(lm(TSP ~ time(TSP))))
acf(DSP)
acf(diff(DSP))
acf(residuals(lm(DSP ~ time(DSP))))
```

* ACF plots of TSP and DSP (left) very similar,
* Differentiated time series (middle),
* series with substracted trend (right).


## Typical patterns of ACF and PACF (Code)

<br>


```{r acfpatterns, echo=TRUE, eval=FALSE}
```




## Unit root test

<br>

* determine whether a time series is of type "DSP".
* ADF-test (augmented Dickey-Fuller test), contained in R-package **tseries**:
* Remember: A "TSP" can be made stationary by subtracting a trend.

$\rightarrow$ This is done automatically by the test.



```{r, echo=TRUE}
library(tseries)
adf.test(TSP)
adf.test(DSP)
```


## DSP: presence of unit root

<br>

* DSP series: presence of an unit root cannot be rejected,
* $\rightarrow$ non-stationary.
* But, after differencing, there are no objections against stationarity:

```{r, echo=TRUE}
adf.test(diff(DSP))
```


## KPSS test: Kwiatkowski-Phillips-Schmidt-Shin test

<br>

... tests directly for stationarity or trend stationarity:


```{r, echo=TRUE}
kpss.test(TSP)                # non-stationary
kpss.test(TSP, null="Trend")  # stationary after trend removal
```

<br>

* detrending made the series stationary

## KPSS test: Kwiatkowski-Phillips-Schmidt-Shin test II

<br>


```{r, echo=TRUE}
kpss.test(DSP)                # non-stationary
kpss.test(DSP, null="Trend")  # still non-stationary
```

<br>

* detrending does not cure non-stationarity

## Trend Tests

<br>

* **Mann-Kendall trend test**, popular in environmental sciences
* strictly suitable only for trend-stationary time series, but robust in cases of weak autocorrelation
* not for "pure" difference-stationary time series, because residuals are autocorrelated

* $\Rightarrow$ Test stationarity (or autocorrelation) before testing trend !!!

```{r, echo=TRUE}
library("Kendall")
MannKendall(TSP)
```

Significant trend. 
<br>

```{r, echo=TRUE}
MannKendall(DSP)
```


Indicates significant trend, but as process is DSP, interpretation is wrong.



## A Simulation Experiment

<br>

* Define two functions to generate time series with specific properties:


```{r, echo=TRUE}
genTSP <- function(time, beta0, beta1)
  as.ts(beta0 + beta1 * time + rnorm(time))

genDSP <- function(time, c) {
  DSP <- numeric(length(time))
  DSP[1] <- rnorm(1)
  for (tt in time[-1]) DSP[tt] <- DSP[tt-1] + c + rnorm(1)
  as.ts(DSP)
}
```


## Run the experiment

* set the trend to zero, so  `count.signif` counts `a` false positive results.

```{r, echo=TRUE}
count.signif <- function(N, time, FUN, ...) {
  a <- 0
  for (i in 1:N) {
    x <- FUN(time, ...)
    m <- summary(lm(x  ~ time(x)))
    f <- m$fstatistic
    p.value <- pf(f[1], f[2], f[3], lower=FALSE)
    # cat("p.value", p.value, "\n")
    if (p.value < 0.05) a <- a + 1
  }
  a
}
```

* test for the number of significant F-values,
* run loop 100 ... 1000  times for both types of time series,

```{r, echo=TRUE, fig.align='center'}
Nruns <- 100 # better 1000 !!!
count.signif(N=Nruns, time=time, FUN=genTSP, beta0=0, beta1=0) / Nruns
count.signif(N=Nruns, time=time, FUN=genDSP, c=0) / Nruns
```


## References